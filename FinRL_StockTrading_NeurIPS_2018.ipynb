{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL/blob/master/FinRL_StockTrading_NeurIPS_2018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading\n",
    "\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)   \n",
    "* [RLlib Section](#7)            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPT0ipYE28wL",
    "outputId": "ef0ba8d0-f57a-4c74-bb0b-46737762677d"
   },
   "outputs": [],
   "source": [
    "## install finrl library\n",
    "#!pip install git+https://github.com/AI4Finance-Foundation/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPqeTTwoh1hn",
    "outputId": "10b08480-3a0c-4826-8e51-f94ce97ab84a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "import os\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "##from finrl.finrl_meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from preprocess.default_preprocessors import FeatureEngineer, data_split \n",
    "#from finrl.finrl_meta.preprocessor.CryptoDataReader import CryptoDataLoader\n",
    "from finrl.finrl_meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "#from finrl.finrl_meta.data_processor import DataProcessor\n",
    "\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline, trx_plot\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = 'MARKETS'\n",
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "import os\n",
    "from finrl.main import check_and_make_directories\n",
    "\n",
    "CHOOSEN_MARKET = 'ForexMarket' \n",
    "\n",
    "DATA_SAVE_DIR = os.path.join(root_path, CHOOSEN_MARKET, 'DATASET')\n",
    "TRAINED_MODEL_DIR = os.path.join(root_path, CHOOSEN_MARKET, 'TRAINED_MODEL_DIR')\n",
    "TENSORBOARD_LOG_DIR = os.path.join(root_path, CHOOSEN_MARKET, 'TENSORBOARD_LOG_DIR')\n",
    "RESULTS_DIR = os.path.join(root_path, CHOOSEN_MARKET, 'RESULTS_DIR')\n",
    "\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "# Part 3: Download Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 use yahoo finance api to get DOWJONES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "83c7f894-3757-473b-8afb-a904e6caabda"
   },
   "outputs": [],
   "source": [
    "df = YahooDownloader(start_date = datetime.datetime(2009, 1, 1),\n",
    "                     end_date = datetime.datetime.now(),\n",
    "                     ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "7a991dfe-f39c-40db-ec44-7c416cdce7dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CSCO', 'CVX', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'KO', 'JPM', 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PG', 'TRV', 'UNH', 'CRM', 'VZ', 'V', 'WBA', 'WMT', 'DIS', 'DOW']\n"
     ]
    }
   ],
   "source": [
    "print(config_tickers.DOW_30_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "5267773c-399c-4ec9-d4d5-13ab1e4cced0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100570, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4hYkeaPiICHS",
    "outputId": "210fade5-e912-40df-be99-4ad00bdb9d2f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>3.070357</td>\n",
       "      <td>3.133571</td>\n",
       "      <td>3.047857</td>\n",
       "      <td>2.602663</td>\n",
       "      <td>607541200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>57.110001</td>\n",
       "      <td>58.220001</td>\n",
       "      <td>57.060001</td>\n",
       "      <td>43.587841</td>\n",
       "      <td>6287200</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>17.969999</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>17.910000</td>\n",
       "      <td>14.852880</td>\n",
       "      <td>9625600</td>\n",
       "      <td>AXP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>41.590000</td>\n",
       "      <td>43.049999</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>32.005890</td>\n",
       "      <td>5443100</td>\n",
       "      <td>BA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>45.099998</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>30.416967</td>\n",
       "      <td>6277400</td>\n",
       "      <td>CAT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       open       high        low      close     volume   tic  \\\n",
       "0  2008-12-31   3.070357   3.133571   3.047857   2.602663  607541200  AAPL   \n",
       "1  2008-12-31  57.110001  58.220001  57.060001  43.587841    6287200  AMGN   \n",
       "2  2008-12-31  17.969999  18.750000  17.910000  14.852880    9625600   AXP   \n",
       "3  2008-12-31  41.590000  43.049999  41.500000  32.005890    5443100    BA   \n",
       "4  2008-12-31  43.700001  45.099998  43.700001  30.416967    6277400   CAT   \n",
       "\n",
       "   day  \n",
       "0    2  \n",
       "1    2  \n",
       "2    2  \n",
       "3    2  \n",
       "4    2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic'],ignore_index=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 read all the forexdata saved in csv  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "forex_symbols = pd.read_csv(os.path.join(DATA_SAVE_DIR,'forex_stocks_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "forex_market_dataset = forex_symbols.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "forex_market_dataset = forex_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "forex_market_dataset.rename(columns={'symbol' : 'tic'}, inplace= True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cleaning forex_symbols dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type str)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/f/financial_projects/Deep Reinforcement Learning Approaches on Stock Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb Cell 31\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bu18/mnt/f/financial_projects/Deep%20Reinforcement%20Learning%20Approaches%20on%20Stock%20Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdatetime\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bu18/mnt/f/financial_projects/Deep%20Reinforcement%20Learning%20Approaches%20on%20Stock%20Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m unixdate \u001b[39min\u001b[39;00m forex_market_dataset[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bu18/mnt/f/financial_projects/Deep%20Reinforcement%20Learning%20Approaches%20on%20Stock%20Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     utcdate \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39;49mdatetime\u001b[39m.\u001b[39;49mfromtimestamp(unixdate)\u001b[39m.\u001b[39mstrftime(\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39mT\u001b[39m\u001b[39m%\u001b[39m\u001b[39mH:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bu18/mnt/f/financial_projects/Deep%20Reinforcement%20Learning%20Approaches%20on%20Stock%20Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     dates\u001b[39m.\u001b[39mappend(utcdate)\n",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required (got type str)"
     ]
    }
   ],
   "source": [
    "dates = []\n",
    "import datetime\n",
    "for unixdate in forex_market_dataset['date']:\n",
    "    utcdate = datetime.datetime.fromtimestamp(unixdate).strftime('%Y-%m-%dT%H:%M:%S')\n",
    "    dates.append(utcdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "forex_market_dataset.rename(columns= {'symbol' : 'tic'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forex_market_dataset['date'] = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>s</th>\n",
       "      <th>date</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3419.60000</td>\n",
       "      <td>3423.70000</td>\n",
       "      <td>3412.60000</td>\n",
       "      <td>3420.60000</td>\n",
       "      <td>ok</td>\n",
       "      <td>2022-07-01T10:30:00</td>\n",
       "      <td>463</td>\n",
       "      <td>OANDA:EU50_EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3438.00000</td>\n",
       "      <td>3444.90000</td>\n",
       "      <td>3401.90000</td>\n",
       "      <td>3419.60000</td>\n",
       "      <td>ok</td>\n",
       "      <td>2022-07-01T11:30:00</td>\n",
       "      <td>1691</td>\n",
       "      <td>OANDA:EU50_EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3456.00000</td>\n",
       "      <td>3462.90000</td>\n",
       "      <td>3428.90000</td>\n",
       "      <td>3440.00000</td>\n",
       "      <td>ok</td>\n",
       "      <td>2022-07-01T12:30:00</td>\n",
       "      <td>794</td>\n",
       "      <td>OANDA:EU50_EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3463.90000</td>\n",
       "      <td>3466.00000</td>\n",
       "      <td>3450.90000</td>\n",
       "      <td>3456.90000</td>\n",
       "      <td>ok</td>\n",
       "      <td>2022-07-01T13:30:00</td>\n",
       "      <td>685</td>\n",
       "      <td>OANDA:EU50_EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3441.00000</td>\n",
       "      <td>3465.90000</td>\n",
       "      <td>3439.90000</td>\n",
       "      <td>3464.90000</td>\n",
       "      <td>ok</td>\n",
       "      <td>2022-07-01T14:30:00</td>\n",
       "      <td>468</td>\n",
       "      <td>OANDA:EU50_EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.69773</td>\n",
       "      <td>0.69848</td>\n",
       "      <td>0.69680</td>\n",
       "      <td>0.69834</td>\n",
       "      <td>ok</td>\n",
       "      <td>2022-07-29T20:30:00</td>\n",
       "      <td>3036</td>\n",
       "      <td>OANDA:AUD_USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.69771</td>\n",
       "      <td>0.69784</td>\n",
       "      <td>0.69713</td>\n",
       "      <td>0.69770</td>\n",
       "      <td>ok</td>\n",
       "      <td>2022-07-29T21:30:00</td>\n",
       "      <td>1886</td>\n",
       "      <td>OANDA:AUD_USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.69951</td>\n",
       "      <td>0.69952</td>\n",
       "      <td>0.69762</td>\n",
       "      <td>0.69771</td>\n",
       "      <td>ok</td>\n",
       "      <td>2022-07-29T22:30:00</td>\n",
       "      <td>1877</td>\n",
       "      <td>OANDA:AUD_USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.69864</td>\n",
       "      <td>0.69978</td>\n",
       "      <td>0.69837</td>\n",
       "      <td>0.69950</td>\n",
       "      <td>ok</td>\n",
       "      <td>2022-07-29T23:30:00</td>\n",
       "      <td>2004</td>\n",
       "      <td>OANDA:AUD_USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.69871</td>\n",
       "      <td>0.69960</td>\n",
       "      <td>0.69838</td>\n",
       "      <td>0.69863</td>\n",
       "      <td>ok</td>\n",
       "      <td>2022-07-30T00:30:00</td>\n",
       "      <td>1120</td>\n",
       "      <td>OANDA:AUD_USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57272 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          close        high         low        open   s                 date  \\\n",
       "0    3419.60000  3423.70000  3412.60000  3420.60000  ok  2022-07-01T10:30:00   \n",
       "1    3438.00000  3444.90000  3401.90000  3419.60000  ok  2022-07-01T11:30:00   \n",
       "2    3456.00000  3462.90000  3428.90000  3440.00000  ok  2022-07-01T12:30:00   \n",
       "3    3463.90000  3466.00000  3450.90000  3456.90000  ok  2022-07-01T13:30:00   \n",
       "4    3441.00000  3465.90000  3439.90000  3464.90000  ok  2022-07-01T14:30:00   \n",
       "..          ...         ...         ...         ...  ..                  ...   \n",
       "490     0.69773     0.69848     0.69680     0.69834  ok  2022-07-29T20:30:00   \n",
       "491     0.69771     0.69784     0.69713     0.69770  ok  2022-07-29T21:30:00   \n",
       "492     0.69951     0.69952     0.69762     0.69771  ok  2022-07-29T22:30:00   \n",
       "493     0.69864     0.69978     0.69837     0.69950  ok  2022-07-29T23:30:00   \n",
       "494     0.69871     0.69960     0.69838     0.69863  ok  2022-07-30T00:30:00   \n",
       "\n",
       "     volume             tic  \n",
       "0       463  OANDA:EU50_EUR  \n",
       "1      1691  OANDA:EU50_EUR  \n",
       "2       794  OANDA:EU50_EUR  \n",
       "3       685  OANDA:EU50_EUR  \n",
       "4       468  OANDA:EU50_EUR  \n",
       "..      ...             ...  \n",
       "490    3036   OANDA:AUD_USD  \n",
       "491    1886   OANDA:AUD_USD  \n",
       "492    1877   OANDA:AUD_USD  \n",
       "493    2004   OANDA:AUD_USD  \n",
       "494    1120   OANDA:AUD_USD  \n",
       "\n",
       "[57272 rows x 8 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forex_market_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>date</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3419.60000</td>\n",
       "      <td>3423.70000</td>\n",
       "      <td>3412.60000</td>\n",
       "      <td>3420.60000</td>\n",
       "      <td>2022-07-01T10:30:00</td>\n",
       "      <td>463</td>\n",
       "      <td>OANDA:EU50_EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3438.00000</td>\n",
       "      <td>3444.90000</td>\n",
       "      <td>3401.90000</td>\n",
       "      <td>3419.60000</td>\n",
       "      <td>2022-07-01T11:30:00</td>\n",
       "      <td>1691</td>\n",
       "      <td>OANDA:EU50_EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3456.00000</td>\n",
       "      <td>3462.90000</td>\n",
       "      <td>3428.90000</td>\n",
       "      <td>3440.00000</td>\n",
       "      <td>2022-07-01T12:30:00</td>\n",
       "      <td>794</td>\n",
       "      <td>OANDA:EU50_EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3463.90000</td>\n",
       "      <td>3466.00000</td>\n",
       "      <td>3450.90000</td>\n",
       "      <td>3456.90000</td>\n",
       "      <td>2022-07-01T13:30:00</td>\n",
       "      <td>685</td>\n",
       "      <td>OANDA:EU50_EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3441.00000</td>\n",
       "      <td>3465.90000</td>\n",
       "      <td>3439.90000</td>\n",
       "      <td>3464.90000</td>\n",
       "      <td>2022-07-01T14:30:00</td>\n",
       "      <td>468</td>\n",
       "      <td>OANDA:EU50_EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.69773</td>\n",
       "      <td>0.69848</td>\n",
       "      <td>0.69680</td>\n",
       "      <td>0.69834</td>\n",
       "      <td>2022-07-29T20:30:00</td>\n",
       "      <td>3036</td>\n",
       "      <td>OANDA:AUD_USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.69771</td>\n",
       "      <td>0.69784</td>\n",
       "      <td>0.69713</td>\n",
       "      <td>0.69770</td>\n",
       "      <td>2022-07-29T21:30:00</td>\n",
       "      <td>1886</td>\n",
       "      <td>OANDA:AUD_USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.69951</td>\n",
       "      <td>0.69952</td>\n",
       "      <td>0.69762</td>\n",
       "      <td>0.69771</td>\n",
       "      <td>2022-07-29T22:30:00</td>\n",
       "      <td>1877</td>\n",
       "      <td>OANDA:AUD_USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.69864</td>\n",
       "      <td>0.69978</td>\n",
       "      <td>0.69837</td>\n",
       "      <td>0.69950</td>\n",
       "      <td>2022-07-29T23:30:00</td>\n",
       "      <td>2004</td>\n",
       "      <td>OANDA:AUD_USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.69871</td>\n",
       "      <td>0.69960</td>\n",
       "      <td>0.69838</td>\n",
       "      <td>0.69863</td>\n",
       "      <td>2022-07-30T00:30:00</td>\n",
       "      <td>1120</td>\n",
       "      <td>OANDA:AUD_USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57272 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          close        high         low        open                 date  \\\n",
       "0    3419.60000  3423.70000  3412.60000  3420.60000  2022-07-01T10:30:00   \n",
       "1    3438.00000  3444.90000  3401.90000  3419.60000  2022-07-01T11:30:00   \n",
       "2    3456.00000  3462.90000  3428.90000  3440.00000  2022-07-01T12:30:00   \n",
       "3    3463.90000  3466.00000  3450.90000  3456.90000  2022-07-01T13:30:00   \n",
       "4    3441.00000  3465.90000  3439.90000  3464.90000  2022-07-01T14:30:00   \n",
       "..          ...         ...         ...         ...                  ...   \n",
       "490     0.69773     0.69848     0.69680     0.69834  2022-07-29T20:30:00   \n",
       "491     0.69771     0.69784     0.69713     0.69770  2022-07-29T21:30:00   \n",
       "492     0.69951     0.69952     0.69762     0.69771  2022-07-29T22:30:00   \n",
       "493     0.69864     0.69978     0.69837     0.69950  2022-07-29T23:30:00   \n",
       "494     0.69871     0.69960     0.69838     0.69863  2022-07-30T00:30:00   \n",
       "\n",
       "     volume             tic  \n",
       "0       463  OANDA:EU50_EUR  \n",
       "1      1691  OANDA:EU50_EUR  \n",
       "2       794  OANDA:EU50_EUR  \n",
       "3       685  OANDA:EU50_EUR  \n",
       "4       468  OANDA:EU50_EUR  \n",
       "..      ...             ...  \n",
       "490    3036   OANDA:AUD_USD  \n",
       "491    1886   OANDA:AUD_USD  \n",
       "492    1877   OANDA:AUD_USD  \n",
       "493    2004   OANDA:AUD_USD  \n",
       "494    1120   OANDA:AUD_USD  \n",
       "\n",
       "[57272 rows x 7 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forex_market_dataset.sort_values(['date', 'tic'], ignore_index = True)\n",
    "forex_market_dataset.drop(columns='s', inplace = True)\n",
    "forex_market_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 : use finnhub to get crypto market data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key='cbj22uqad3i2thcmtg80'\n",
    "choosen_symbols = ['BTC', 'ETH', 'USDT', 'USDC', 'BNB', 'XRP', 'ADA', 'BUSD', 'SOL', 'DOT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = CryptoDataLoader(symbols_list= choosen_symbols, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_df = data_loader.load_crypto_candles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>h</th>\n",
       "      <th>l</th>\n",
       "      <th>o</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>v</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.06921</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.01444</td>\n",
       "      <td>0.01444</td>\n",
       "      <td>ok</td>\n",
       "      <td>1586476800</td>\n",
       "      <td>3695792.1</td>\n",
       "      <td>BINANCE:SOLBNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05773</td>\n",
       "      <td>0.07609</td>\n",
       "      <td>0.05568</td>\n",
       "      <td>0.06921</td>\n",
       "      <td>ok</td>\n",
       "      <td>1586563200</td>\n",
       "      <td>1792845.2</td>\n",
       "      <td>BINANCE:SOLBNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06188</td>\n",
       "      <td>0.06589</td>\n",
       "      <td>0.05464</td>\n",
       "      <td>0.05756</td>\n",
       "      <td>ok</td>\n",
       "      <td>1586649600</td>\n",
       "      <td>1036908.3</td>\n",
       "      <td>BINANCE:SOLBNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05171</td>\n",
       "      <td>0.06188</td>\n",
       "      <td>0.05160</td>\n",
       "      <td>0.06188</td>\n",
       "      <td>ok</td>\n",
       "      <td>1586736000</td>\n",
       "      <td>476803.6</td>\n",
       "      <td>BINANCE:SOLBNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04272</td>\n",
       "      <td>0.05264</td>\n",
       "      <td>0.04040</td>\n",
       "      <td>0.05171</td>\n",
       "      <td>ok</td>\n",
       "      <td>1586822400</td>\n",
       "      <td>617685.5</td>\n",
       "      <td>BINANCE:SOLBNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.23700</td>\n",
       "      <td>1.33100</td>\n",
       "      <td>1.23700</td>\n",
       "      <td>1.31300</td>\n",
       "      <td>ok</td>\n",
       "      <td>1639612800</td>\n",
       "      <td>1450240.9</td>\n",
       "      <td>BINANCE:ADAUSDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.22200</td>\n",
       "      <td>1.25800</td>\n",
       "      <td>1.18300</td>\n",
       "      <td>1.23900</td>\n",
       "      <td>ok</td>\n",
       "      <td>1639699200</td>\n",
       "      <td>3451131.2</td>\n",
       "      <td>BINANCE:ADAUSDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.24300</td>\n",
       "      <td>1.26800</td>\n",
       "      <td>1.19900</td>\n",
       "      <td>1.21900</td>\n",
       "      <td>ok</td>\n",
       "      <td>1639785600</td>\n",
       "      <td>658339.6</td>\n",
       "      <td>BINANCE:ADAUSDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.24400</td>\n",
       "      <td>1.31100</td>\n",
       "      <td>1.24100</td>\n",
       "      <td>1.24200</td>\n",
       "      <td>ok</td>\n",
       "      <td>1639872000</td>\n",
       "      <td>1262579.4</td>\n",
       "      <td>BINANCE:ADAUSDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.23700</td>\n",
       "      <td>1.26100</td>\n",
       "      <td>1.20200</td>\n",
       "      <td>1.24300</td>\n",
       "      <td>ok</td>\n",
       "      <td>1639958400</td>\n",
       "      <td>2011319.1</td>\n",
       "      <td>BINANCE:ADAUSDC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33683 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           c        h        l        o   s           t          v  \\\n",
       "0    0.06921  0.10000  0.01444  0.01444  ok  1586476800  3695792.1   \n",
       "1    0.05773  0.07609  0.05568  0.06921  ok  1586563200  1792845.2   \n",
       "2    0.06188  0.06589  0.05464  0.05756  ok  1586649600  1036908.3   \n",
       "3    0.05171  0.06188  0.05160  0.06188  ok  1586736000   476803.6   \n",
       "4    0.04272  0.05264  0.04040  0.05171  ok  1586822400   617685.5   \n",
       "..       ...      ...      ...      ...  ..         ...        ...   \n",
       "995  1.23700  1.33100  1.23700  1.31300  ok  1639612800  1450240.9   \n",
       "996  1.22200  1.25800  1.18300  1.23900  ok  1639699200  3451131.2   \n",
       "997  1.24300  1.26800  1.19900  1.21900  ok  1639785600   658339.6   \n",
       "998  1.24400  1.31100  1.24100  1.24200  ok  1639872000  1262579.4   \n",
       "999  1.23700  1.26100  1.20200  1.24300  ok  1639958400  2011319.1   \n",
       "\n",
       "              symbol  \n",
       "0     BINANCE:SOLBNB  \n",
       "1     BINANCE:SOLBNB  \n",
       "2     BINANCE:SOLBNB  \n",
       "3     BINANCE:SOLBNB  \n",
       "4     BINANCE:SOLBNB  \n",
       "..               ...  \n",
       "995  BINANCE:ADAUSDC  \n",
       "996  BINANCE:ADAUSDC  \n",
       "997  BINANCE:ADAUSDC  \n",
       "998  BINANCE:ADAUSDC  \n",
       "999  BINANCE:ADAUSDC  \n",
       "\n",
       "[33683 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crypto_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_symbols_df = data_loader.cleansing_holcv_dataframes(crypto_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "import datetime\n",
    "for unixdate in crypto_symbols_df['date']:\n",
    "    utcdate = datetime.datetime.fromtimestamp(unixdate).strftime('%Y-%m-%d')\n",
    "    dates.append(utcdate)\n",
    "crypto_symbols_df['date'] = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>date</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.06921</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.01444</td>\n",
       "      <td>0.01444</td>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>3695792.1</td>\n",
       "      <td>BINANCE:SOLBNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05773</td>\n",
       "      <td>0.07609</td>\n",
       "      <td>0.05568</td>\n",
       "      <td>0.06921</td>\n",
       "      <td>2020-04-11</td>\n",
       "      <td>1792845.2</td>\n",
       "      <td>BINANCE:SOLBNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06188</td>\n",
       "      <td>0.06589</td>\n",
       "      <td>0.05464</td>\n",
       "      <td>0.05756</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>1036908.3</td>\n",
       "      <td>BINANCE:SOLBNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05171</td>\n",
       "      <td>0.06188</td>\n",
       "      <td>0.05160</td>\n",
       "      <td>0.06188</td>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>476803.6</td>\n",
       "      <td>BINANCE:SOLBNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04272</td>\n",
       "      <td>0.05264</td>\n",
       "      <td>0.04040</td>\n",
       "      <td>0.05171</td>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>617685.5</td>\n",
       "      <td>BINANCE:SOLBNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.23700</td>\n",
       "      <td>1.33100</td>\n",
       "      <td>1.23700</td>\n",
       "      <td>1.31300</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>1450240.9</td>\n",
       "      <td>BINANCE:ADAUSDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.22200</td>\n",
       "      <td>1.25800</td>\n",
       "      <td>1.18300</td>\n",
       "      <td>1.23900</td>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>3451131.2</td>\n",
       "      <td>BINANCE:ADAUSDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.24300</td>\n",
       "      <td>1.26800</td>\n",
       "      <td>1.19900</td>\n",
       "      <td>1.21900</td>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>658339.6</td>\n",
       "      <td>BINANCE:ADAUSDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.24400</td>\n",
       "      <td>1.31100</td>\n",
       "      <td>1.24100</td>\n",
       "      <td>1.24200</td>\n",
       "      <td>2021-12-19</td>\n",
       "      <td>1262579.4</td>\n",
       "      <td>BINANCE:ADAUSDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.23700</td>\n",
       "      <td>1.26100</td>\n",
       "      <td>1.20200</td>\n",
       "      <td>1.24300</td>\n",
       "      <td>2021-12-20</td>\n",
       "      <td>2011319.1</td>\n",
       "      <td>BINANCE:ADAUSDC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33683 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       close     high      low     open        date     volume  \\\n",
       "0    0.06921  0.10000  0.01444  0.01444  2020-04-10  3695792.1   \n",
       "1    0.05773  0.07609  0.05568  0.06921  2020-04-11  1792845.2   \n",
       "2    0.06188  0.06589  0.05464  0.05756  2020-04-12  1036908.3   \n",
       "3    0.05171  0.06188  0.05160  0.06188  2020-04-13   476803.6   \n",
       "4    0.04272  0.05264  0.04040  0.05171  2020-04-14   617685.5   \n",
       "..       ...      ...      ...      ...         ...        ...   \n",
       "995  1.23700  1.33100  1.23700  1.31300  2021-12-16  1450240.9   \n",
       "996  1.22200  1.25800  1.18300  1.23900  2021-12-17  3451131.2   \n",
       "997  1.24300  1.26800  1.19900  1.21900  2021-12-18   658339.6   \n",
       "998  1.24400  1.31100  1.24100  1.24200  2021-12-19  1262579.4   \n",
       "999  1.23700  1.26100  1.20200  1.24300  2021-12-20  2011319.1   \n",
       "\n",
       "                 tic  \n",
       "0     BINANCE:SOLBNB  \n",
       "1     BINANCE:SOLBNB  \n",
       "2     BINANCE:SOLBNB  \n",
       "3     BINANCE:SOLBNB  \n",
       "4     BINANCE:SOLBNB  \n",
       "..               ...  \n",
       "995  BINANCE:ADAUSDC  \n",
       "996  BINANCE:ADAUSDC  \n",
       "997  BINANCE:ADAUSDC  \n",
       "998  BINANCE:ADAUSDC  \n",
       "999  BINANCE:ADAUSDC  \n",
       "\n",
       "[33683 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = crypto_symbols_df.copy()\n",
    "data  = data_loader.crypto_clean_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/f/financial_projects/Deep Reinforcement Learning Approaches on Stock Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb Cell 51\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bu18/mnt/f/financial_projects/Deep%20Reinforcement%20Learning%20Approaches%20on%20Stock%20Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m data\u001b[39m.\u001b[39mto_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(DATA_SAVE_DIR,\u001b[39m'\u001b[39m\u001b[39mDataset.csv\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.to_csv(os.path.join(DATA_SAVE_DIR,'Dataset.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'Dataset.csv'\n",
    "data  = pd.read_csv(os.path.join(DATA_SAVE_DIR,data_name))\n",
    "data.drop(columns={'Unnamed: 0'}, inplace= True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 :use yahoofinance api to get s&p 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4 as bs\n",
    "import pickle\n",
    "\n",
    "def save_sp500_tickers():\n",
    "    resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "    tickers = []\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[0].text\n",
    "        tickers.append(ticker)\n",
    "    with open(\"sp500tickers.pickle\", \"wb\") as f:\n",
    "        pickle.dump(tickers, f)\n",
    "    return tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_tickers = save_sp500_tickers()\n",
    "data = YahooDownloader(start_date = datetime.datetime(2016, 1, 1),\n",
    "                     end_date = datetime.datetime.now(),\n",
    "                     ticker_list = sp_tickers).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)\n",
    "data.to_csv(os.path.join(DATA_SAVE_DIR,'sp500.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(DATA_SAVE_DIR,'sp500.csv'))\n",
    "data.drop(columns={'Unnamed: 0'}, inplace= True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - alternative: Load Data From CSV File\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "forex_market_dataset = pd.read_csv(os.path.join(DATA_SAVE_DIR, 'forex_data.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = forex_market_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>tic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1.149306</td>\n",
       "      <td>1.149306</td>\n",
       "      <td>1.155001</td>\n",
       "      <td>1.146500</td>\n",
       "      <td>1.149425</td>\n",
       "      <td>0</td>\n",
       "      <td>EURUSD=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>1.146171</td>\n",
       "      <td>1.146171</td>\n",
       "      <td>1.149700</td>\n",
       "      <td>1.134572</td>\n",
       "      <td>1.146132</td>\n",
       "      <td>0</td>\n",
       "      <td>EURUSD=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>1.131811</td>\n",
       "      <td>1.131811</td>\n",
       "      <td>1.140914</td>\n",
       "      <td>1.131734</td>\n",
       "      <td>1.131734</td>\n",
       "      <td>0</td>\n",
       "      <td>EURUSD=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>1.139108</td>\n",
       "      <td>1.139108</td>\n",
       "      <td>1.141774</td>\n",
       "      <td>1.134816</td>\n",
       "      <td>1.139095</td>\n",
       "      <td>0</td>\n",
       "      <td>EURUSD=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>1.141044</td>\n",
       "      <td>1.141044</td>\n",
       "      <td>1.147447</td>\n",
       "      <td>1.140524</td>\n",
       "      <td>1.141292</td>\n",
       "      <td>0</td>\n",
       "      <td>EURUSD=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6253</th>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>0.932880</td>\n",
       "      <td>0.932880</td>\n",
       "      <td>0.933900</td>\n",
       "      <td>0.930900</td>\n",
       "      <td>0.932880</td>\n",
       "      <td>0</td>\n",
       "      <td>USDCHF=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6254</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>0.932010</td>\n",
       "      <td>0.932010</td>\n",
       "      <td>0.932090</td>\n",
       "      <td>0.926900</td>\n",
       "      <td>0.932010</td>\n",
       "      <td>0</td>\n",
       "      <td>USDCHF=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6255</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>0.929200</td>\n",
       "      <td>0.929200</td>\n",
       "      <td>0.930600</td>\n",
       "      <td>0.924640</td>\n",
       "      <td>0.929200</td>\n",
       "      <td>0</td>\n",
       "      <td>USDCHF=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6256</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>0.927710</td>\n",
       "      <td>0.927710</td>\n",
       "      <td>0.928720</td>\n",
       "      <td>0.921190</td>\n",
       "      <td>0.927710</td>\n",
       "      <td>0</td>\n",
       "      <td>USDCHF=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6257</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>0.922850</td>\n",
       "      <td>0.922850</td>\n",
       "      <td>0.926110</td>\n",
       "      <td>0.920320</td>\n",
       "      <td>0.922850</td>\n",
       "      <td>0</td>\n",
       "      <td>USDCHF=X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6258 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Adj Close     Close      High       Low      Open  Volume  \\\n",
       "0     2019-01-01   1.149306  1.149306  1.155001  1.146500  1.149425       0   \n",
       "1     2019-01-02   1.146171  1.146171  1.149700  1.134572  1.146132       0   \n",
       "2     2019-01-03   1.131811  1.131811  1.140914  1.131734  1.131734       0   \n",
       "3     2019-01-04   1.139108  1.139108  1.141774  1.134816  1.139095       0   \n",
       "4     2019-01-07   1.141044  1.141044  1.147447  1.140524  1.141292       0   \n",
       "...          ...        ...       ...       ...       ...       ...     ...   \n",
       "6253  2022-12-26   0.932880  0.932880  0.933900  0.930900  0.932880       0   \n",
       "6254  2022-12-27   0.932010  0.932010  0.932090  0.926900  0.932010       0   \n",
       "6255  2022-12-28   0.929200  0.929200  0.930600  0.924640  0.929200       0   \n",
       "6256  2022-12-29   0.927710  0.927710  0.928720  0.921190  0.927710       0   \n",
       "6257  2022-12-30   0.922850  0.922850  0.926110  0.920320  0.922850       0   \n",
       "\n",
       "           tic  \n",
       "0     EURUSD=X  \n",
       "1     EURUSD=X  \n",
       "2     EURUSD=X  \n",
       "3     EURUSD=X  \n",
       "4     EURUSD=X  \n",
       "...        ...  \n",
       "6253  USDCHF=X  \n",
       "6254  USDCHF=X  \n",
       "6255  USDCHF=X  \n",
       "6256  USDCHF=X  \n",
       "6257  USDCHF=X  \n",
       "\n",
       "[6258 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns='Volume', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'Date': 'date','Adj Close': 'adj close', 'Close' : 'close', 'High' : 'high', 'Low': 'low', 'Open': 'open'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EURUSD=X', 'GBPUSD=X', 'USDJPY=X', 'AUDUSD=X', 'USDCAD=X',\n",
       "       'USDCHF=X'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tic.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess.default_preprocessors import FeatureEngineer, data_split \n",
    "from finrl import config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PmKP-1ii3RLS",
    "outputId": "0708badb-77ef-4c86-f77c-6525f0e8934d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'adj close', 'close', 'high', 'low', 'open', 'tic'], dtype='object')\n",
      "Successfully added technical indicators\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (1007, 8)\n",
      "Successfully added vix\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator = True,\n",
    "                    tech_indicator_list =  config.INDICATORS,\n",
    "                    use_vix= True ,\n",
    "                    use_turbulence=True,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AUDUSD=X', 'EURUSD=X', 'GBPUSD=X', 'USDCAD=X', 'USDCHF=X',\n",
       "       'USDJPY=X'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.tic.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(processed.isna() == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>adj close</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>tic</th>\n",
       "      <th>macd</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>0.704791</td>\n",
       "      <td>0.704791</td>\n",
       "      <td>0.704821</td>\n",
       "      <td>0.698470</td>\n",
       "      <td>0.704722</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.704483</td>\n",
       "      <td>0.704483</td>\n",
       "      <td>23.219999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>1.146171</td>\n",
       "      <td>1.146171</td>\n",
       "      <td>1.149700</td>\n",
       "      <td>1.134572</td>\n",
       "      <td>1.146132</td>\n",
       "      <td>EURUSD=X</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.147739</td>\n",
       "      <td>1.147739</td>\n",
       "      <td>23.219999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>1.275429</td>\n",
       "      <td>1.275429</td>\n",
       "      <td>1.277335</td>\n",
       "      <td>1.258463</td>\n",
       "      <td>1.275234</td>\n",
       "      <td>GBPUSD=X</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.274617</td>\n",
       "      <td>1.274617</td>\n",
       "      <td>23.219999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>1.362540</td>\n",
       "      <td>1.362540</td>\n",
       "      <td>1.365960</td>\n",
       "      <td>1.356900</td>\n",
       "      <td>1.362500</td>\n",
       "      <td>USDCAD=X</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.350985</td>\n",
       "      <td>1.350985</td>\n",
       "      <td>23.219999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>0.982000</td>\n",
       "      <td>0.982000</td>\n",
       "      <td>0.989250</td>\n",
       "      <td>0.979400</td>\n",
       "      <td>0.981800</td>\n",
       "      <td>USDCHF=X</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.982755</td>\n",
       "      <td>0.982755</td>\n",
       "      <td>23.219999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6031</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>1.062925</td>\n",
       "      <td>1.062925</td>\n",
       "      <td>1.067019</td>\n",
       "      <td>1.061233</td>\n",
       "      <td>1.062925</td>\n",
       "      <td>EURUSD=X</td>\n",
       "      <td>0.008925</td>\n",
       "      <td>60.167083</td>\n",
       "      <td>78.327051</td>\n",
       "      <td>49.139568</td>\n",
       "      <td>1.050900</td>\n",
       "      <td>1.022255</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>6.166426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6032</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>1.202848</td>\n",
       "      <td>1.202848</td>\n",
       "      <td>1.207584</td>\n",
       "      <td>1.201548</td>\n",
       "      <td>1.203297</td>\n",
       "      <td>GBPUSD=X</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>52.732919</td>\n",
       "      <td>-46.930901</td>\n",
       "      <td>3.480165</td>\n",
       "      <td>1.211069</td>\n",
       "      <td>1.176042</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>6.166426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6033</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>1.359940</td>\n",
       "      <td>1.359940</td>\n",
       "      <td>1.360760</td>\n",
       "      <td>1.354450</td>\n",
       "      <td>1.359940</td>\n",
       "      <td>USDCAD=X</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>52.738428</td>\n",
       "      <td>36.079932</td>\n",
       "      <td>8.181686</td>\n",
       "      <td>1.353157</td>\n",
       "      <td>1.357071</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>6.166426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6034</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>0.927710</td>\n",
       "      <td>0.927710</td>\n",
       "      <td>0.928720</td>\n",
       "      <td>0.921190</td>\n",
       "      <td>0.927710</td>\n",
       "      <td>USDCHF=X</td>\n",
       "      <td>-0.006936</td>\n",
       "      <td>40.654053</td>\n",
       "      <td>-97.756970</td>\n",
       "      <td>35.855458</td>\n",
       "      <td>0.938252</td>\n",
       "      <td>0.963402</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>6.166426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>134.033997</td>\n",
       "      <td>134.033997</td>\n",
       "      <td>134.188004</td>\n",
       "      <td>132.936005</td>\n",
       "      <td>134.033997</td>\n",
       "      <td>USDJPY=X</td>\n",
       "      <td>-1.870648</td>\n",
       "      <td>41.564990</td>\n",
       "      <td>-88.398318</td>\n",
       "      <td>29.149269</td>\n",
       "      <td>136.605233</td>\n",
       "      <td>141.392699</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>6.166426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6036 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date   adj close       close        high         low        open  \\\n",
       "0     2019-01-02    0.704791    0.704791    0.704821    0.698470    0.704722   \n",
       "1     2019-01-02    1.146171    1.146171    1.149700    1.134572    1.146132   \n",
       "2     2019-01-02    1.275429    1.275429    1.277335    1.258463    1.275234   \n",
       "3     2019-01-02    1.362540    1.362540    1.365960    1.356900    1.362500   \n",
       "4     2019-01-02    0.982000    0.982000    0.989250    0.979400    0.981800   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "6031  2022-12-29    1.062925    1.062925    1.067019    1.061233    1.062925   \n",
       "6032  2022-12-29    1.202848    1.202848    1.207584    1.201548    1.203297   \n",
       "6033  2022-12-29    1.359940    1.359940    1.360760    1.354450    1.359940   \n",
       "6034  2022-12-29    0.927710    0.927710    0.928720    0.921190    0.927710   \n",
       "6035  2022-12-29  134.033997  134.033997  134.188004  132.936005  134.033997   \n",
       "\n",
       "           tic      macd      rsi_30     cci_30       dx_30  close_30_sma  \\\n",
       "0     AUDUSD=X  0.000014  100.000000 -66.666667  100.000000      0.704483   \n",
       "1     EURUSD=X -0.000070    0.000000 -66.666667  100.000000      1.147739   \n",
       "2     GBPUSD=X  0.000036  100.000000 -66.666667  100.000000      1.274617   \n",
       "3     USDCAD=X  0.000518  100.000000  66.666667  100.000000      1.350985   \n",
       "4     USDCHF=X -0.000034    0.000000  66.666667  100.000000      0.982755   \n",
       "...        ...       ...         ...        ...         ...           ...   \n",
       "6031  EURUSD=X  0.008925   60.167083  78.327051   49.139568      1.050900   \n",
       "6032  GBPUSD=X  0.003764   52.732919 -46.930901    3.480165      1.211069   \n",
       "6033  USDCAD=X  0.002138   52.738428  36.079932    8.181686      1.353157   \n",
       "6034  USDCHF=X -0.006936   40.654053 -97.756970   35.855458      0.938252   \n",
       "6035  USDJPY=X -1.870648   41.564990 -88.398318   29.149269    136.605233   \n",
       "\n",
       "      close_60_sma        vix  turbulence  \n",
       "0         0.704483  23.219999    0.000000  \n",
       "1         1.147739  23.219999    0.000000  \n",
       "2         1.274617  23.219999    0.000000  \n",
       "3         1.350985  23.219999    0.000000  \n",
       "4         0.982755  23.219999    0.000000  \n",
       "...            ...        ...         ...  \n",
       "6031      1.022255  21.440001    6.166426  \n",
       "6032      1.176042  21.440001    6.166426  \n",
       "6033      1.357071  21.440001    6.166426  \n",
       "6034      0.963402  21.440001    6.166426  \n",
       "6035    141.392699  21.440001    6.166426  \n",
       "\n",
       "[6036 rows x 15 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Kixon2tR3RLT"
   },
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "id": "grvhGJJII3Xn",
    "outputId": "733758c3-3552-4aa5-e1f9-789bd4ce0c92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>adj close</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>macd</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.704791</td>\n",
       "      <td>0.704791</td>\n",
       "      <td>0.704821</td>\n",
       "      <td>0.698470</td>\n",
       "      <td>0.704722</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.704483</td>\n",
       "      <td>0.704483</td>\n",
       "      <td>23.219999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>EURUSD=X</td>\n",
       "      <td>1.146171</td>\n",
       "      <td>1.146171</td>\n",
       "      <td>1.149700</td>\n",
       "      <td>1.134572</td>\n",
       "      <td>1.146132</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.147739</td>\n",
       "      <td>1.147739</td>\n",
       "      <td>23.219999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>GBPUSD=X</td>\n",
       "      <td>1.275429</td>\n",
       "      <td>1.275429</td>\n",
       "      <td>1.277335</td>\n",
       "      <td>1.258463</td>\n",
       "      <td>1.275234</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.274617</td>\n",
       "      <td>1.274617</td>\n",
       "      <td>23.219999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>USDCAD=X</td>\n",
       "      <td>1.362540</td>\n",
       "      <td>1.362540</td>\n",
       "      <td>1.365960</td>\n",
       "      <td>1.356900</td>\n",
       "      <td>1.362500</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.350985</td>\n",
       "      <td>1.350985</td>\n",
       "      <td>23.219999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>USDCHF=X</td>\n",
       "      <td>0.982000</td>\n",
       "      <td>0.982000</td>\n",
       "      <td>0.989250</td>\n",
       "      <td>0.979400</td>\n",
       "      <td>0.981800</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.982755</td>\n",
       "      <td>0.982755</td>\n",
       "      <td>23.219999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6031</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>EURUSD=X</td>\n",
       "      <td>1.062925</td>\n",
       "      <td>1.062925</td>\n",
       "      <td>1.067019</td>\n",
       "      <td>1.061233</td>\n",
       "      <td>1.062925</td>\n",
       "      <td>0.008925</td>\n",
       "      <td>60.167083</td>\n",
       "      <td>78.327051</td>\n",
       "      <td>49.139568</td>\n",
       "      <td>1.050900</td>\n",
       "      <td>1.022255</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>6.166426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6032</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>GBPUSD=X</td>\n",
       "      <td>1.202848</td>\n",
       "      <td>1.202848</td>\n",
       "      <td>1.207584</td>\n",
       "      <td>1.201548</td>\n",
       "      <td>1.203297</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>52.732919</td>\n",
       "      <td>-46.930901</td>\n",
       "      <td>3.480165</td>\n",
       "      <td>1.211069</td>\n",
       "      <td>1.176042</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>6.166426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6033</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>USDCAD=X</td>\n",
       "      <td>1.359940</td>\n",
       "      <td>1.359940</td>\n",
       "      <td>1.360760</td>\n",
       "      <td>1.354450</td>\n",
       "      <td>1.359940</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>52.738428</td>\n",
       "      <td>36.079932</td>\n",
       "      <td>8.181686</td>\n",
       "      <td>1.353157</td>\n",
       "      <td>1.357071</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>6.166426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6034</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>USDCHF=X</td>\n",
       "      <td>0.927710</td>\n",
       "      <td>0.927710</td>\n",
       "      <td>0.928720</td>\n",
       "      <td>0.921190</td>\n",
       "      <td>0.927710</td>\n",
       "      <td>-0.006936</td>\n",
       "      <td>40.654053</td>\n",
       "      <td>-97.756970</td>\n",
       "      <td>35.855458</td>\n",
       "      <td>0.938252</td>\n",
       "      <td>0.963402</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>6.166426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>USDJPY=X</td>\n",
       "      <td>134.033997</td>\n",
       "      <td>134.033997</td>\n",
       "      <td>134.188004</td>\n",
       "      <td>132.936005</td>\n",
       "      <td>134.033997</td>\n",
       "      <td>-1.870648</td>\n",
       "      <td>41.564990</td>\n",
       "      <td>-88.398318</td>\n",
       "      <td>29.149269</td>\n",
       "      <td>136.605233</td>\n",
       "      <td>141.392699</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>6.166426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6036 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date       tic   adj close       close        high         low  \\\n",
       "0     2019-01-02  AUDUSD=X    0.704791    0.704791    0.704821    0.698470   \n",
       "1     2019-01-02  EURUSD=X    1.146171    1.146171    1.149700    1.134572   \n",
       "2     2019-01-02  GBPUSD=X    1.275429    1.275429    1.277335    1.258463   \n",
       "3     2019-01-02  USDCAD=X    1.362540    1.362540    1.365960    1.356900   \n",
       "4     2019-01-02  USDCHF=X    0.982000    0.982000    0.989250    0.979400   \n",
       "...          ...       ...         ...         ...         ...         ...   \n",
       "6031  2022-12-29  EURUSD=X    1.062925    1.062925    1.067019    1.061233   \n",
       "6032  2022-12-29  GBPUSD=X    1.202848    1.202848    1.207584    1.201548   \n",
       "6033  2022-12-29  USDCAD=X    1.359940    1.359940    1.360760    1.354450   \n",
       "6034  2022-12-29  USDCHF=X    0.927710    0.927710    0.928720    0.921190   \n",
       "6035  2022-12-29  USDJPY=X  134.033997  134.033997  134.188004  132.936005   \n",
       "\n",
       "            open      macd      rsi_30     cci_30       dx_30  close_30_sma  \\\n",
       "0       0.704722  0.000014  100.000000 -66.666667  100.000000      0.704483   \n",
       "1       1.146132 -0.000070    0.000000 -66.666667  100.000000      1.147739   \n",
       "2       1.275234  0.000036  100.000000 -66.666667  100.000000      1.274617   \n",
       "3       1.362500  0.000518  100.000000  66.666667  100.000000      1.350985   \n",
       "4       0.981800 -0.000034    0.000000  66.666667  100.000000      0.982755   \n",
       "...          ...       ...         ...        ...         ...           ...   \n",
       "6031    1.062925  0.008925   60.167083  78.327051   49.139568      1.050900   \n",
       "6032    1.203297  0.003764   52.732919 -46.930901    3.480165      1.211069   \n",
       "6033    1.359940  0.002138   52.738428  36.079932    8.181686      1.353157   \n",
       "6034    0.927710 -0.006936   40.654053 -97.756970   35.855458      0.938252   \n",
       "6035  134.033997 -1.870648   41.564990 -88.398318   29.149269    136.605233   \n",
       "\n",
       "      close_60_sma        vix  turbulence  \n",
       "0         0.704483  23.219999    0.000000  \n",
       "1         1.147739  23.219999    0.000000  \n",
       "2         1.274617  23.219999    0.000000  \n",
       "3         1.350985  23.219999    0.000000  \n",
       "4         0.982755  23.219999    0.000000  \n",
       "...            ...        ...         ...  \n",
       "6031      1.022255  21.440001    6.166426  \n",
       "6032      1.176042  21.440001    6.166426  \n",
       "6033      1.357071  21.440001    6.166426  \n",
       "6034      0.963402  21.440001    6.166426  \n",
       "6035    141.392699  21.440001    6.166426  \n",
       "\n",
       "[6036 rows x 15 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full.sort_values(['date','tic'],ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-12-29'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full['date'].max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "5TOhcryx44bb"
   },
   "source": [
    "## Training data and Trading data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0qaVGjLtgbI",
    "outputId": "ca8d1a43-ffc3-4fc3-efa9-4de9a9065842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4536\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "# from config.py TRAIN_START_DATE is a string\n",
    "#config.TRAIN_START_DATE\n",
    "train_start_date = datetime.datetime(2019,1,1).strftime('%Y-%m-%d')\n",
    "# from config.py TRAIN_END_DATE is a string\n",
    "train_end_date = datetime.datetime(2022,1,1).strftime('%Y-%m-%d')\n",
    "trade_end_date = datetime.datetime(2023,1,1).strftime('%Y-%m-%d')\n",
    "train = data_split(processed_full, train_start_date ,train_end_date)\n",
    "trade = data_split(processed_full, train_end_date ,trade_end_date)\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "p52zNCOhTtLR",
    "outputId": "b3ad3e10-376f-4186-f875-0331708c5e14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>adj close</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>macd</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>EURUSD=X</td>\n",
       "      <td>1.132503</td>\n",
       "      <td>1.132503</td>\n",
       "      <td>1.137915</td>\n",
       "      <td>1.130506</td>\n",
       "      <td>1.132323</td>\n",
       "      <td>-0.000965</td>\n",
       "      <td>44.911151</td>\n",
       "      <td>109.118753</td>\n",
       "      <td>16.257448</td>\n",
       "      <td>1.129425</td>\n",
       "      <td>1.142246</td>\n",
       "      <td>17.219999</td>\n",
       "      <td>3.822869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>GBPUSD=X</td>\n",
       "      <td>1.349837</td>\n",
       "      <td>1.349837</td>\n",
       "      <td>1.354848</td>\n",
       "      <td>1.346747</td>\n",
       "      <td>1.349892</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>52.327576</td>\n",
       "      <td>171.604444</td>\n",
       "      <td>30.393030</td>\n",
       "      <td>1.332000</td>\n",
       "      <td>1.347087</td>\n",
       "      <td>17.219999</td>\n",
       "      <td>3.822869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>USDCAD=X</td>\n",
       "      <td>1.274440</td>\n",
       "      <td>1.274440</td>\n",
       "      <td>1.275000</td>\n",
       "      <td>1.262680</td>\n",
       "      <td>1.274300</td>\n",
       "      <td>0.003544</td>\n",
       "      <td>52.687505</td>\n",
       "      <td>-70.077708</td>\n",
       "      <td>14.859173</td>\n",
       "      <td>1.277305</td>\n",
       "      <td>1.260555</td>\n",
       "      <td>17.219999</td>\n",
       "      <td>3.822869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>USDCHF=X</td>\n",
       "      <td>0.913700</td>\n",
       "      <td>0.913700</td>\n",
       "      <td>0.914740</td>\n",
       "      <td>0.910470</td>\n",
       "      <td>0.913900</td>\n",
       "      <td>-0.002014</td>\n",
       "      <td>44.964408</td>\n",
       "      <td>-170.194575</td>\n",
       "      <td>37.535785</td>\n",
       "      <td>0.922676</td>\n",
       "      <td>0.921276</td>\n",
       "      <td>17.219999</td>\n",
       "      <td>3.822869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>USDJPY=X</td>\n",
       "      <td>115.063004</td>\n",
       "      <td>115.063004</td>\n",
       "      <td>115.192001</td>\n",
       "      <td>115.004997</td>\n",
       "      <td>115.058998</td>\n",
       "      <td>0.301309</td>\n",
       "      <td>59.394022</td>\n",
       "      <td>120.417399</td>\n",
       "      <td>32.024355</td>\n",
       "      <td>114.023701</td>\n",
       "      <td>113.945000</td>\n",
       "      <td>17.219999</td>\n",
       "      <td>3.822869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date       tic   adj close       close        high         low  \\\n",
       "755  2021-12-31  EURUSD=X    1.132503    1.132503    1.137915    1.130506   \n",
       "755  2021-12-31  GBPUSD=X    1.349837    1.349837    1.354848    1.346747   \n",
       "755  2021-12-31  USDCAD=X    1.274440    1.274440    1.275000    1.262680   \n",
       "755  2021-12-31  USDCHF=X    0.913700    0.913700    0.914740    0.910470   \n",
       "755  2021-12-31  USDJPY=X  115.063004  115.063004  115.192001  115.004997   \n",
       "\n",
       "           open      macd     rsi_30      cci_30      dx_30  close_30_sma  \\\n",
       "755    1.132323 -0.000965  44.911151  109.118753  16.257448      1.129425   \n",
       "755    1.349892  0.002156  52.327576  171.604444  30.393030      1.332000   \n",
       "755    1.274300  0.003544  52.687505  -70.077708  14.859173      1.277305   \n",
       "755    0.913900 -0.002014  44.964408 -170.194575  37.535785      0.922676   \n",
       "755  115.058998  0.301309  59.394022  120.417399  32.024355    114.023701   \n",
       "\n",
       "     close_60_sma        vix  turbulence  \n",
       "755      1.142246  17.219999    3.822869  \n",
       "755      1.347087  17.219999    3.822869  \n",
       "755      1.260555  17.219999    3.822869  \n",
       "755      0.921276  17.219999    3.822869  \n",
       "755    113.945000  17.219999    3.822869  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "k9zU9YaTTvFq",
    "outputId": "72213585-39a3-4bff-c031-874ec0ca06f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>adj close</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>macd</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>EURUSD=X</td>\n",
       "      <td>1.062925</td>\n",
       "      <td>1.062925</td>\n",
       "      <td>1.067019</td>\n",
       "      <td>1.061233</td>\n",
       "      <td>1.062925</td>\n",
       "      <td>0.008925</td>\n",
       "      <td>60.167083</td>\n",
       "      <td>78.327051</td>\n",
       "      <td>49.139568</td>\n",
       "      <td>1.050900</td>\n",
       "      <td>1.022255</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>6.166426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>GBPUSD=X</td>\n",
       "      <td>1.202848</td>\n",
       "      <td>1.202848</td>\n",
       "      <td>1.207584</td>\n",
       "      <td>1.201548</td>\n",
       "      <td>1.203297</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>52.732919</td>\n",
       "      <td>-46.930901</td>\n",
       "      <td>3.480165</td>\n",
       "      <td>1.211069</td>\n",
       "      <td>1.176042</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>6.166426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>USDCAD=X</td>\n",
       "      <td>1.359940</td>\n",
       "      <td>1.359940</td>\n",
       "      <td>1.360760</td>\n",
       "      <td>1.354450</td>\n",
       "      <td>1.359940</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>52.738428</td>\n",
       "      <td>36.079932</td>\n",
       "      <td>8.181686</td>\n",
       "      <td>1.353157</td>\n",
       "      <td>1.357071</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>6.166426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>USDCHF=X</td>\n",
       "      <td>0.927710</td>\n",
       "      <td>0.927710</td>\n",
       "      <td>0.928720</td>\n",
       "      <td>0.921190</td>\n",
       "      <td>0.927710</td>\n",
       "      <td>-0.006936</td>\n",
       "      <td>40.654053</td>\n",
       "      <td>-97.756970</td>\n",
       "      <td>35.855458</td>\n",
       "      <td>0.938252</td>\n",
       "      <td>0.963402</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>6.166426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>USDJPY=X</td>\n",
       "      <td>134.033997</td>\n",
       "      <td>134.033997</td>\n",
       "      <td>134.188004</td>\n",
       "      <td>132.936005</td>\n",
       "      <td>134.033997</td>\n",
       "      <td>-1.870648</td>\n",
       "      <td>41.564990</td>\n",
       "      <td>-88.398318</td>\n",
       "      <td>29.149269</td>\n",
       "      <td>136.605233</td>\n",
       "      <td>141.392699</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>6.166426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date       tic   adj close       close        high         low  \\\n",
       "249  2022-12-29  EURUSD=X    1.062925    1.062925    1.067019    1.061233   \n",
       "249  2022-12-29  GBPUSD=X    1.202848    1.202848    1.207584    1.201548   \n",
       "249  2022-12-29  USDCAD=X    1.359940    1.359940    1.360760    1.354450   \n",
       "249  2022-12-29  USDCHF=X    0.927710    0.927710    0.928720    0.921190   \n",
       "249  2022-12-29  USDJPY=X  134.033997  134.033997  134.188004  132.936005   \n",
       "\n",
       "           open      macd     rsi_30     cci_30      dx_30  close_30_sma  \\\n",
       "249    1.062925  0.008925  60.167083  78.327051  49.139568      1.050900   \n",
       "249    1.203297  0.003764  52.732919 -46.930901   3.480165      1.211069   \n",
       "249    1.359940  0.002138  52.738428  36.079932   8.181686      1.353157   \n",
       "249    0.927710 -0.006936  40.654053 -97.756970  35.855458      0.938252   \n",
       "249  134.033997 -1.870648  41.564990 -88.398318  29.149269    136.605233   \n",
       "\n",
       "     close_60_sma        vix  turbulence  \n",
       "249      1.022255  21.440001    6.166426  \n",
       "249      1.176042  21.440001    6.166426  \n",
       "249      1.357071  21.440001    6.166426  \n",
       "249      0.963402  21.440001    6.166426  \n",
       "249    141.392699  21.440001    6.166426  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "7f228183-abe3-4477-f574-3c9b25c62cd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "1f54d044-e2d3-4a34-c041-e913d686654e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 6, State Space: 49\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + len(config.INDICATORS)*stock_dimension + 2*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "64EoqOrQjiVf"
   },
   "source": [
    "## Environment for Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwSvvPjutpqS",
    "outputId": "deeaef07-afda-4ca1-fea8-99384224c7cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "YDmqOyF9h1iz"
   },
   "source": [
    "### Model Training: 5 models, A2C DDPG, PPO, TD3, SAC\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "uijiWgkuh1jB"
   },
   "source": [
    "### Model 1: A2C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUCnkn-HIbmj",
    "outputId": "a90a7a60-21a5-47e1-b683-1f7cbb4b8bc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "model_a2c.pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0GVpkWGqH4-D",
    "outputId": "570d540f-abe9-402b-e0cc-f9b007228e8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 58          |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 8           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -96.5       |\n",
      "|    explained_variance | -52.8       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -16.7       |\n",
      "|    reward             | 0.044553936 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.0917      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 69           |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -97.4        |\n",
      "|    explained_variance | -9.89        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | 3.2          |\n",
      "|    reward             | -0.015797459 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 0.00661      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 21         |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -98        |\n",
      "|    explained_variance | -4.21      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | 5.7        |\n",
      "|    reward             | 0.01450776 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.0173     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 73          |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -98.7       |\n",
      "|    explained_variance | -51.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -1.55       |\n",
      "|    reward             | -0.10984398 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.0376      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 75          |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 33          |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -99.3       |\n",
      "|    explained_variance | -3.75       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | 21.5        |\n",
      "|    reward             | -0.02329195 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.0704      |\n",
      "---------------------------------------\n",
      "day: 325, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 997125.73\n",
      "total_reward: -2874.27\n",
      "total_cost: 14981.98\n",
      "total_trades: 17064\n",
      "Sharpe: -0.149\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 77         |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 38         |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -100       |\n",
      "|    explained_variance | -0.895     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | 6.88       |\n",
      "|    reward             | 0.09444232 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.00818    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 78          |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 44          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -101        |\n",
      "|    explained_variance | -0.00131    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | -28         |\n",
      "|    reward             | -0.12089544 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.0764      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -102        |\n",
      "|    explained_variance | 0.0122      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 19.3        |\n",
      "|    reward             | 0.057961393 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 0.0612      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 56          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -103        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -0.609      |\n",
      "|    reward             | -0.05697777 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 0.000473    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 79            |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 63            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -104          |\n",
      "|    explained_variance | -1.09         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | 15.4          |\n",
      "|    reward             | -0.0060025565 |\n",
      "|    std                | 1.14          |\n",
      "|    value_loss         | 0.0281        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 78          |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 69          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -105        |\n",
      "|    explained_variance | -0.569      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | 0.417       |\n",
      "|    reward             | 0.048435513 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 0.000814    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 78         |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 76         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -106       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | 7.17       |\n",
      "|    reward             | 0.08244916 |\n",
      "|    std                | 1.17       |\n",
      "|    value_loss         | 0.0208     |\n",
      "--------------------------------------\n",
      "day: 325, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1001062.14\n",
      "total_reward: 1062.14\n",
      "total_cost: 9043.68\n",
      "total_trades: 14910\n",
      "Sharpe: 0.070\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 78          |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -106        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | 1.75        |\n",
      "|    reward             | 0.058699276 |\n",
      "|    std                | 1.19        |\n",
      "|    value_loss         | 0.00114     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 78          |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -107        |\n",
      "|    explained_variance | 0.000685    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 17.6        |\n",
      "|    reward             | 0.003506949 |\n",
      "|    std                | 1.2         |\n",
      "|    value_loss         | 0.0311      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 78           |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 94           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -108         |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.223       |\n",
      "|    reward             | 0.0011988588 |\n",
      "|    std                | 1.22         |\n",
      "|    value_loss         | 0.000432     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 78         |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 101        |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -109       |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | -30        |\n",
      "|    reward             | 0.08882735 |\n",
      "|    std                | 1.24       |\n",
      "|    value_loss         | 0.0849     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 79         |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 107        |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -110       |\n",
      "|    explained_variance | -1.75      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | 15.2       |\n",
      "|    reward             | 0.07436467 |\n",
      "|    std                | 1.25       |\n",
      "|    value_loss         | 0.0257     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 78           |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 114          |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -111         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.00714      |\n",
      "|    reward             | -0.039154794 |\n",
      "|    std                | 1.27         |\n",
      "|    value_loss         | 0.00137      |\n",
      "----------------------------------------\n",
      "day: 325, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000650.74\n",
      "total_reward: 650.74\n",
      "total_cost: 8004.09\n",
      "total_trades: 14055\n",
      "Sharpe: 0.040\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 78          |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 121         |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -112        |\n",
      "|    explained_variance | 0.0193      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | 11.5        |\n",
      "|    reward             | 0.085746616 |\n",
      "|    std                | 1.28        |\n",
      "|    value_loss         | 0.0119      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 78           |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -112         |\n",
      "|    explained_variance | 0.57         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | 14.2         |\n",
      "|    reward             | -0.021977013 |\n",
      "|    std                | 1.3          |\n",
      "|    value_loss         | 0.0187       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 77           |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 134          |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -113         |\n",
      "|    explained_variance | -0.886       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2099         |\n",
      "|    policy_loss        | 4.88         |\n",
      "|    reward             | -0.028431328 |\n",
      "|    std                | 1.31         |\n",
      "|    value_loss         | 0.0138       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 78           |\n",
      "|    iterations         | 2200         |\n",
      "|    time_elapsed       | 140          |\n",
      "|    total_timesteps    | 11000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -114         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2199         |\n",
      "|    policy_loss        | -1.55        |\n",
      "|    reward             | -0.066542126 |\n",
      "|    std                | 1.32         |\n",
      "|    value_loss         | 0.00226      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 78          |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -114        |\n",
      "|    explained_variance | 0.21        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2299        |\n",
      "|    policy_loss        | 12.4        |\n",
      "|    reward             | -0.09345006 |\n",
      "|    std                | 1.34        |\n",
      "|    value_loss         | 0.018       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 78            |\n",
      "|    iterations         | 2400          |\n",
      "|    time_elapsed       | 151           |\n",
      "|    total_timesteps    | 12000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -115          |\n",
      "|    explained_variance | -0.493        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2399          |\n",
      "|    policy_loss        | -2.24         |\n",
      "|    reward             | -0.0030777536 |\n",
      "|    std                | 1.35          |\n",
      "|    value_loss         | 0.00227       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 2500        |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 12500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -116        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2499        |\n",
      "|    policy_loss        | 8.36        |\n",
      "|    reward             | 0.026250772 |\n",
      "|    std                | 1.37        |\n",
      "|    value_loss         | 0.00864     |\n",
      "---------------------------------------\n",
      "day: 325, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1005846.42\n",
      "total_reward: 5846.42\n",
      "total_cost: 6409.88\n",
      "total_trades: 13706\n",
      "Sharpe: 0.279\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 79         |\n",
      "|    iterations         | 2600       |\n",
      "|    time_elapsed       | 164        |\n",
      "|    total_timesteps    | 13000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -117       |\n",
      "|    explained_variance | 0.255      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2599       |\n",
      "|    policy_loss        | 3.96       |\n",
      "|    reward             | 0.09710817 |\n",
      "|    std                | 1.38       |\n",
      "|    value_loss         | 0.00135    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 79           |\n",
      "|    iterations         | 2700         |\n",
      "|    time_elapsed       | 170          |\n",
      "|    total_timesteps    | 13500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -118         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2699         |\n",
      "|    policy_loss        | 20.1         |\n",
      "|    reward             | -0.014896936 |\n",
      "|    std                | 1.4          |\n",
      "|    value_loss         | 0.0408       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 79         |\n",
      "|    iterations         | 2800       |\n",
      "|    time_elapsed       | 175        |\n",
      "|    total_timesteps    | 14000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -118       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2799       |\n",
      "|    policy_loss        | -4.09      |\n",
      "|    reward             | 0.09568252 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 0.0014     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 2900        |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 14500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -119        |\n",
      "|    explained_variance | 0.377       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2899        |\n",
      "|    policy_loss        | -14.2       |\n",
      "|    reward             | -0.07864827 |\n",
      "|    std                | 1.43        |\n",
      "|    value_loss         | 0.0173      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 3000        |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 15000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -120        |\n",
      "|    explained_variance | -1.4        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2999        |\n",
      "|    policy_loss        | -15.5       |\n",
      "|    reward             | -0.06088617 |\n",
      "|    std                | 1.45        |\n",
      "|    value_loss         | 0.0292      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 79           |\n",
      "|    iterations         | 3100         |\n",
      "|    time_elapsed       | 194          |\n",
      "|    total_timesteps    | 15500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -121         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3099         |\n",
      "|    policy_loss        | -18.8        |\n",
      "|    reward             | -0.016993023 |\n",
      "|    std                | 1.47         |\n",
      "|    value_loss         | 0.0504       |\n",
      "----------------------------------------\n",
      "day: 325, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 996928.75\n",
      "total_reward: -3071.25\n",
      "total_cost: 8902.68\n",
      "total_trades: 13935\n",
      "Sharpe: -0.122\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 79           |\n",
      "|    iterations         | 3200         |\n",
      "|    time_elapsed       | 200          |\n",
      "|    total_timesteps    | 16000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -121         |\n",
      "|    explained_variance | 0.263        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3199         |\n",
      "|    policy_loss        | 0.4          |\n",
      "|    reward             | -0.092677295 |\n",
      "|    std                | 1.48         |\n",
      "|    value_loss         | 0.00187      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 207       |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -122      |\n",
      "|    explained_variance | 0.395     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 16.6      |\n",
      "|    reward             | 0.1896723 |\n",
      "|    std                | 1.5       |\n",
      "|    value_loss         | 0.0232    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -123        |\n",
      "|    explained_variance | 0.753       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3399        |\n",
      "|    policy_loss        | 22.1        |\n",
      "|    reward             | -0.07774133 |\n",
      "|    std                | 1.52        |\n",
      "|    value_loss         | 0.0334      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 3500        |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 17500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -124        |\n",
      "|    explained_variance | 0.0553      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3499        |\n",
      "|    policy_loss        | 42.3        |\n",
      "|    reward             | 0.055191994 |\n",
      "|    std                | 1.54        |\n",
      "|    value_loss         | 0.131       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 80          |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -125        |\n",
      "|    explained_variance | -7.65       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | -26.1       |\n",
      "|    reward             | -0.06462753 |\n",
      "|    std                | 1.56        |\n",
      "|    value_loss         | 0.0583      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 80           |\n",
      "|    iterations         | 3700         |\n",
      "|    time_elapsed       | 230          |\n",
      "|    total_timesteps    | 18500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -126         |\n",
      "|    explained_variance | 0.000239     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3699         |\n",
      "|    policy_loss        | -10.2        |\n",
      "|    reward             | -0.015423859 |\n",
      "|    std                | 1.58         |\n",
      "|    value_loss         | 0.00762      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 3800       |\n",
      "|    time_elapsed       | 237        |\n",
      "|    total_timesteps    | 19000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -127       |\n",
      "|    explained_variance | 3.58e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3799       |\n",
      "|    policy_loss        | -1.6       |\n",
      "|    reward             | 0.09261574 |\n",
      "|    std                | 1.6        |\n",
      "|    value_loss         | 0.00437    |\n",
      "--------------------------------------\n",
      "day: 325, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1009951.96\n",
      "total_reward: 9951.96\n",
      "total_cost: 6110.00\n",
      "total_trades: 13919\n",
      "Sharpe: 0.578\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 243        |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -128       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | 3.87       |\n",
      "|    reward             | 0.02725004 |\n",
      "|    std                | 1.63       |\n",
      "|    value_loss         | 0.00172    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 4000       |\n",
      "|    time_elapsed       | 249        |\n",
      "|    total_timesteps    | 20000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -128       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3999       |\n",
      "|    policy_loss        | -5.52      |\n",
      "|    reward             | 0.12782644 |\n",
      "|    std                | 1.65       |\n",
      "|    value_loss         | 0.00199    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 80          |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -129        |\n",
      "|    explained_variance | -1.57       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | -9.7        |\n",
      "|    reward             | -0.01622392 |\n",
      "|    std                | 1.67        |\n",
      "|    value_loss         | 0.0083      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 4200       |\n",
      "|    time_elapsed       | 261        |\n",
      "|    total_timesteps    | 21000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -130       |\n",
      "|    explained_variance | -0.0566    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4199       |\n",
      "|    policy_loss        | -10.4      |\n",
      "|    reward             | 0.08525824 |\n",
      "|    std                | 1.69       |\n",
      "|    value_loss         | 0.00886    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 80           |\n",
      "|    iterations         | 4300         |\n",
      "|    time_elapsed       | 267          |\n",
      "|    total_timesteps    | 21500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -131         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4299         |\n",
      "|    policy_loss        | -1.2         |\n",
      "|    reward             | -0.063264504 |\n",
      "|    std                | 1.71         |\n",
      "|    value_loss         | 0.00071      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 80          |\n",
      "|    iterations         | 4400        |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 22000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -132        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4399        |\n",
      "|    policy_loss        | 2.76        |\n",
      "|    reward             | -0.06586589 |\n",
      "|    std                | 1.73        |\n",
      "|    value_loss         | 0.00622     |\n",
      "---------------------------------------\n",
      "day: 325, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1006461.44\n",
      "total_reward: 6461.44\n",
      "total_cost: 8401.39\n",
      "total_trades: 13832\n",
      "Sharpe: 0.350\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 280        |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -133       |\n",
      "|    explained_variance | -0.894     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4499       |\n",
      "|    policy_loss        | -35        |\n",
      "|    reward             | -0.0704834 |\n",
      "|    std                | 1.75       |\n",
      "|    value_loss         | 0.0971     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 80           |\n",
      "|    iterations         | 4600         |\n",
      "|    time_elapsed       | 287          |\n",
      "|    total_timesteps    | 23000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -133         |\n",
      "|    explained_variance | -0.0995      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4599         |\n",
      "|    policy_loss        | -13.6        |\n",
      "|    reward             | -0.063179575 |\n",
      "|    std                | 1.77         |\n",
      "|    value_loss         | 0.0191       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 80            |\n",
      "|    iterations         | 4700          |\n",
      "|    time_elapsed       | 293           |\n",
      "|    total_timesteps    | 23500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -134          |\n",
      "|    explained_variance | -239          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4699          |\n",
      "|    policy_loss        | 67.1          |\n",
      "|    reward             | -0.0028111953 |\n",
      "|    std                | 1.79          |\n",
      "|    value_loss         | 0.314         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 80          |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 299         |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -135        |\n",
      "|    explained_variance | 0.253       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | 23.7        |\n",
      "|    reward             | 0.002634839 |\n",
      "|    std                | 1.82        |\n",
      "|    value_loss         | 0.0326      |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 305      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -136     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 14.8     |\n",
      "|    reward             | -0.44721 |\n",
      "|    std                | 1.84     |\n",
      "|    value_loss         | 0.0248   |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 5000       |\n",
      "|    time_elapsed       | 312        |\n",
      "|    total_timesteps    | 25000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -137       |\n",
      "|    explained_variance | 0.0648     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4999       |\n",
      "|    policy_loss        | 6.56       |\n",
      "|    reward             | 0.06591305 |\n",
      "|    std                | 1.86       |\n",
      "|    value_loss         | 0.0188     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 5100       |\n",
      "|    time_elapsed       | 318        |\n",
      "|    total_timesteps    | 25500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -138       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5099       |\n",
      "|    policy_loss        | -35.6      |\n",
      "|    reward             | 0.23811533 |\n",
      "|    std                | 1.89       |\n",
      "|    value_loss         | 0.0754     |\n",
      "--------------------------------------\n",
      "day: 325, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 998124.33\n",
      "total_reward: -1875.67\n",
      "total_cost: 7503.01\n",
      "total_trades: 14475\n",
      "Sharpe: -0.084\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 80        |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 324       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -138      |\n",
      "|    explained_variance | 0.258     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | 10.3      |\n",
      "|    reward             | 0.0854351 |\n",
      "|    std                | 1.91      |\n",
      "|    value_loss         | 0.0161    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 79           |\n",
      "|    iterations         | 5300         |\n",
      "|    time_elapsed       | 332          |\n",
      "|    total_timesteps    | 26500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -139         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5299         |\n",
      "|    policy_loss        | 3.36         |\n",
      "|    reward             | -0.034995917 |\n",
      "|    std                | 1.94         |\n",
      "|    value_loss         | 0.0012       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -140        |\n",
      "|    explained_variance | 0.0977      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | -6.47       |\n",
      "|    reward             | -0.14480287 |\n",
      "|    std                | 1.96        |\n",
      "|    value_loss         | 0.00265     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 79         |\n",
      "|    iterations         | 5500       |\n",
      "|    time_elapsed       | 345        |\n",
      "|    total_timesteps    | 27500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -141       |\n",
      "|    explained_variance | -0.542     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5499       |\n",
      "|    policy_loss        | 0.356      |\n",
      "|    reward             | -0.3527186 |\n",
      "|    std                | 1.98       |\n",
      "|    value_loss         | 0.00103    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 79         |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 352        |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -142       |\n",
      "|    explained_variance | -0.287     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5599       |\n",
      "|    policy_loss        | -17        |\n",
      "|    reward             | 0.02866846 |\n",
      "|    std                | 2          |\n",
      "|    value_loss         | 0.0183     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 358         |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -142        |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5699        |\n",
      "|    policy_loss        | -0.969      |\n",
      "|    reward             | 0.012986316 |\n",
      "|    std                | 2.03        |\n",
      "|    value_loss         | 0.00195     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 79         |\n",
      "|    iterations         | 5800       |\n",
      "|    time_elapsed       | 365        |\n",
      "|    total_timesteps    | 29000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -143       |\n",
      "|    explained_variance | 0.121      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5799       |\n",
      "|    policy_loss        | -13.3      |\n",
      "|    reward             | 0.11760746 |\n",
      "|    std                | 2.05       |\n",
      "|    value_loss         | 0.00853    |\n",
      "--------------------------------------\n",
      "day: 325, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 997293.17\n",
      "total_reward: -2706.83\n",
      "total_cost: 7881.25\n",
      "total_trades: 14579\n",
      "Sharpe: -0.120\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 79           |\n",
      "|    iterations         | 5900         |\n",
      "|    time_elapsed       | 371          |\n",
      "|    total_timesteps    | 29500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -144         |\n",
      "|    explained_variance | 0.00623      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5899         |\n",
      "|    policy_loss        | -7.15        |\n",
      "|    reward             | -0.020696951 |\n",
      "|    std                | 2.07         |\n",
      "|    value_loss         | 0.00688      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 6000        |\n",
      "|    time_elapsed       | 377         |\n",
      "|    total_timesteps    | 30000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -145        |\n",
      "|    explained_variance | 0.837       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5999        |\n",
      "|    policy_loss        | -6.48       |\n",
      "|    reward             | -0.14656143 |\n",
      "|    std                | 2.1         |\n",
      "|    value_loss         | 0.00328     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 384       |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -145      |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | 41.1      |\n",
      "|    reward             | 0.0618338 |\n",
      "|    std                | 2.13      |\n",
      "|    value_loss         | 0.0828    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 390         |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -146        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6199        |\n",
      "|    policy_loss        | 121         |\n",
      "|    reward             | 0.031480942 |\n",
      "|    std                | 2.15        |\n",
      "|    value_loss         | 0.708       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 397         |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -147        |\n",
      "|    explained_variance | 0.0472      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6299        |\n",
      "|    policy_loss        | 8.02        |\n",
      "|    reward             | -0.06042169 |\n",
      "|    std                | 2.18        |\n",
      "|    value_loss         | 0.00938     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 403       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -148      |\n",
      "|    explained_variance | 0.000239  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 9.33      |\n",
      "|    reward             | 0.1208408 |\n",
      "|    std                | 2.2       |\n",
      "|    value_loss         | 0.00894   |\n",
      "-------------------------------------\n",
      "day: 325, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999030.39\n",
      "total_reward: -969.61\n",
      "total_cost: 7880.40\n",
      "total_trades: 13898\n",
      "Sharpe: -0.042\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 6500        |\n",
      "|    time_elapsed       | 410         |\n",
      "|    total_timesteps    | 32500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -149        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6499        |\n",
      "|    policy_loss        | -21         |\n",
      "|    reward             | -0.17246264 |\n",
      "|    std                | 2.23        |\n",
      "|    value_loss         | 0.0226      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 417         |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -149        |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | -11.2       |\n",
      "|    reward             | -0.22344671 |\n",
      "|    std                | 2.25        |\n",
      "|    value_loss         | 0.0217      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 78         |\n",
      "|    iterations         | 6700       |\n",
      "|    time_elapsed       | 425        |\n",
      "|    total_timesteps    | 33500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -150       |\n",
      "|    explained_variance | -0.00827   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6699       |\n",
      "|    policy_loss        | 15.8       |\n",
      "|    reward             | 0.18044727 |\n",
      "|    std                | 2.28       |\n",
      "|    value_loss         | 0.0227     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 78          |\n",
      "|    iterations         | 6800        |\n",
      "|    time_elapsed       | 431         |\n",
      "|    total_timesteps    | 34000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -151        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6799        |\n",
      "|    policy_loss        | -8.27       |\n",
      "|    reward             | -0.11957112 |\n",
      "|    std                | 2.31        |\n",
      "|    value_loss         | 0.00449     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 78           |\n",
      "|    iterations         | 6900         |\n",
      "|    time_elapsed       | 437          |\n",
      "|    total_timesteps    | 34500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -152         |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6899         |\n",
      "|    policy_loss        | 13.6         |\n",
      "|    reward             | 0.0025138045 |\n",
      "|    std                | 2.34         |\n",
      "|    value_loss         | 0.00866      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 78          |\n",
      "|    iterations         | 7000        |\n",
      "|    time_elapsed       | 443         |\n",
      "|    total_timesteps    | 35000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -153        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6999        |\n",
      "|    policy_loss        | -5.35       |\n",
      "|    reward             | -0.10785075 |\n",
      "|    std                | 2.37        |\n",
      "|    value_loss         | 0.00199     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 7100        |\n",
      "|    time_elapsed       | 448         |\n",
      "|    total_timesteps    | 35500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -154        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7099        |\n",
      "|    policy_loss        | 7.95        |\n",
      "|    reward             | 0.018192958 |\n",
      "|    std                | 2.4         |\n",
      "|    value_loss         | 0.00419     |\n",
      "---------------------------------------\n",
      "day: 325, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 997816.32\n",
      "total_reward: -2183.68\n",
      "total_cost: 7703.39\n",
      "total_trades: 13708\n",
      "Sharpe: -0.115\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 454         |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -154        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7199        |\n",
      "|    policy_loss        | -11.6       |\n",
      "|    reward             | 0.054953314 |\n",
      "|    std                | 2.43        |\n",
      "|    value_loss         | 0.00677     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 79         |\n",
      "|    iterations         | 7300       |\n",
      "|    time_elapsed       | 460        |\n",
      "|    total_timesteps    | 36500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -155       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7299       |\n",
      "|    policy_loss        | 2.44       |\n",
      "|    reward             | 0.10644107 |\n",
      "|    std                | 2.47       |\n",
      "|    value_loss         | 0.000922   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 79           |\n",
      "|    iterations         | 7400         |\n",
      "|    time_elapsed       | 466          |\n",
      "|    total_timesteps    | 37000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -156         |\n",
      "|    explained_variance | 0.0929       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7399         |\n",
      "|    policy_loss        | -14.1        |\n",
      "|    reward             | -0.022051882 |\n",
      "|    std                | 2.5          |\n",
      "|    value_loss         | 0.00882      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 79           |\n",
      "|    iterations         | 7500         |\n",
      "|    time_elapsed       | 472          |\n",
      "|    total_timesteps    | 37500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -157         |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7499         |\n",
      "|    policy_loss        | -8.62        |\n",
      "|    reward             | -0.006015171 |\n",
      "|    std                | 2.54         |\n",
      "|    value_loss         | 0.0052       |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 479       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -158      |\n",
      "|    explained_variance | -0.478    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | 17.4      |\n",
      "|    reward             | 0.0540547 |\n",
      "|    std                | 2.57      |\n",
      "|    value_loss         | 0.0169    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 79           |\n",
      "|    iterations         | 7700         |\n",
      "|    time_elapsed       | 485          |\n",
      "|    total_timesteps    | 38500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -159         |\n",
      "|    explained_variance | -0.0659      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7699         |\n",
      "|    policy_loss        | 8.58         |\n",
      "|    reward             | -0.005875446 |\n",
      "|    std                | 2.61         |\n",
      "|    value_loss         | 0.0147       |\n",
      "----------------------------------------\n",
      "day: 325, episode: 120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1005201.07\n",
      "total_reward: 5201.07\n",
      "total_cost: 7400.16\n",
      "total_trades: 13231\n",
      "Sharpe: 0.326\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 7800        |\n",
      "|    time_elapsed       | 491         |\n",
      "|    total_timesteps    | 39000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -160        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7799        |\n",
      "|    policy_loss        | -1.46       |\n",
      "|    reward             | 0.024679447 |\n",
      "|    std                | 2.64        |\n",
      "|    value_loss         | 0.00173     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 79         |\n",
      "|    iterations         | 7900       |\n",
      "|    time_elapsed       | 496        |\n",
      "|    total_timesteps    | 39500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -161       |\n",
      "|    explained_variance | -0.0668    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7899       |\n",
      "|    policy_loss        | -59        |\n",
      "|    reward             | -0.1057444 |\n",
      "|    std                | 2.68       |\n",
      "|    value_loss         | 0.134      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 502         |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -162        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7999        |\n",
      "|    policy_loss        | -2.76       |\n",
      "|    reward             | 0.074616134 |\n",
      "|    std                | 2.72        |\n",
      "|    value_loss         | 0.000674    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 508         |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -163        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8099        |\n",
      "|    policy_loss        | -28.6       |\n",
      "|    reward             | -0.09276098 |\n",
      "|    std                | 2.76        |\n",
      "|    value_loss         | 0.044       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 8200        |\n",
      "|    time_elapsed       | 513         |\n",
      "|    total_timesteps    | 41000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -164        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8199        |\n",
      "|    policy_loss        | 2.91        |\n",
      "|    reward             | -0.02269935 |\n",
      "|    std                | 2.79        |\n",
      "|    value_loss         | 0.00809     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 8300        |\n",
      "|    time_elapsed       | 519         |\n",
      "|    total_timesteps    | 41500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -165        |\n",
      "|    explained_variance | -0.802      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8299        |\n",
      "|    policy_loss        | 17.6        |\n",
      "|    reward             | 0.017249057 |\n",
      "|    std                | 2.83        |\n",
      "|    value_loss         | 0.0177      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 79         |\n",
      "|    iterations         | 8400       |\n",
      "|    time_elapsed       | 525        |\n",
      "|    total_timesteps    | 42000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -165       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8399       |\n",
      "|    policy_loss        | 20.5       |\n",
      "|    reward             | 0.01790307 |\n",
      "|    std                | 2.86       |\n",
      "|    value_loss         | 0.016      |\n",
      "--------------------------------------\n",
      "day: 325, episode: 130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999935.90\n",
      "total_reward: -64.10\n",
      "total_cost: 8020.77\n",
      "total_trades: 12957\n",
      "Sharpe: 0.005\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 79         |\n",
      "|    iterations         | 8500       |\n",
      "|    time_elapsed       | 531        |\n",
      "|    total_timesteps    | 42500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -166       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8499       |\n",
      "|    policy_loss        | 16.3       |\n",
      "|    reward             | 0.03369065 |\n",
      "|    std                | 2.89       |\n",
      "|    value_loss         | 0.012      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 537        |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -167       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | 58.5       |\n",
      "|    reward             | 0.07048566 |\n",
      "|    std                | 2.92       |\n",
      "|    value_loss         | 0.129      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 80           |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 542          |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -168         |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8699         |\n",
      "|    policy_loss        | 10.1         |\n",
      "|    reward             | -0.009022867 |\n",
      "|    std                | 2.96         |\n",
      "|    value_loss         | 0.00446      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 80          |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 549         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -168        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | -10         |\n",
      "|    reward             | -0.16628057 |\n",
      "|    std                | 2.99        |\n",
      "|    value_loss         | 0.00558     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 8900       |\n",
      "|    time_elapsed       | 555        |\n",
      "|    total_timesteps    | 44500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -169       |\n",
      "|    explained_variance | 0.159      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8899       |\n",
      "|    policy_loss        | -17.6      |\n",
      "|    reward             | 0.03691724 |\n",
      "|    std                | 3.03       |\n",
      "|    value_loss         | 0.0161     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 80          |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 560         |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -170        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8999        |\n",
      "|    policy_loss        | -8.59       |\n",
      "|    reward             | 0.024818545 |\n",
      "|    std                | 3.07        |\n",
      "|    value_loss         | 0.00409     |\n",
      "---------------------------------------\n",
      "day: 325, episode: 140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1004351.92\n",
      "total_reward: 4351.92\n",
      "total_cost: 6894.43\n",
      "total_trades: 12557\n",
      "Sharpe: 0.225\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 9100       |\n",
      "|    time_elapsed       | 566        |\n",
      "|    total_timesteps    | 45500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -171       |\n",
      "|    explained_variance | 0.00334    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9099       |\n",
      "|    policy_loss        | -5.96      |\n",
      "|    reward             | 0.11579938 |\n",
      "|    std                | 3.1        |\n",
      "|    value_loss         | 0.00194    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 80           |\n",
      "|    iterations         | 9200         |\n",
      "|    time_elapsed       | 573          |\n",
      "|    total_timesteps    | 46000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -171         |\n",
      "|    explained_variance | -0.265       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9199         |\n",
      "|    policy_loss        | 1.86         |\n",
      "|    reward             | -0.011156072 |\n",
      "|    std                | 3.13         |\n",
      "|    value_loss         | 0.00647      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 9300       |\n",
      "|    time_elapsed       | 578        |\n",
      "|    total_timesteps    | 46500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -172       |\n",
      "|    explained_variance | -0.00572   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9299       |\n",
      "|    policy_loss        | 8.06       |\n",
      "|    reward             | 0.07710647 |\n",
      "|    std                | 3.18       |\n",
      "|    value_loss         | 0.00636    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 80          |\n",
      "|    iterations         | 9400        |\n",
      "|    time_elapsed       | 583         |\n",
      "|    total_timesteps    | 47000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -173        |\n",
      "|    explained_variance | -0.404      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9399        |\n",
      "|    policy_loss        | -65.5       |\n",
      "|    reward             | 0.061751492 |\n",
      "|    std                | 3.21        |\n",
      "|    value_loss         | 0.176       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 80           |\n",
      "|    iterations         | 9500         |\n",
      "|    time_elapsed       | 589          |\n",
      "|    total_timesteps    | 47500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -174         |\n",
      "|    explained_variance | -3.58e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9499         |\n",
      "|    policy_loss        | 11.2         |\n",
      "|    reward             | -0.015867148 |\n",
      "|    std                | 3.25         |\n",
      "|    value_loss         | 0.00697      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 80           |\n",
      "|    iterations         | 9600         |\n",
      "|    time_elapsed       | 596          |\n",
      "|    total_timesteps    | 48000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -175         |\n",
      "|    explained_variance | -0.173       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9599         |\n",
      "|    policy_loss        | 19.1         |\n",
      "|    reward             | -0.043441076 |\n",
      "|    std                | 3.29         |\n",
      "|    value_loss         | 0.0206       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 80          |\n",
      "|    iterations         | 9700        |\n",
      "|    time_elapsed       | 603         |\n",
      "|    total_timesteps    | 48500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -176        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9699        |\n",
      "|    policy_loss        | -18.5       |\n",
      "|    reward             | 0.008588206 |\n",
      "|    std                | 3.33        |\n",
      "|    value_loss         | 0.0139      |\n",
      "---------------------------------------\n",
      "day: 325, episode: 150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1001651.66\n",
      "total_reward: 1651.66\n",
      "total_cost: 8699.30\n",
      "total_trades: 13079\n",
      "Sharpe: 0.093\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 80          |\n",
      "|    iterations         | 9800        |\n",
      "|    time_elapsed       | 609         |\n",
      "|    total_timesteps    | 49000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -176        |\n",
      "|    explained_variance | -0.266      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9799        |\n",
      "|    policy_loss        | 30.9        |\n",
      "|    reward             | -0.19544636 |\n",
      "|    std                | 3.37        |\n",
      "|    value_loss         | 0.0316      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 80          |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 618         |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -177        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | -22.1       |\n",
      "|    reward             | -0.09898668 |\n",
      "|    std                | 3.41        |\n",
      "|    value_loss         | 0.0188      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 80          |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 624         |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -178        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9999        |\n",
      "|    policy_loss        | -49.3       |\n",
      "|    reward             | -0.03631921 |\n",
      "|    std                | 3.45        |\n",
      "|    value_loss         | 0.0913      |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_name = 'a2c_'\n",
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=50000)\n",
    "trained_a2c.save(os.path.join(TRAINED_MODEL_DIR, model_name + \".pth\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "MRiOtrywfAo1"
   },
   "source": [
    "### Model 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "M2YadjfnLwgt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 50, 'learning_rate': 0.0025}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.utils import get_schedule_fn\n",
    "agent = DRLAgent(env = env_train)\n",
    "DDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50, \"learning_rate\": 0.0025}\n",
    "model_ddpg = agent.get_model(\"ddpg\",model_kwargs= DDPG_PARAMS,  tensorboard_log = TENSORBOARD_LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "tCDa78rqfO_a",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to MARKETS/ForexMarket/TENSORBOARD_LOG_DIR/ddpg_3\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 16        |\n",
      "|    total_timesteps | 3024      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -88.2     |\n",
      "|    critic_loss     | 22.3      |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 2268      |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 196       |\n",
      "|    time_elapsed    | 30        |\n",
      "|    total_timesteps | 6048      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -51       |\n",
      "|    critic_loss     | 19.8      |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 5292      |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 200       |\n",
      "|    time_elapsed    | 45        |\n",
      "|    total_timesteps | 9072      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -24       |\n",
      "|    critic_loss     | 1.21      |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 8316      |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 200       |\n",
      "|    time_elapsed    | 60        |\n",
      "|    total_timesteps | 12096     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -6.15     |\n",
      "|    critic_loss     | 0.572     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 11340     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 200       |\n",
      "|    time_elapsed    | 75        |\n",
      "|    total_timesteps | 15120     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.24     |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 14364     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 200       |\n",
      "|    time_elapsed    | 90        |\n",
      "|    total_timesteps | 18144     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.972    |\n",
      "|    critic_loss     | 0.109     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 17388     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 28        |\n",
      "|    fps             | 200       |\n",
      "|    time_elapsed    | 105       |\n",
      "|    total_timesteps | 21168     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -4.18     |\n",
      "|    critic_loss     | 0.212     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 20412     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 32        |\n",
      "|    fps             | 199       |\n",
      "|    time_elapsed    | 121       |\n",
      "|    total_timesteps | 24192     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -2.17     |\n",
      "|    critic_loss     | 0.116     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 23436     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 36        |\n",
      "|    fps             | 198       |\n",
      "|    time_elapsed    | 136       |\n",
      "|    total_timesteps | 27216     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.46     |\n",
      "|    critic_loss     | 0.0123    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 26460     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 40        |\n",
      "|    fps             | 198       |\n",
      "|    time_elapsed    | 152       |\n",
      "|    total_timesteps | 30240     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.18     |\n",
      "|    critic_loss     | 0.00662   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 29484     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 44        |\n",
      "|    fps             | 198       |\n",
      "|    time_elapsed    | 167       |\n",
      "|    total_timesteps | 33264     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.814    |\n",
      "|    critic_loss     | 0.00192   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 32508     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 48        |\n",
      "|    fps             | 195       |\n",
      "|    time_elapsed    | 185       |\n",
      "|    total_timesteps | 36288     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.889    |\n",
      "|    critic_loss     | 0.0207    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 35532     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 52        |\n",
      "|    fps             | 194       |\n",
      "|    time_elapsed    | 202       |\n",
      "|    total_timesteps | 39312     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.962    |\n",
      "|    critic_loss     | 0.00103   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 38556     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 56        |\n",
      "|    fps             | 192       |\n",
      "|    time_elapsed    | 219       |\n",
      "|    total_timesteps | 42336     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.978    |\n",
      "|    critic_loss     | 0.00151   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 41580     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 60        |\n",
      "|    fps             | 192       |\n",
      "|    time_elapsed    | 236       |\n",
      "|    total_timesteps | 45360     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.954    |\n",
      "|    critic_loss     | 0.00124   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 44604     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 64        |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 253       |\n",
      "|    total_timesteps | 48384     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.904    |\n",
      "|    critic_loss     | 0.00129   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 47628     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 68        |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 268       |\n",
      "|    total_timesteps | 51408     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.878    |\n",
      "|    critic_loss     | 0.00105   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 50652     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 72        |\n",
      "|    fps             | 192       |\n",
      "|    time_elapsed    | 283       |\n",
      "|    total_timesteps | 54432     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.889    |\n",
      "|    critic_loss     | 0.000129  |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 53676     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 76        |\n",
      "|    fps             | 192       |\n",
      "|    time_elapsed    | 298       |\n",
      "|    total_timesteps | 57456     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.904    |\n",
      "|    critic_loss     | 0.000565  |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 56700     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 80        |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 315       |\n",
      "|    total_timesteps | 60480     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.89     |\n",
      "|    critic_loss     | 0.000893  |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 59724     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 84        |\n",
      "|    fps             | 192       |\n",
      "|    time_elapsed    | 330       |\n",
      "|    total_timesteps | 63504     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.94     |\n",
      "|    critic_loss     | 0.0239    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 62748     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 88        |\n",
      "|    fps             | 192       |\n",
      "|    time_elapsed    | 345       |\n",
      "|    total_timesteps | 66528     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.08     |\n",
      "|    critic_loss     | 0.0328    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 65772     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 92        |\n",
      "|    fps             | 192       |\n",
      "|    time_elapsed    | 360       |\n",
      "|    total_timesteps | 69552     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.04     |\n",
      "|    critic_loss     | 0.0177    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 68796     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 96        |\n",
      "|    fps             | 193       |\n",
      "|    time_elapsed    | 375       |\n",
      "|    total_timesteps | 72576     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.06     |\n",
      "|    critic_loss     | 0.0091    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 71820     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 100       |\n",
      "|    fps             | 193       |\n",
      "|    time_elapsed    | 389       |\n",
      "|    total_timesteps | 75600     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.957    |\n",
      "|    critic_loss     | 0.0158    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 74844     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 104       |\n",
      "|    fps             | 194       |\n",
      "|    time_elapsed    | 404       |\n",
      "|    total_timesteps | 78624     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.927    |\n",
      "|    critic_loss     | 0.0102    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 77868     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 108       |\n",
      "|    fps             | 194       |\n",
      "|    time_elapsed    | 420       |\n",
      "|    total_timesteps | 81648     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.892    |\n",
      "|    critic_loss     | 0.0074    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 80892     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 112       |\n",
      "|    fps             | 193       |\n",
      "|    time_elapsed    | 438       |\n",
      "|    total_timesteps | 84672     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.878    |\n",
      "|    critic_loss     | 0.0064    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 83916     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 116       |\n",
      "|    fps             | 192       |\n",
      "|    time_elapsed    | 455       |\n",
      "|    total_timesteps | 87696     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.861    |\n",
      "|    critic_loss     | 0.00514   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 86940     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 120       |\n",
      "|    fps             | 192       |\n",
      "|    time_elapsed    | 471       |\n",
      "|    total_timesteps | 90720     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.851    |\n",
      "|    critic_loss     | 0.00453   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 89964     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 124       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 488       |\n",
      "|    total_timesteps | 93744     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.84     |\n",
      "|    critic_loss     | 0.00397   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 92988     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 128       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 504       |\n",
      "|    total_timesteps | 96768     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.839    |\n",
      "|    critic_loss     | 0.00406   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 96012     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 132       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 520       |\n",
      "|    total_timesteps | 99792     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.856    |\n",
      "|    critic_loss     | 0.00399   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 99036     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 136       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 535       |\n",
      "|    total_timesteps | 102816    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.861    |\n",
      "|    critic_loss     | 0.00481   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 102060    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 140       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 552       |\n",
      "|    total_timesteps | 105840    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.87     |\n",
      "|    critic_loss     | 0.00447   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 105084    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 144       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 567       |\n",
      "|    total_timesteps | 108864    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.869    |\n",
      "|    critic_loss     | 0.0152    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 108108    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 148       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 583       |\n",
      "|    total_timesteps | 111888    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.892    |\n",
      "|    critic_loss     | 0.00647   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 111132    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 152       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 599       |\n",
      "|    total_timesteps | 114912    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.899    |\n",
      "|    critic_loss     | 0.0151    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 114156    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 156       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 614       |\n",
      "|    total_timesteps | 117936    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.899    |\n",
      "|    critic_loss     | 0.00409   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 117180    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 160       |\n",
      "|    fps             | 192       |\n",
      "|    time_elapsed    | 629       |\n",
      "|    total_timesteps | 120960    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.869    |\n",
      "|    critic_loss     | 0.00279   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 120204    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 164       |\n",
      "|    fps             | 192       |\n",
      "|    time_elapsed    | 644       |\n",
      "|    total_timesteps | 123984    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.861    |\n",
      "|    critic_loss     | 0.00234   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 123228    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 168       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 662       |\n",
      "|    total_timesteps | 127008    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.862    |\n",
      "|    critic_loss     | 0.00209   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 126252    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 172       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 679       |\n",
      "|    total_timesteps | 130032    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.874    |\n",
      "|    critic_loss     | 0.00241   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 129276    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 176       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 697       |\n",
      "|    total_timesteps | 133056    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.867    |\n",
      "|    critic_loss     | 0.00127   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 132300    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 180       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 713       |\n",
      "|    total_timesteps | 136080    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.86     |\n",
      "|    critic_loss     | 0.00197   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 135324    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 184       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 730       |\n",
      "|    total_timesteps | 139104    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.86     |\n",
      "|    critic_loss     | 0.000987  |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 138348    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 188       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 748       |\n",
      "|    total_timesteps | 142128    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.874    |\n",
      "|    critic_loss     | 0.00136   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 141372    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 192       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 765       |\n",
      "|    total_timesteps | 145152    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.887    |\n",
      "|    critic_loss     | 0.00125   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 144396    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 196       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 781       |\n",
      "|    total_timesteps | 148176    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.891    |\n",
      "|    critic_loss     | 0.00142   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 147420    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 200       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 797       |\n",
      "|    total_timesteps | 151200    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.886    |\n",
      "|    critic_loss     | 0.00187   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 150444    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 204       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 812       |\n",
      "|    total_timesteps | 154224    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.897    |\n",
      "|    critic_loss     | 0.00206   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 153468    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 208       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 828       |\n",
      "|    total_timesteps | 157248    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.902    |\n",
      "|    critic_loss     | 0.00187   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 156492    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 212       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 843       |\n",
      "|    total_timesteps | 160272    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.902    |\n",
      "|    critic_loss     | 0.0017    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 159516    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 216       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 858       |\n",
      "|    total_timesteps | 163296    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.93     |\n",
      "|    critic_loss     | 0.0109    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 162540    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 220\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 220       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 873       |\n",
      "|    total_timesteps | 166320    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.998    |\n",
      "|    critic_loss     | 0.0665    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 165564    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 224       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 887       |\n",
      "|    total_timesteps | 169344    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.977    |\n",
      "|    critic_loss     | 0.063     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 168588    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 228       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 904       |\n",
      "|    total_timesteps | 172368    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.973    |\n",
      "|    critic_loss     | 0.0785    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 171612    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 230\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 232       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 921       |\n",
      "|    total_timesteps | 175392    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.968    |\n",
      "|    critic_loss     | 0.0597    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 174636    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 236       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 938       |\n",
      "|    total_timesteps | 178416    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.93     |\n",
      "|    critic_loss     | 0.0834    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 177660    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 240\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 240       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 955       |\n",
      "|    total_timesteps | 181440    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.913    |\n",
      "|    critic_loss     | 0.0588    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 180684    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 244       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 972       |\n",
      "|    total_timesteps | 184464    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.911    |\n",
      "|    critic_loss     | 0.066     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 183708    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 248       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 988       |\n",
      "|    total_timesteps | 187488    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.972    |\n",
      "|    critic_loss     | 0.0708    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 186732    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 250\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 252       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1002      |\n",
      "|    total_timesteps | 190512    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.98     |\n",
      "|    critic_loss     | 0.0783    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 189756    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 256       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1017      |\n",
      "|    total_timesteps | 193536    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.02     |\n",
      "|    critic_loss     | 0.0717    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 192780    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 260\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 260       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1033      |\n",
      "|    total_timesteps | 196560    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.831    |\n",
      "|    critic_loss     | 0.134     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 195804    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 264       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1049      |\n",
      "|    total_timesteps | 199584    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.693    |\n",
      "|    critic_loss     | 0.133     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 198828    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 268       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1065      |\n",
      "|    total_timesteps | 202608    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.603    |\n",
      "|    critic_loss     | 0.131     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 201852    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 270\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 272       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1080      |\n",
      "|    total_timesteps | 205632    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.557    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 204876    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 276       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1095      |\n",
      "|    total_timesteps | 208656    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.545    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 207900    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 280\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 280       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1110      |\n",
      "|    total_timesteps | 211680    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.521    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 210924    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 284       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1126      |\n",
      "|    total_timesteps | 214704    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.505    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 213948    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 288       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1142      |\n",
      "|    total_timesteps | 217728    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.49     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 216972    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 290\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 292       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1159      |\n",
      "|    total_timesteps | 220752    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 219996    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 296       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1177      |\n",
      "|    total_timesteps | 223776    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 223020    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 300\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 300       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 1194      |\n",
      "|    total_timesteps | 226800    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 226044    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 304       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 1210      |\n",
      "|    total_timesteps | 229824    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 229068    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 308       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 1226      |\n",
      "|    total_timesteps | 232848    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 232092    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 310\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 312       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1240      |\n",
      "|    total_timesteps | 235872    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 235116    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 316       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1256      |\n",
      "|    total_timesteps | 238896    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.484    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 238140    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 320\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 320       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1271      |\n",
      "|    total_timesteps | 241920    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.467    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 241164    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 324       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1286      |\n",
      "|    total_timesteps | 244944    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.462    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 244188    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 328       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1301      |\n",
      "|    total_timesteps | 247968    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.455    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 247212    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 330\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 332       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1317      |\n",
      "|    total_timesteps | 250992    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.464    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 250236    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 336       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1332      |\n",
      "|    total_timesteps | 254016    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.469    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 253260    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 340\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 340       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1346      |\n",
      "|    total_timesteps | 257040    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 256284    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 344       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1361      |\n",
      "|    total_timesteps | 260064    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 259308    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 348       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1378      |\n",
      "|    total_timesteps | 263088    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.488    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 262332    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 350\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 352       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1395      |\n",
      "|    total_timesteps | 266112    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.492    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 265356    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 356       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1412      |\n",
      "|    total_timesteps | 269136    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.499    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 268380    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 360\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 360       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1428      |\n",
      "|    total_timesteps | 272160    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.483    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 271404    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 364       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1444      |\n",
      "|    total_timesteps | 275184    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 274428    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 368       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1460      |\n",
      "|    total_timesteps | 278208    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.478    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 277452    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 370\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 372       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1475      |\n",
      "|    total_timesteps | 281232    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.491    |\n",
      "|    critic_loss     | 0.13      |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 280476    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 376       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1489      |\n",
      "|    total_timesteps | 284256    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.485    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 283500    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 380\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 380       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1505      |\n",
      "|    total_timesteps | 287280    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.484    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 286524    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 384       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1521      |\n",
      "|    total_timesteps | 290304    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.482    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 289548    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 388       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1536      |\n",
      "|    total_timesteps | 293328    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 292572    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 390\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 392       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1551      |\n",
      "|    total_timesteps | 296352    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 295596    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 396       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1565      |\n",
      "|    total_timesteps | 299376    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 298620    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 400\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 400       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1580      |\n",
      "|    total_timesteps | 302400    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.473    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 301644    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 404       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1594      |\n",
      "|    total_timesteps | 305424    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.476    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 304668    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 408       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1608      |\n",
      "|    total_timesteps | 308448    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.478    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 307692    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 410\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 412       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1624      |\n",
      "|    total_timesteps | 311472    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 310716    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 416       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1640      |\n",
      "|    total_timesteps | 314496    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 313740    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 420\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 420       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1657      |\n",
      "|    total_timesteps | 317520    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.478    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 316764    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 424       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1675      |\n",
      "|    total_timesteps | 320544    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 319788    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 428       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1692      |\n",
      "|    total_timesteps | 323568    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 322812    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 430\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 432       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1709      |\n",
      "|    total_timesteps | 326592    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 325836    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 436       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1726      |\n",
      "|    total_timesteps | 329616    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.483    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 328860    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 440\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 440       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1743      |\n",
      "|    total_timesteps | 332640    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.49     |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 331884    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 444       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1759      |\n",
      "|    total_timesteps | 335664    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 334908    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 448       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1775      |\n",
      "|    total_timesteps | 338688    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.484    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 337932    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 450\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 452       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1790      |\n",
      "|    total_timesteps | 341712    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 340956    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 456       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1804      |\n",
      "|    total_timesteps | 344736    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 343980    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 460\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 460       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1819      |\n",
      "|    total_timesteps | 347760    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 347004    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 464       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1833      |\n",
      "|    total_timesteps | 350784    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.46     |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 350028    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 468       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1848      |\n",
      "|    total_timesteps | 353808    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.469    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 353052    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 470\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 472       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1865      |\n",
      "|    total_timesteps | 356832    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 356076    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 476       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1882      |\n",
      "|    total_timesteps | 359856    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.486    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 359100    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 480\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 480       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1899      |\n",
      "|    total_timesteps | 362880    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.476    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 362124    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 484       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1916      |\n",
      "|    total_timesteps | 365904    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.464    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 365148    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 488       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1934      |\n",
      "|    total_timesteps | 368928    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.466    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 368172    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 490\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 492       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1949      |\n",
      "|    total_timesteps | 371952    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.473    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 371196    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 496       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1963      |\n",
      "|    total_timesteps | 374976    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.476    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 374220    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 500\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 500       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1984      |\n",
      "|    total_timesteps | 378000    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.478    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 377244    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 504       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 2004      |\n",
      "|    total_timesteps | 381024    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.493    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 380268    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 508       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 2020      |\n",
      "|    total_timesteps | 384048    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.487    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 383292    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 510\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 512       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2037      |\n",
      "|    total_timesteps | 387072    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.483    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 386316    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 516       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 2053      |\n",
      "|    total_timesteps | 390096    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.494    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 389340    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 520\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 520       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 2068      |\n",
      "|    total_timesteps | 393120    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.493    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 392364    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 524       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2085      |\n",
      "|    total_timesteps | 396144    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.495    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 395388    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 528       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2107      |\n",
      "|    total_timesteps | 399168    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.486    |\n",
      "|    critic_loss     | 0.13      |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 398412    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 530\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 532       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2128      |\n",
      "|    total_timesteps | 402192    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.484    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 401436    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 536       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2144      |\n",
      "|    total_timesteps | 405216    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.49     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 404460    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 540\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 540       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2160      |\n",
      "|    total_timesteps | 408240    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.489    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 407484    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 544       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2177      |\n",
      "|    total_timesteps | 411264    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.493    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 410508    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 548       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2192      |\n",
      "|    total_timesteps | 414288    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.491    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 413532    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 550\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 552       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2206      |\n",
      "|    total_timesteps | 417312    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.484    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 416556    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 556       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2223      |\n",
      "|    total_timesteps | 420336    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 419580    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 560\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 560       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2241      |\n",
      "|    total_timesteps | 423360    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.482    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 422604    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 564       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2257      |\n",
      "|    total_timesteps | 426384    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 425628    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 568       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2272      |\n",
      "|    total_timesteps | 429408    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.467    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 428652    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 570\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 572       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2287      |\n",
      "|    total_timesteps | 432432    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.473    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 431676    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 576       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2302      |\n",
      "|    total_timesteps | 435456    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.476    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 434700    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 580\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 580       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2318      |\n",
      "|    total_timesteps | 438480    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 437724    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 584       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2334      |\n",
      "|    total_timesteps | 441504    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.47     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 440748    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 588       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2351      |\n",
      "|    total_timesteps | 444528    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.467    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 443772    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 590\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 592       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2369      |\n",
      "|    total_timesteps | 447552    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.478    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 446796    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 596       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2386      |\n",
      "|    total_timesteps | 450576    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.478    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 449820    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 600\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 600       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2402      |\n",
      "|    total_timesteps | 453600    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 452844    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 604       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2419      |\n",
      "|    total_timesteps | 456624    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 455868    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 608       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2434      |\n",
      "|    total_timesteps | 459648    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 458892    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 610\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 612       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2448      |\n",
      "|    total_timesteps | 462672    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.46     |\n",
      "|    critic_loss     | 0.125     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 461916    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 616       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2466      |\n",
      "|    total_timesteps | 465696    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.465    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 464940    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 620\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 620       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2483      |\n",
      "|    total_timesteps | 468720    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 467964    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 624       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2499      |\n",
      "|    total_timesteps | 471744    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 470988    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 628       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2514      |\n",
      "|    total_timesteps | 474768    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.474    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 474012    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 630\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 632       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2529      |\n",
      "|    total_timesteps | 477792    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.469    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 477036    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 636       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2543      |\n",
      "|    total_timesteps | 480816    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 480060    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 640\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 640       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2558      |\n",
      "|    total_timesteps | 483840    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.464    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 483084    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 644       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2573      |\n",
      "|    total_timesteps | 486864    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.473    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 486108    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 648       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2590      |\n",
      "|    total_timesteps | 489888    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.472    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 489132    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 650\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 652       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2608      |\n",
      "|    total_timesteps | 492912    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 492156    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 656       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2625      |\n",
      "|    total_timesteps | 495936    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 495180    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 660\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 660       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2642      |\n",
      "|    total_timesteps | 498960    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.488    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 498204    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 664       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2659      |\n",
      "|    total_timesteps | 501984    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.493    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 501228    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 668       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2674      |\n",
      "|    total_timesteps | 505008    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.49     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 504252    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 670\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 672       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2690      |\n",
      "|    total_timesteps | 508032    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.493    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 507276    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 676       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2705      |\n",
      "|    total_timesteps | 511056    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.495    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 510300    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 680\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 680       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2722      |\n",
      "|    total_timesteps | 514080    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.488    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 513324    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 684       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2738      |\n",
      "|    total_timesteps | 517104    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.488    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 516348    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 688       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2753      |\n",
      "|    total_timesteps | 520128    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.489    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 519372    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 690\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 692       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2768      |\n",
      "|    total_timesteps | 523152    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 522396    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 696       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2783      |\n",
      "|    total_timesteps | 526176    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 525420    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 700\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 700       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2797      |\n",
      "|    total_timesteps | 529200    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 528444    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 704       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2812      |\n",
      "|    total_timesteps | 532224    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.469    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 531468    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 708       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2829      |\n",
      "|    total_timesteps | 535248    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.469    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 534492    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 710\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 712       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2846      |\n",
      "|    total_timesteps | 538272    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.478    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 537516    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 716       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2863      |\n",
      "|    total_timesteps | 541296    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.468    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 540540    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 720\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 720       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2880      |\n",
      "|    total_timesteps | 544320    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.46     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 543564    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 724       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2897      |\n",
      "|    total_timesteps | 547344    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.47     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 546588    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 728       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2911      |\n",
      "|    total_timesteps | 550368    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.469    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 549612    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 730\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 732       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2926      |\n",
      "|    total_timesteps | 553392    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.466    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 552636    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 736       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2943      |\n",
      "|    total_timesteps | 556416    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.471    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 555660    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 740\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 740       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2960      |\n",
      "|    total_timesteps | 559440    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.468    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 558684    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 744       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2976      |\n",
      "|    total_timesteps | 562464    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.47     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 561708    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 748       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2991      |\n",
      "|    total_timesteps | 565488    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.476    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 564732    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 750\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 752       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3006      |\n",
      "|    total_timesteps | 568512    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 567756    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 756       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3020      |\n",
      "|    total_timesteps | 571536    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.485    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 570780    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 760\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 760       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3035      |\n",
      "|    total_timesteps | 574560    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 573804    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 764       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3050      |\n",
      "|    total_timesteps | 577584    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.483    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 576828    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 768       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3068      |\n",
      "|    total_timesteps | 580608    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.487    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 579852    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 770\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 772       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3085      |\n",
      "|    total_timesteps | 583632    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 582876    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 776       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3102      |\n",
      "|    total_timesteps | 586656    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.488    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 585900    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 780\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 780       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3119      |\n",
      "|    total_timesteps | 589680    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.493    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 588924    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 784       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3137      |\n",
      "|    total_timesteps | 592704    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.491    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 591948    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 788       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3152      |\n",
      "|    total_timesteps | 595728    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.495    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 594972    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 790\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 792       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3166      |\n",
      "|    total_timesteps | 598752    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.487    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 597996    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 796       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3184      |\n",
      "|    total_timesteps | 601776    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.476    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 601020    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 800\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 800       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3201      |\n",
      "|    total_timesteps | 604800    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.474    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 604044    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 804       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3216      |\n",
      "|    total_timesteps | 607824    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 607068    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 808       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3232      |\n",
      "|    total_timesteps | 610848    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.47     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 610092    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 810\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 812       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3247      |\n",
      "|    total_timesteps | 613872    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 613116    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 816       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3262      |\n",
      "|    total_timesteps | 616896    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.469    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 616140    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 820\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 820       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3276      |\n",
      "|    total_timesteps | 619920    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 619164    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 824       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3292      |\n",
      "|    total_timesteps | 622944    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.484    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 622188    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 828       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3310      |\n",
      "|    total_timesteps | 625968    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 625212    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 830\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 832       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3327      |\n",
      "|    total_timesteps | 628992    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 628236    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 836       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3343      |\n",
      "|    total_timesteps | 632016    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.466    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 631260    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 840\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 840       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3360      |\n",
      "|    total_timesteps | 635040    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.468    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 634284    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 844       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3377      |\n",
      "|    total_timesteps | 638064    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.482    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 637308    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 848       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3396      |\n",
      "|    total_timesteps | 641088    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.486    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 640332    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 850\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 852       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3413      |\n",
      "|    total_timesteps | 644112    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.489    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 643356    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 856       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3431      |\n",
      "|    total_timesteps | 647136    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.495    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 646380    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 860\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 860       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3447      |\n",
      "|    total_timesteps | 650160    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 649404    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 864       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3462      |\n",
      "|    total_timesteps | 653184    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.497    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 652428    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 868       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3477      |\n",
      "|    total_timesteps | 656208    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.498    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 655452    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 870\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 872       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3492      |\n",
      "|    total_timesteps | 659232    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.489    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 658476    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 876       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3506      |\n",
      "|    total_timesteps | 662256    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.493    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 661500    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 880\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 880       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3521      |\n",
      "|    total_timesteps | 665280    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.485    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 664524    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 884       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3537      |\n",
      "|    total_timesteps | 668304    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.473    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 667548    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 888       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3554      |\n",
      "|    total_timesteps | 671328    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 670572    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 890\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 892       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3572      |\n",
      "|    total_timesteps | 674352    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.469    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 673596    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 896       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3589      |\n",
      "|    total_timesteps | 677376    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.463    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 676620    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 900\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 900       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3607      |\n",
      "|    total_timesteps | 680400    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.461    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 679644    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 904       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3623      |\n",
      "|    total_timesteps | 683424    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.473    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 682668    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 908       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3637      |\n",
      "|    total_timesteps | 686448    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.476    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 685692    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 910\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 912       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3652      |\n",
      "|    total_timesteps | 689472    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 688716    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 916       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3670      |\n",
      "|    total_timesteps | 692496    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 691740    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 920\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 920       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3686      |\n",
      "|    total_timesteps | 695520    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.463    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 694764    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 924       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3702      |\n",
      "|    total_timesteps | 698544    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.468    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 697788    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 928       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3717      |\n",
      "|    total_timesteps | 701568    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.464    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 700812    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 930\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 932       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3732      |\n",
      "|    total_timesteps | 704592    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.466    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 703836    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 936       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3746      |\n",
      "|    total_timesteps | 707616    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.471    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 706860    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 940\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 940       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3761      |\n",
      "|    total_timesteps | 710640    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.484    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 709884    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 944       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3777      |\n",
      "|    total_timesteps | 713664    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 712908    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 948       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3794      |\n",
      "|    total_timesteps | 716688    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.488    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 715932    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 950\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 952       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3811      |\n",
      "|    total_timesteps | 719712    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.495    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 718956    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 956       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3828      |\n",
      "|    total_timesteps | 722736    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.495    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 721980    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 960\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 960       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3846      |\n",
      "|    total_timesteps | 725760    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.487    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 725004    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 964       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3863      |\n",
      "|    total_timesteps | 728784    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.485    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 728028    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 968       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3877      |\n",
      "|    total_timesteps | 731808    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.495    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 731052    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 970\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 972       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3892      |\n",
      "|    total_timesteps | 734832    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.498    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 734076    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 976       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3909      |\n",
      "|    total_timesteps | 737856    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.494    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 737100    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 980\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 980       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3924      |\n",
      "|    total_timesteps | 740880    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.488    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 740124    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 984       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3940      |\n",
      "|    total_timesteps | 743904    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.501    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 743148    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 988       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3955      |\n",
      "|    total_timesteps | 746928    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.504    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 746172    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 990\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 992       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3971      |\n",
      "|    total_timesteps | 749952    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.503    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 749196    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 996       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3985      |\n",
      "|    total_timesteps | 752976    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.497    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 752220    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1000\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1000      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4000      |\n",
      "|    total_timesteps | 756000    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.486    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 755244    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1004      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4016      |\n",
      "|    total_timesteps | 759024    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 758268    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1008      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4033      |\n",
      "|    total_timesteps | 762048    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 761292    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1010\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1012      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4050      |\n",
      "|    total_timesteps | 765072    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 764316    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1016      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4068      |\n",
      "|    total_timesteps | 768096    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 767340    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1020\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1020      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4086      |\n",
      "|    total_timesteps | 771120    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.469    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 770364    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1024      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4104      |\n",
      "|    total_timesteps | 774144    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.471    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 773388    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1028      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4121      |\n",
      "|    total_timesteps | 777168    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.464    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 776412    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1030\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1032      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4139      |\n",
      "|    total_timesteps | 780192    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.474    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 779436    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1036      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4154      |\n",
      "|    total_timesteps | 783216    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 782460    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1040\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1040      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4169      |\n",
      "|    total_timesteps | 786240    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 785484    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1044      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4184      |\n",
      "|    total_timesteps | 789264    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.47     |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 788508    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1048      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4200      |\n",
      "|    total_timesteps | 792288    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 791532    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1050\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1052      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4215      |\n",
      "|    total_timesteps | 795312    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.47     |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 794556    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1056      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4229      |\n",
      "|    total_timesteps | 798336    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.474    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 797580    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1060\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1060      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4246      |\n",
      "|    total_timesteps | 801360    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 800604    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1064      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4262      |\n",
      "|    total_timesteps | 804384    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.483    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 803628    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1068      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4280      |\n",
      "|    total_timesteps | 807408    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.489    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 806652    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1070\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1072      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4296      |\n",
      "|    total_timesteps | 810432    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.491    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 809676    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1076      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4313      |\n",
      "|    total_timesteps | 813456    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.483    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 812700    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1080\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1080      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4332      |\n",
      "|    total_timesteps | 816480    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 815724    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1084      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4347      |\n",
      "|    total_timesteps | 819504    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 818748    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1088      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4361      |\n",
      "|    total_timesteps | 822528    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.478    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 821772    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1090\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1092      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4377      |\n",
      "|    total_timesteps | 825552    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 824796    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1096      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4395      |\n",
      "|    total_timesteps | 828576    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.476    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 827820    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1100      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4411      |\n",
      "|    total_timesteps | 831600    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.476    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 830844    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1104      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4426      |\n",
      "|    total_timesteps | 834624    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.488    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 833868    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1108      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4441      |\n",
      "|    total_timesteps | 837648    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.494    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 836892    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1112      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4456      |\n",
      "|    total_timesteps | 840672    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.486    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 839916    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1116      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4471      |\n",
      "|    total_timesteps | 843696    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.491    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 842940    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1120      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4485      |\n",
      "|    total_timesteps | 846720    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.493    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 845964    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1124      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4501      |\n",
      "|    total_timesteps | 849744    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.495    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 848988    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1128      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4518      |\n",
      "|    total_timesteps | 852768    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.482    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 852012    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1132      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4536      |\n",
      "|    total_timesteps | 855792    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.483    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 855036    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1136      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4553      |\n",
      "|    total_timesteps | 858816    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.49     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 858060    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1140      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4570      |\n",
      "|    total_timesteps | 861840    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.485    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 861084    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1144      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4586      |\n",
      "|    total_timesteps | 864864    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 864108    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1148      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4601      |\n",
      "|    total_timesteps | 867888    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.482    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 867132    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1152      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4617      |\n",
      "|    total_timesteps | 870912    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.476    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 870156    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1156      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4633      |\n",
      "|    total_timesteps | 873936    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.483    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 873180    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1160      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4649      |\n",
      "|    total_timesteps | 876960    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.485    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 876204    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1164      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4665      |\n",
      "|    total_timesteps | 879984    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.482    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 879228    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1168      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4680      |\n",
      "|    total_timesteps | 883008    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.478    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 882252    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1172      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4695      |\n",
      "|    total_timesteps | 886032    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 885276    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1176      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4710      |\n",
      "|    total_timesteps | 889056    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.471    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 888300    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1180      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4724      |\n",
      "|    total_timesteps | 892080    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.473    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 891324    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1184      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4741      |\n",
      "|    total_timesteps | 895104    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.467    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 894348    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1188      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4757      |\n",
      "|    total_timesteps | 898128    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.473    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 897372    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1192      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4774      |\n",
      "|    total_timesteps | 901152    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.474    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 900396    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1196      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4790      |\n",
      "|    total_timesteps | 904176    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.455    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 903420    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1200      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4807      |\n",
      "|    total_timesteps | 907200    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.465    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 906444    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1204      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4823      |\n",
      "|    total_timesteps | 910224    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.468    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 909468    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1208      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4837      |\n",
      "|    total_timesteps | 913248    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.467    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 912492    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1212      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4852      |\n",
      "|    total_timesteps | 916272    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 915516    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1216      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4869      |\n",
      "|    total_timesteps | 919296    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.478    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 918540    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1220\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1220      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4884      |\n",
      "|    total_timesteps | 922320    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.468    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 921564    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1224      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4899      |\n",
      "|    total_timesteps | 925344    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.47     |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 924588    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1228      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4914      |\n",
      "|    total_timesteps | 928368    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.478    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 927612    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1230\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1232      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4929      |\n",
      "|    total_timesteps | 931392    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.473    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 930636    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1236      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4944      |\n",
      "|    total_timesteps | 934416    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.484    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 933660    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1240\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1240      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 4958      |\n",
      "|    total_timesteps | 937440    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.484    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 936684    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1244      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 4974      |\n",
      "|    total_timesteps | 940464    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 939708    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1248      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 4990      |\n",
      "|    total_timesteps | 943488    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.482    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 942732    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1250\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1252      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 5007      |\n",
      "|    total_timesteps | 946512    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.487    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 945756    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1256      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 5025      |\n",
      "|    total_timesteps | 949536    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 948780    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1260\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1260      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 5042      |\n",
      "|    total_timesteps | 952560    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.472    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 951804    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1264      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 5058      |\n",
      "|    total_timesteps | 955584    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.472    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 954828    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1268      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 5073      |\n",
      "|    total_timesteps | 958608    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 957852    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1270\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1272      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 5088      |\n",
      "|    total_timesteps | 961632    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 960876    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1276      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 5104      |\n",
      "|    total_timesteps | 964656    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.474    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 963900    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1280\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1280      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 5120      |\n",
      "|    total_timesteps | 967680    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 966924    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1284      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 5136      |\n",
      "|    total_timesteps | 970704    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.487    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 969948    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1288      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 5151      |\n",
      "|    total_timesteps | 973728    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.488    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 972972    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1290\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1292      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 5166      |\n",
      "|    total_timesteps | 976752    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 975996    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1296      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 5181      |\n",
      "|    total_timesteps | 979776    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.474    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 979020    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1300\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1300      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 5196      |\n",
      "|    total_timesteps | 982800    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.474    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 982044    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1304      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 5212      |\n",
      "|    total_timesteps | 985824    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.468    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 985068    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1308      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 5229      |\n",
      "|    total_timesteps | 988848    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.464    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 988092    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1310\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1312      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 5246      |\n",
      "|    total_timesteps | 991872    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.471    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 991116    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1316      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 5263      |\n",
      "|    total_timesteps | 994896    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.476    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 994140    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1320\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1320      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 5280      |\n",
      "|    total_timesteps | 997920    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 997164    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_name  = 'DDPG_'\n",
    "total_timesteps = 1000000\n",
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=total_timesteps)\n",
    "trained_ddpg.save(os.path.join(TRAINED_MODEL_DIR, model_name + str(total_timesteps) + \".pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of stable_baselines3.common.logger failed: Traceback (most recent call last):\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 365, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 319, in update_instances\n",
      "    refs = gc.get_referrers(old)\n",
      "KeyboardInterrupt\n",
      "]\n",
      "[autoreload of stable_baselines3.common.type_aliases failed: Traceback (most recent call last):\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 365, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 319, in update_instances\n",
      "    refs = gc.get_referrers(old)\n",
      "KeyboardInterrupt\n",
      "]\n",
      "[autoreload of stable_baselines3.common.base_class failed: Traceback (most recent call last):\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 365, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 319, in update_instances\n",
      "    refs = gc.get_referrers(old)\n",
      "KeyboardInterrupt\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "TENSORBOARD_LOG_DIR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_gDkU-j-fCmZ"
   },
   "source": [
    "### Model 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "y5D5PFUhMzSV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = config.PPO_PARAMS\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS, tensorboard_log= TENSORBOARD_LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ppo.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "Gt8eIQKYM4G3",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to MARKETS/ForexMarket/TENSORBOARD_LOG_DIR/ppo_1\n",
      "day: 521, episode: 120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999930.23\n",
      "total_reward: -69.77\n",
      "total_cost: 28.03\n",
      "total_trades: 477\n",
      "Sharpe: -1.430\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 125           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 16            |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0018495668 |\n",
      "--------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 109            |\n",
      "|    iterations           | 2              |\n",
      "|    time_elapsed         | 37             |\n",
      "|    total_timesteps      | 4096           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.00394472     |\n",
      "|    clip_fraction        | 0.03           |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.43          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.0204        |\n",
      "|    n_updates            | 10             |\n",
      "|    policy_gradient_loss | -0.000754      |\n",
      "|    reward               | -0.00047071525 |\n",
      "|    std                  | 1.02           |\n",
      "|    value_loss           | 0.00464        |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 111            |\n",
      "|    iterations           | 3              |\n",
      "|    time_elapsed         | 54             |\n",
      "|    total_timesteps      | 6144           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.002440176    |\n",
      "|    clip_fraction        | 0.0201         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.45          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.0126        |\n",
      "|    n_updates            | 20             |\n",
      "|    policy_gradient_loss | -0.000334      |\n",
      "|    reward               | 1.30455865e-05 |\n",
      "|    std                  | 1.04           |\n",
      "|    value_loss           | 0.00424        |\n",
      "--------------------------------------------\n",
      "day: 521, episode: 130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999924.49\n",
      "total_reward: -75.51\n",
      "total_cost: 29.17\n",
      "total_trades: 485\n",
      "Sharpe: -1.616\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 114           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 71            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0060861534  |\n",
      "|    clip_fraction        | 0.0339        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.47         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.00979       |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00154      |\n",
      "|    reward               | 0.00020111975 |\n",
      "|    std                  | 1.05          |\n",
      "|    value_loss           | 0.00282       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 117           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 87            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.005029171   |\n",
      "|    clip_fraction        | 0.0629        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.47         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.0247       |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00271      |\n",
      "|    reward               | -0.0028566222 |\n",
      "|    std                  | 1.06          |\n",
      "|    value_loss           | 0.00182       |\n",
      "-------------------------------------------\n",
      "day: 521, episode: 140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999831.76\n",
      "total_reward: -168.24\n",
      "total_cost: 32.68\n",
      "total_trades: 514\n",
      "Sharpe: -1.870\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 119            |\n",
      "|    iterations           | 6              |\n",
      "|    time_elapsed         | 103            |\n",
      "|    total_timesteps      | 12288          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0015087505   |\n",
      "|    clip_fraction        | 0.00361        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.49          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.0123        |\n",
      "|    n_updates            | 50             |\n",
      "|    policy_gradient_loss | -0.000296      |\n",
      "|    reward               | -5.6918084e-06 |\n",
      "|    std                  | 1.08           |\n",
      "|    value_loss           | 0.00113        |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 119            |\n",
      "|    iterations           | 7              |\n",
      "|    time_elapsed         | 120            |\n",
      "|    total_timesteps      | 14336          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0030484116   |\n",
      "|    clip_fraction        | 0.0104         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.5           |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.0165        |\n",
      "|    n_updates            | 60             |\n",
      "|    policy_gradient_loss | -0.000133      |\n",
      "|    reward               | -0.00031188942 |\n",
      "|    std                  | 1.09           |\n",
      "|    value_loss           | 0.000803       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 119           |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 136           |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.004512899   |\n",
      "|    clip_fraction        | 0.0732        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.51         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.00205      |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | -0.00269      |\n",
      "|    reward               | 0.00017221503 |\n",
      "|    std                  | 1.09          |\n",
      "|    value_loss           | 0.000569      |\n",
      "-------------------------------------------\n",
      "day: 521, episode: 150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999918.99\n",
      "total_reward: -81.01\n",
      "total_cost: 32.80\n",
      "total_trades: 511\n",
      "Sharpe: -0.939\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 119           |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 153           |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0027297186  |\n",
      "|    clip_fraction        | 0.00474       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.52         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.0198       |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -0.000151     |\n",
      "|    reward               | 0.00021074452 |\n",
      "|    std                  | 1.11          |\n",
      "|    value_loss           | 0.000347      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 124          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 164          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075865053 |\n",
      "|    clip_fraction        | 0.0496       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.53        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0199      |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    reward               | -0.002994742 |\n",
      "|    std                  | 1.13         |\n",
      "|    value_loss           | 0.000235     |\n",
      "------------------------------------------\n",
      "day: 521, episode: 160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999280.49\n",
      "total_reward: -719.51\n",
      "total_cost: 33.68\n",
      "total_trades: 515\n",
      "Sharpe: -1.093\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 128          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 175          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039439714 |\n",
      "|    clip_fraction        | 0.0237       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.54        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0387      |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    reward               | 6.970362e-06 |\n",
      "|    std                  | 1.13         |\n",
      "|    value_loss           | 0.000171     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 128          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 191          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004982753 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.55        |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0192      |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | 0.000155     |\n",
      "|    reward               | 9.264035e-05 |\n",
      "|    std                  | 1.14         |\n",
      "|    value_loss           | 0.000362     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 127           |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 208           |\n",
      "|    total_timesteps      | 26624         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0034466549  |\n",
      "|    clip_fraction        | 0.017         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.55         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.0283       |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | -0.00101      |\n",
      "|    reward               | 5.7179794e-05 |\n",
      "|    std                  | 1.15          |\n",
      "|    value_loss           | 8.63e-05      |\n",
      "-------------------------------------------\n",
      "day: 521, episode: 170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999096.44\n",
      "total_reward: -903.56\n",
      "total_cost: 34.32\n",
      "total_trades: 507\n",
      "Sharpe: -1.147\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 128          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 223          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043732603 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.55        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.000302     |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00127     |\n",
      "|    reward               | 0.011728906  |\n",
      "|    std                  | 1.15         |\n",
      "|    value_loss           | 8.57e-05     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 129            |\n",
      "|    iterations           | 15             |\n",
      "|    time_elapsed         | 237            |\n",
      "|    total_timesteps      | 30720          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0017186309   |\n",
      "|    clip_fraction        | 0.0138         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.56          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.0191        |\n",
      "|    n_updates            | 140            |\n",
      "|    policy_gradient_loss | -0.000946      |\n",
      "|    reward               | -0.00040880957 |\n",
      "|    std                  | 1.16           |\n",
      "|    value_loss           | 5.14e-05       |\n",
      "--------------------------------------------\n",
      "day: 521, episode: 180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 998634.26\n",
      "total_reward: -1365.74\n",
      "total_cost: 34.65\n",
      "total_trades: 519\n",
      "Sharpe: -1.143\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 129           |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 253           |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.004056423   |\n",
      "|    clip_fraction        | 0.0132        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.57         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.00962      |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -0.000824     |\n",
      "|    reward               | 0.00041280323 |\n",
      "|    std                  | 1.16          |\n",
      "|    value_loss           | 5.59e-05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 129           |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 268           |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.006900086   |\n",
      "|    clip_fraction        | 0.076         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.56         |\n",
      "|    explained_variance   | 0.382         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.0151       |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | -0.00523      |\n",
      "|    reward               | 0.00018699822 |\n",
      "|    std                  | 1.14          |\n",
      "|    value_loss           | 0.00306       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 130          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 281          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011767203 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.54        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0078      |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | 8.54e-07     |\n",
      "|    reward               | 0.0074774367 |\n",
      "|    std                  | 1.12         |\n",
      "|    value_loss           | 3.6e-05      |\n",
      "------------------------------------------\n",
      "day: 521, episode: 190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 998682.58\n",
      "total_reward: -1317.42\n",
      "total_cost: 34.82\n",
      "total_trades: 515\n",
      "Sharpe: -1.157\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 131          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 295          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049920124 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.53        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0194      |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    reward               | 0.0021066798 |\n",
      "|    std                  | 1.12         |\n",
      "|    value_loss           | 5.57e-05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 132           |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 309           |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0036663166  |\n",
      "|    clip_fraction        | 0.00688       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.53         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.0111        |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -0.000345     |\n",
      "|    reward               | -0.0017155814 |\n",
      "|    std                  | 1.11          |\n",
      "|    value_loss           | 5.53e-05      |\n",
      "-------------------------------------------\n",
      "day: 521, episode: 200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 998877.32\n",
      "total_reward: -1122.68\n",
      "total_cost: 33.74\n",
      "total_trades: 517\n",
      "Sharpe: -1.150\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 132            |\n",
      "|    iterations           | 21             |\n",
      "|    time_elapsed         | 324            |\n",
      "|    total_timesteps      | 43008          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0056640343   |\n",
      "|    clip_fraction        | 0.0377         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.52          |\n",
      "|    explained_variance   | -1.19e-07      |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 0.00815        |\n",
      "|    n_updates            | 200            |\n",
      "|    policy_gradient_loss | -0.00234       |\n",
      "|    reward               | -0.00011513752 |\n",
      "|    std                  | 1.1            |\n",
      "|    value_loss           | 9.72e-05       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 133           |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 337           |\n",
      "|    total_timesteps      | 45056         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0036093714  |\n",
      "|    clip_fraction        | 0.0291        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.51         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.0238       |\n",
      "|    n_updates            | 210           |\n",
      "|    policy_gradient_loss | -0.00185      |\n",
      "|    reward               | 0.00032092122 |\n",
      "|    std                  | 1.09          |\n",
      "|    value_loss           | 6.25e-05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 132           |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 354           |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.004442614   |\n",
      "|    clip_fraction        | 0.0303        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.51         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.000453     |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.0028       |\n",
      "|    reward               | -0.0013100529 |\n",
      "|    std                  | 1.09          |\n",
      "|    value_loss           | 4.2e-05       |\n",
      "-------------------------------------------\n",
      "day: 521, episode: 210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 998574.30\n",
      "total_reward: -1425.70\n",
      "total_cost: 34.62\n",
      "total_trades: 519\n",
      "Sharpe: -1.139\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 131            |\n",
      "|    iterations           | 24             |\n",
      "|    time_elapsed         | 374            |\n",
      "|    total_timesteps      | 49152          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0031746945   |\n",
      "|    clip_fraction        | 0.00918        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.51          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.0147        |\n",
      "|    n_updates            | 230            |\n",
      "|    policy_gradient_loss | -0.000383      |\n",
      "|    reward               | -0.00012352185 |\n",
      "|    std                  | 1.1            |\n",
      "|    value_loss           | 7.06e-05       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 130           |\n",
      "|    iterations           | 25            |\n",
      "|    time_elapsed         | 390           |\n",
      "|    total_timesteps      | 51200         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.002029471   |\n",
      "|    clip_fraction        | 0.0181        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.52         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.00494      |\n",
      "|    n_updates            | 240           |\n",
      "|    policy_gradient_loss | -0.00142      |\n",
      "|    reward               | 0.00020285514 |\n",
      "|    std                  | 1.11          |\n",
      "|    value_loss           | 9.74e-05      |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_name  = 'ppo_'\n",
    "model_version = '50000'\n",
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=50000)\n",
    "trained_ppo.save(os.path.join(TRAINED_MODEL_DIR, model_name + \".pth\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zpv4S0-fDBv"
   },
   "source": [
    "### Model 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSAHhV4Xc-bh"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 100, \n",
    "              \"buffer_size\": 1000000, \n",
    "              \"learning_rate\": 0.001}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSRxNYAxdKpU"
   },
   "outputs": [],
   "source": [
    "model_name ='td3_'\n",
    "trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=30000)\n",
    "trained_td3.save(os.path.join(TRAINED_MODEL_DIR, model_name + \".pth\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr49PotrfG01"
   },
   "source": [
    "### Model 5: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwOhVjqRkCdM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 1000000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 1000000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8RSdKCckJyH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 23        |\n",
      "|    time_elapsed    | 63        |\n",
      "|    total_timesteps | 1508      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.22e+03  |\n",
      "|    critic_loss     | 7.89e+03  |\n",
      "|    ent_coef        | 0.115     |\n",
      "|    ent_coef_loss   | 1.08e+03  |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 1407      |\n",
      "|    reward          | 4.9791036 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 19        |\n",
      "|    time_elapsed    | 156       |\n",
      "|    total_timesteps | 3016      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.66e+03  |\n",
      "|    critic_loss     | 8.25e+03  |\n",
      "|    ent_coef        | 0.134     |\n",
      "|    ent_coef_loss   | 1.01e+03  |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 2915      |\n",
      "|    reward          | 4.9791036 |\n",
      "----------------------------------\n",
      "day: 376, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 964607.58\n",
      "total_reward: -35392.42\n",
      "total_cost: 1002.62\n",
      "total_trades: 4139\n",
      "Sharpe: 1.166\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 21        |\n",
      "|    time_elapsed    | 212       |\n",
      "|    total_timesteps | 4524      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 2e+03     |\n",
      "|    critic_loss     | 6.04e+03  |\n",
      "|    ent_coef        | 0.155     |\n",
      "|    ent_coef_loss   | 939       |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 4423      |\n",
      "|    reward          | 4.9791036 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 22        |\n",
      "|    time_elapsed    | 273       |\n",
      "|    total_timesteps | 6032      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 2.55e+03  |\n",
      "|    critic_loss     | 9.16e+03  |\n",
      "|    ent_coef        | 0.181     |\n",
      "|    ent_coef_loss   | 863       |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 5931      |\n",
      "|    reward          | 4.9791036 |\n",
      "----------------------------------\n",
      "day: 376, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 964607.58\n",
      "total_reward: -35392.42\n",
      "total_cost: 1002.62\n",
      "total_trades: 4139\n",
      "Sharpe: 1.166\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 22        |\n",
      "|    time_elapsed    | 336       |\n",
      "|    total_timesteps | 7540      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 3.08e+03  |\n",
      "|    critic_loss     | 8.01e+03  |\n",
      "|    ent_coef        | 0.21      |\n",
      "|    ent_coef_loss   | 787       |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 7439      |\n",
      "|    reward          | 4.9791036 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 22        |\n",
      "|    time_elapsed    | 397       |\n",
      "|    total_timesteps | 9048      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 3.8e+03   |\n",
      "|    critic_loss     | 1.12e+04  |\n",
      "|    ent_coef        | 0.244     |\n",
      "|    ent_coef_loss   | 709       |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 8947      |\n",
      "|    reward          | 4.9791036 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 28        |\n",
      "|    fps             | 23        |\n",
      "|    time_elapsed    | 453       |\n",
      "|    total_timesteps | 10556     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.48e+03  |\n",
      "|    critic_loss     | 6.41e+03  |\n",
      "|    ent_coef        | 0.284     |\n",
      "|    ent_coef_loss   | 635       |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 10455     |\n",
      "|    reward          | 4.9791036 |\n",
      "----------------------------------\n",
      "day: 376, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 964607.58\n",
      "total_reward: -35392.42\n",
      "total_cost: 1002.62\n",
      "total_trades: 4139\n",
      "Sharpe: 1.166\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 32        |\n",
      "|    fps             | 23        |\n",
      "|    time_elapsed    | 516       |\n",
      "|    total_timesteps | 12064     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 5.47e+03  |\n",
      "|    critic_loss     | 9.98e+03  |\n",
      "|    ent_coef        | 0.331     |\n",
      "|    ent_coef_loss   | 559       |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 11963     |\n",
      "|    reward          | 4.9791036 |\n",
      "----------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/f/financial_projects/Deep Reinforcement Learning Approaches on Stock Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb Cell 89\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bu18/mnt/f/financial_projects/Deep%20Reinforcement%20Learning%20Approaches%20on%20Stock%20Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb#Y154sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msac_\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bu18/mnt/f/financial_projects/Deep%20Reinforcement%20Learning%20Approaches%20on%20Stock%20Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb#Y154sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m trained_sac \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mtrain_model(model\u001b[39m=\u001b[39;49mmodel_sac, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bu18/mnt/f/financial_projects/Deep%20Reinforcement%20Learning%20Approaches%20on%20Stock%20Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb#Y154sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m                              tb_log_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msac\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bu18/mnt/f/financial_projects/Deep%20Reinforcement%20Learning%20Approaches%20on%20Stock%20Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb#Y154sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m                              total_timesteps\u001b[39m=\u001b[39;49m\u001b[39m60000\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bu18/mnt/f/financial_projects/Deep%20Reinforcement%20Learning%20Approaches%20on%20Stock%20Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb#Y154sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m trained_sac\u001b[39m.\u001b[39msave(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(TRAINED_MODEL_DIR, model_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.pth\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[0;32m/mnt/f/financial_projects/Deep Reinforcement Learning Approaches on Stock Prediction/FinRL/finrl/agents/stablebaselines3/models.py:102\u001b[0m, in \u001b[0;36mDRLAgent.train_model\u001b[0;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_model\u001b[39m(\u001b[39mself\u001b[39m, model, tb_log_name, total_timesteps\u001b[39m=\u001b[39m\u001b[39m5000\u001b[39m):\n\u001b[0;32m--> 102\u001b[0m     model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    103\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    104\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    105\u001b[0m         callback\u001b[39m=\u001b[39;49mTensorboardCallback(),\n\u001b[1;32m    106\u001b[0m     )\n\u001b[1;32m    107\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/FinRl/lib/python3.8/site-packages/stable_baselines3/sac/sac.py:298\u001b[0m, in \u001b[0;36mSAC.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    286\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    287\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    295\u001b[0m     reset_num_timesteps: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    296\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OffPolicyAlgorithm:\n\u001b[0;32m--> 298\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    299\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    300\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    301\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    302\u001b[0m         eval_env\u001b[39m=\u001b[39;49meval_env,\n\u001b[1;32m    303\u001b[0m         eval_freq\u001b[39m=\u001b[39;49meval_freq,\n\u001b[1;32m    304\u001b[0m         n_eval_episodes\u001b[39m=\u001b[39;49mn_eval_episodes,\n\u001b[1;32m    305\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    306\u001b[0m         eval_log_path\u001b[39m=\u001b[39;49meval_log_path,\n\u001b[1;32m    307\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    308\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/FinRl/lib/python3.8/site-packages/stable_baselines3/common/off_policy_algorithm.py:363\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[39m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[1;32m    362\u001b[0m         \u001b[39mif\u001b[39;00m gradient_steps \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 363\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size, gradient_steps\u001b[39m=\u001b[39;49mgradient_steps)\n\u001b[1;32m    365\u001b[0m callback\u001b[39m.\u001b[39mon_training_end()\n\u001b[1;32m    367\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/FinRl/lib/python3.8/site-packages/stable_baselines3/sac/sac.py:239\u001b[0m, in \u001b[0;36mSAC.train\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    237\u001b[0m next_actions, next_log_prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactor\u001b[39m.\u001b[39maction_log_prob(replay_data\u001b[39m.\u001b[39mnext_observations)\n\u001b[1;32m    238\u001b[0m \u001b[39m# Compute the next Q values: min over all critics targets\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m next_q_values \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mcat(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcritic_target(replay_data\u001b[39m.\u001b[39;49mnext_observations, next_actions), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    240\u001b[0m next_q_values, _ \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mmin(next_q_values, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    241\u001b[0m \u001b[39m# add entropy term\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/FinRl/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/FinRl/lib/python3.8/site-packages/stable_baselines3/common/policies.py:885\u001b[0m, in \u001b[0;36mContinuousCritic.forward\u001b[0;34m(self, obs, actions)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshare_features_extractor):\n\u001b[1;32m    884\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_features(obs)\n\u001b[0;32m--> 885\u001b[0m qvalue_input \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39;49mcat([features, actions], dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    886\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(q_net(qvalue_input) \u001b[39mfor\u001b[39;00m q_net \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_networks)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_name = 'sac_'\n",
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=60000)\n",
    "trained_sac.save(os.path.join(TRAINED_MODEL_DIR, model_name + \".pth\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6: recurrentppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 13  |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 9   |\n",
      "|    total_timesteps | 128 |\n",
      "----------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 13         |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 19         |\n",
      "|    total_timesteps      | 256        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15408333 |\n",
      "|    clip_fraction        | 0.392      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.863     |\n",
      "|    explained_variance   | -0.28      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.465      |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | 0.431      |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 0.00468    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 21         |\n",
      "|    total_timesteps      | 384        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09988053 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.04      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.414      |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | 0.35       |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 0.0059     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 22         |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 22         |\n",
      "|    total_timesteps      | 512        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15821509 |\n",
      "|    clip_fraction        | 0.384      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.883     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.473      |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | 0.416      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.00376    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 23         |\n",
      "|    total_timesteps      | 640        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08317316 |\n",
      "|    clip_fraction        | 0.292      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.395      |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | 0.379      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.00516    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 28         |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 26         |\n",
      "|    total_timesteps      | 768        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16150594 |\n",
      "|    clip_fraction        | 0.505      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.705     |\n",
      "|    explained_variance   | -0.0297    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.297      |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | 0.288      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.00753    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 31          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 896         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.069801815 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.365       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | 0.392       |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.00087     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 34         |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 29         |\n",
      "|    total_timesteps      | 1024       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15124899 |\n",
      "|    clip_fraction        | 0.38       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.882     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.468      |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | 0.433      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.00103    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 37         |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 30         |\n",
      "|    total_timesteps      | 1152       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06769338 |\n",
      "|    clip_fraction        | 0.37       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.896     |\n",
      "|    explained_variance   | -0.142     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.364      |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | 0.442      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.000693   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 36         |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 35         |\n",
      "|    total_timesteps      | 1280       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15645479 |\n",
      "|    clip_fraction        | 0.479      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.742     |\n",
      "|    explained_variance   | -0.103     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.284      |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | 0.272      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.00162    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 38           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 1408         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052852547 |\n",
      "|    clip_fraction        | 0.21         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0467       |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | 0.292        |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000221     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 40         |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 38         |\n",
      "|    total_timesteps      | 1536       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03370288 |\n",
      "|    clip_fraction        | 0.353      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.923     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.168      |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | 0.362      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.000173   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 1664         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061935047 |\n",
      "|    clip_fraction        | 0.317        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.973       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0291       |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | 0.315        |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000182     |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 31        |\n",
      "|    iterations           | 14        |\n",
      "|    time_elapsed         | 57        |\n",
      "|    total_timesteps      | 1792      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1431268 |\n",
      "|    clip_fraction        | 0.377     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.893    |\n",
      "|    explained_variance   | -0.318    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.253     |\n",
      "|    n_updates            | 130       |\n",
      "|    policy_gradient_loss | 0.22      |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 0.000525  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 32         |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 59         |\n",
      "|    total_timesteps      | 1920       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12339346 |\n",
      "|    clip_fraction        | 0.36       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.929     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.436      |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | 0.414      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 6.06e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 33         |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 60         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07184786 |\n",
      "|    clip_fraction        | 0.296      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.296      |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | 0.328      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 5.43e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 35         |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 61         |\n",
      "|    total_timesteps      | 2176       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16030458 |\n",
      "|    clip_fraction        | 0.374      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.897     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.439      |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | 0.37       |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 6.56e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 34         |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 66         |\n",
      "|    total_timesteps      | 2304       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14065298 |\n",
      "|    clip_fraction        | 0.399      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.863     |\n",
      "|    explained_variance   | -0.681     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.234      |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | 0.221      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.000253   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 36         |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 67         |\n",
      "|    total_timesteps      | 2432       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09432593 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.412      |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | 0.391      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 2.85e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 37          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 2560        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048354544 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.285       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | 0.366       |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.88e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 38         |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 70         |\n",
      "|    total_timesteps      | 2688       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13321045 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.03      |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.462      |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | 0.366      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 1.63e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 38         |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 73         |\n",
      "|    total_timesteps      | 2816       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14739487 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.03      |\n",
      "|    explained_variance   | -1.64      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.206      |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | 0.146      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.000175   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 39         |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 74         |\n",
      "|    total_timesteps      | 2944       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11653935 |\n",
      "|    clip_fraction        | 0.358      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.927     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.429      |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | 0.425      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 2e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 40         |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 76         |\n",
      "|    total_timesteps      | 3072       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10517091 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.07      |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.422      |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | 0.33       |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 1.51e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 3200        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.104902156 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.411       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | 0.323       |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.16e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 3328        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.101244435 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.971      |\n",
      "|    explained_variance   | -5.57       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0988      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | 0.102       |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.94e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 3456        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027844852 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.155       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | 0.325       |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 6.52e-06    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 42        |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 84        |\n",
      "|    total_timesteps      | 3584      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1597437 |\n",
      "|    clip_fraction        | 0.349     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.93     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.299     |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | 0.233     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 1.1e-05   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 43        |\n",
      "|    iterations           | 29        |\n",
      "|    time_elapsed         | 85        |\n",
      "|    total_timesteps      | 3712      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1089355 |\n",
      "|    clip_fraction        | 0.333     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.95     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.178     |\n",
      "|    n_updates            | 280       |\n",
      "|    policy_gradient_loss | 0.171     |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.63e-05  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 43         |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 89         |\n",
      "|    total_timesteps      | 3840       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12448902 |\n",
      "|    clip_fraction        | 0.365      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.902     |\n",
      "|    explained_variance   | -6.81      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0763     |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | 0.0725     |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 8.51e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 3968        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.111158736 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00632    |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00396    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 4.39e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036548078 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.931      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.044       |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | 0.118       |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.6e-06     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 44         |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 94         |\n",
      "|    total_timesteps      | 4224       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08662726 |\n",
      "|    clip_fraction        | 0.348      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.93      |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0191     |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | 0.0272     |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 8.72e-07   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 44         |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 97         |\n",
      "|    total_timesteps      | 4352       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03746298 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | -82.5      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0216    |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0475    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 6.75e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 45          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 4480        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014671897 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.957      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.112      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.362      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 7.61e-07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 45          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 4608        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021620678 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0283     |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0739     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.75e-07    |\n",
      "-----------------------------------------\n",
      "day: 521, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999967.69\n",
      "total_reward: -32.31\n",
      "total_cost: 26.22\n",
      "total_trades: 441\n",
      "Sharpe: -0.968\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 46         |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 102        |\n",
      "|    total_timesteps      | 4736       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12244283 |\n",
      "|    clip_fraction        | 0.332      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.957     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.089     |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.08      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 7.1e-08    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 45         |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 106        |\n",
      "|    total_timesteps      | 4864       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16883782 |\n",
      "|    clip_fraction        | 0.395      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.86      |\n",
      "|    explained_variance   | -776       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0513    |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0415    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 5.49e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 4992        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013858112 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0178     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | 0.055       |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3.77e-07    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 46        |\n",
      "|    iterations           | 40        |\n",
      "|    time_elapsed         | 109       |\n",
      "|    total_timesteps      | 5120      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1256581 |\n",
      "|    clip_fraction        | 0.389     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.01     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.337     |\n",
      "|    n_updates            | 390       |\n",
      "|    policy_gradient_loss | 0.284     |\n",
      "|    std                  | 0.999     |\n",
      "|    value_loss           | 6.67e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 47         |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 110        |\n",
      "|    total_timesteps      | 5248       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14783949 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.389      |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | 0.26       |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 1.45e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 46         |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 115        |\n",
      "|    total_timesteps      | 5376       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10867713 |\n",
      "|    clip_fraction        | 0.408      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.839     |\n",
      "|    explained_variance   | -6.56e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0227    |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0275    |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 5.14e-05   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 47        |\n",
      "|    iterations           | 43        |\n",
      "|    time_elapsed         | 116       |\n",
      "|    total_timesteps      | 5504      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0760449 |\n",
      "|    clip_fraction        | 0.384     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.909    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.307     |\n",
      "|    n_updates            | 420       |\n",
      "|    policy_gradient_loss | 0.419     |\n",
      "|    std                  | 0.993     |\n",
      "|    value_loss           | 6.96e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 47         |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 118        |\n",
      "|    total_timesteps      | 5632       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15575205 |\n",
      "|    clip_fraction        | 0.307      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.985     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.466      |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | 0.332      |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 2.55e-08   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 48        |\n",
      "|    iterations           | 45        |\n",
      "|    time_elapsed         | 119       |\n",
      "|    total_timesteps      | 5760      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1564574 |\n",
      "|    clip_fraction        | 0.311     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.973    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.455     |\n",
      "|    n_updates            | 440       |\n",
      "|    policy_gradient_loss | 0.36      |\n",
      "|    std                  | 0.992     |\n",
      "|    value_loss           | 1.88e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 47         |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 123        |\n",
      "|    total_timesteps      | 5888       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20510347 |\n",
      "|    clip_fraction        | 0.489      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.72      |\n",
      "|    explained_variance   | -7.82e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0333    |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0301    |\n",
      "|    std                  | 0.991      |\n",
      "|    value_loss           | 4.23e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 47          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 6016        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.097795665 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.892      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.381       |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | 0.434       |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 2.62e-08    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 48         |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 126        |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14543793 |\n",
      "|    clip_fraction        | 0.211      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.11      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.455      |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | 0.287      |\n",
      "|    std                  | 0.989      |\n",
      "|    value_loss           | 1.5e-08    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 48         |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 128        |\n",
      "|    total_timesteps      | 6272       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13879074 |\n",
      "|    clip_fraction        | 0.291      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.434      |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | 0.331      |\n",
      "|    std                  | 0.987      |\n",
      "|    value_loss           | 2.32e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 48         |\n",
      "|    iterations           | 50         |\n",
      "|    time_elapsed         | 133        |\n",
      "|    total_timesteps      | 6400       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16466427 |\n",
      "|    clip_fraction        | 0.539      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.648     |\n",
      "|    explained_variance   | -7.34e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0291    |\n",
      "|    n_updates            | 490        |\n",
      "|    policy_gradient_loss | -0.0304    |\n",
      "|    std                  | 0.986      |\n",
      "|    value_loss           | 3.67e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 48         |\n",
      "|    iterations           | 51         |\n",
      "|    time_elapsed         | 134        |\n",
      "|    total_timesteps      | 6528       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15399475 |\n",
      "|    clip_fraction        | 0.29       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.996     |\n",
      "|    explained_variance   | 1.21e-05   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.462      |\n",
      "|    n_updates            | 500        |\n",
      "|    policy_gradient_loss | 0.362      |\n",
      "|    std                  | 0.985      |\n",
      "|    value_loss           | 1.86e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 48         |\n",
      "|    iterations           | 52         |\n",
      "|    time_elapsed         | 136        |\n",
      "|    total_timesteps      | 6656       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07069981 |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.03      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.341      |\n",
      "|    n_updates            | 510        |\n",
      "|    policy_gradient_loss | 0.389      |\n",
      "|    std                  | 0.988      |\n",
      "|    value_loss           | 9.33e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 49         |\n",
      "|    iterations           | 53         |\n",
      "|    time_elapsed         | 137        |\n",
      "|    total_timesteps      | 6784       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11164945 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.998     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.387      |\n",
      "|    n_updates            | 520        |\n",
      "|    policy_gradient_loss | 0.337      |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 4.28e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 49         |\n",
      "|    iterations           | 54         |\n",
      "|    time_elapsed         | 139        |\n",
      "|    total_timesteps      | 6912       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15012172 |\n",
      "|    clip_fraction        | 0.399      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.873     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.425      |\n",
      "|    n_updates            | 530        |\n",
      "|    policy_gradient_loss | 0.405      |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 3.65e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 48         |\n",
      "|    iterations           | 55         |\n",
      "|    time_elapsed         | 144        |\n",
      "|    total_timesteps      | 7040       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22074872 |\n",
      "|    clip_fraction        | 0.541      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.648     |\n",
      "|    explained_variance   | -1.21e+04  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0409    |\n",
      "|    n_updates            | 540        |\n",
      "|    policy_gradient_loss | -0.0358    |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 3.52e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 49         |\n",
      "|    iterations           | 56         |\n",
      "|    time_elapsed         | 145        |\n",
      "|    total_timesteps      | 7168       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15641776 |\n",
      "|    clip_fraction        | 0.336      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.936     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.466      |\n",
      "|    n_updates            | 550        |\n",
      "|    policy_gradient_loss | 0.419      |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 1.61e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 49         |\n",
      "|    iterations           | 57         |\n",
      "|    time_elapsed         | 147        |\n",
      "|    total_timesteps      | 7296       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17036983 |\n",
      "|    clip_fraction        | 0.347      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.919     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.461      |\n",
      "|    n_updates            | 560        |\n",
      "|    policy_gradient_loss | 0.406      |\n",
      "|    std                  | 0.988      |\n",
      "|    value_loss           | 6.55e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 49         |\n",
      "|    iterations           | 58         |\n",
      "|    time_elapsed         | 148        |\n",
      "|    total_timesteps      | 7424       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10111868 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.362      |\n",
      "|    n_updates            | 570        |\n",
      "|    policy_gradient_loss | 0.337      |\n",
      "|    std                  | 0.985      |\n",
      "|    value_loss           | 2.01e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 49         |\n",
      "|    iterations           | 59         |\n",
      "|    time_elapsed         | 153        |\n",
      "|    total_timesteps      | 7552       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14264031 |\n",
      "|    clip_fraction        | 0.501      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.7       |\n",
      "|    explained_variance   | -7.47e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0247    |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | -0.0322    |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 3.66e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 7680        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.102023624 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.947      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.336       |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | 0.403       |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 6.82e-08    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 50         |\n",
      "|    iterations           | 61         |\n",
      "|    time_elapsed         | 156        |\n",
      "|    total_timesteps      | 7808       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15964685 |\n",
      "|    clip_fraction        | 0.429      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.801     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.463      |\n",
      "|    n_updates            | 600        |\n",
      "|    policy_gradient_loss | 0.46       |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 2.35e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 50         |\n",
      "|    iterations           | 62         |\n",
      "|    time_elapsed         | 157        |\n",
      "|    total_timesteps      | 7936       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10198855 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.393      |\n",
      "|    n_updates            | 610        |\n",
      "|    policy_gradient_loss | 0.402      |\n",
      "|    std                  | 0.985      |\n",
      "|    value_loss           | 7.45e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 49         |\n",
      "|    iterations           | 63         |\n",
      "|    time_elapsed         | 162        |\n",
      "|    total_timesteps      | 8064       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19069375 |\n",
      "|    clip_fraction        | 0.463      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.753     |\n",
      "|    explained_variance   | -4.2e+03   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0314    |\n",
      "|    n_updates            | 620        |\n",
      "|    policy_gradient_loss | -0.0285    |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 3.76e-05   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 50        |\n",
      "|    iterations           | 64        |\n",
      "|    time_elapsed         | 163       |\n",
      "|    total_timesteps      | 8192      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1685556 |\n",
      "|    clip_fraction        | 0.295     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.988    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.469     |\n",
      "|    n_updates            | 630       |\n",
      "|    policy_gradient_loss | 0.393     |\n",
      "|    std                  | 0.982     |\n",
      "|    value_loss           | 2.97e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 50         |\n",
      "|    iterations           | 65         |\n",
      "|    time_elapsed         | 164        |\n",
      "|    total_timesteps      | 8320       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14001903 |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.426      |\n",
      "|    n_updates            | 640        |\n",
      "|    policy_gradient_loss | 0.354      |\n",
      "|    std                  | 0.981      |\n",
      "|    value_loss           | 1.59e-08   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 50        |\n",
      "|    iterations           | 66        |\n",
      "|    time_elapsed         | 166       |\n",
      "|    total_timesteps      | 8448      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1624584 |\n",
      "|    clip_fraction        | 0.334     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.944    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.451     |\n",
      "|    n_updates            | 650       |\n",
      "|    policy_gradient_loss | 0.407     |\n",
      "|    std                  | 0.98      |\n",
      "|    value_loss           | 4.91e-09  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 50         |\n",
      "|    iterations           | 67         |\n",
      "|    time_elapsed         | 170        |\n",
      "|    total_timesteps      | 8576       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23852569 |\n",
      "|    clip_fraction        | 0.537      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.728     |\n",
      "|    explained_variance   | -3.16e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.039     |\n",
      "|    n_updates            | 660        |\n",
      "|    policy_gradient_loss | -0.0347    |\n",
      "|    std                  | 0.981      |\n",
      "|    value_loss           | 3.48e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 8704        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.068229266 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.974      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | 0.363       |\n",
      "|    std                  | 0.982       |\n",
      "|    value_loss           | 1.97e-08    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 50         |\n",
      "|    iterations           | 69         |\n",
      "|    time_elapsed         | 173        |\n",
      "|    total_timesteps      | 8832       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10282493 |\n",
      "|    clip_fraction        | 0.254      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.249      |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | 0.352      |\n",
      "|    std                  | 0.983      |\n",
      "|    value_loss           | 1.83e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 70         |\n",
      "|    time_elapsed         | 174        |\n",
      "|    total_timesteps      | 8960       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18163605 |\n",
      "|    clip_fraction        | 0.324      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.952     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.469      |\n",
      "|    n_updates            | 690        |\n",
      "|    policy_gradient_loss | 0.405      |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 9.65e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 50         |\n",
      "|    iterations           | 71         |\n",
      "|    time_elapsed         | 178        |\n",
      "|    total_timesteps      | 9088       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21353415 |\n",
      "|    clip_fraction        | 0.413      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.845     |\n",
      "|    explained_variance   | -5.31e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0437    |\n",
      "|    n_updates            | 700        |\n",
      "|    policy_gradient_loss | -0.0317    |\n",
      "|    std                  | 0.985      |\n",
      "|    value_loss           | 3.86e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 72         |\n",
      "|    time_elapsed         | 180        |\n",
      "|    total_timesteps      | 9216       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10872651 |\n",
      "|    clip_fraction        | 0.374      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.02      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.364      |\n",
      "|    n_updates            | 710        |\n",
      "|    policy_gradient_loss | 0.372      |\n",
      "|    std                  | 0.986      |\n",
      "|    value_loss           | 2.05e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 73         |\n",
      "|    time_elapsed         | 181        |\n",
      "|    total_timesteps      | 9344       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15029989 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.428      |\n",
      "|    n_updates            | 720        |\n",
      "|    policy_gradient_loss | 0.338      |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 2.53e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 74         |\n",
      "|    time_elapsed         | 183        |\n",
      "|    total_timesteps      | 9472       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12373399 |\n",
      "|    clip_fraction        | 0.407      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.891     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.342      |\n",
      "|    n_updates            | 730        |\n",
      "|    policy_gradient_loss | 0.391      |\n",
      "|    std                  | 0.981      |\n",
      "|    value_loss           | 2.47e-09   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 187         |\n",
      "|    total_timesteps      | 9600        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.094799474 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -8.42e+03   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0222     |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    std                  | 0.981       |\n",
      "|    value_loss           | 4.66e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 76         |\n",
      "|    time_elapsed         | 188        |\n",
      "|    total_timesteps      | 9728       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14130296 |\n",
      "|    clip_fraction        | 0.352      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.907     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.443      |\n",
      "|    n_updates            | 750        |\n",
      "|    policy_gradient_loss | 0.407      |\n",
      "|    std                  | 0.98       |\n",
      "|    value_loss           | 4.39e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 77         |\n",
      "|    time_elapsed         | 190        |\n",
      "|    total_timesteps      | 9856       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15193553 |\n",
      "|    clip_fraction        | 0.271      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.43       |\n",
      "|    n_updates            | 760        |\n",
      "|    policy_gradient_loss | 0.341      |\n",
      "|    std                  | 0.98       |\n",
      "|    value_loss           | 1.02e-08   |\n",
      "----------------------------------------\n",
      "day: 521, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999998.49\n",
      "total_reward: -1.51\n",
      "total_cost: 2.28\n",
      "total_trades: 56\n",
      "Sharpe: -0.754\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 78         |\n",
      "|    time_elapsed         | 191        |\n",
      "|    total_timesteps      | 9984       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12814093 |\n",
      "|    clip_fraction        | 0.291      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.992     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.398      |\n",
      "|    n_updates            | 770        |\n",
      "|    policy_gradient_loss | 0.394      |\n",
      "|    std                  | 0.979      |\n",
      "|    value_loss           | 4.95e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 79         |\n",
      "|    time_elapsed         | 195        |\n",
      "|    total_timesteps      | 10112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04398776 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.957     |\n",
      "|    explained_variance   | -2.74e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.016     |\n",
      "|    n_updates            | 780        |\n",
      "|    policy_gradient_loss | -0.024     |\n",
      "|    std                  | 0.979      |\n",
      "|    value_loss           | 3.92e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 80         |\n",
      "|    time_elapsed         | 197        |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17542498 |\n",
      "|    clip_fraction        | 0.447      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.859     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.431      |\n",
      "|    n_updates            | 790        |\n",
      "|    policy_gradient_loss | 0.422      |\n",
      "|    std                  | 0.979      |\n",
      "|    value_loss           | 1.86e-08   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 52        |\n",
      "|    iterations           | 81        |\n",
      "|    time_elapsed         | 198       |\n",
      "|    total_timesteps      | 10368     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1721585 |\n",
      "|    clip_fraction        | 0.32      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.951    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.464     |\n",
      "|    n_updates            | 800       |\n",
      "|    policy_gradient_loss | 0.425     |\n",
      "|    std                  | 0.98      |\n",
      "|    value_loss           | 1.84e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 82         |\n",
      "|    time_elapsed         | 200        |\n",
      "|    total_timesteps      | 10496      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18671098 |\n",
      "|    clip_fraction        | 0.334      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.976     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.463      |\n",
      "|    n_updates            | 810        |\n",
      "|    policy_gradient_loss | 0.379      |\n",
      "|    std                  | 0.982      |\n",
      "|    value_loss           | 4.41e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 83         |\n",
      "|    time_elapsed         | 203        |\n",
      "|    total_timesteps      | 10624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17494391 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | -4.63e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0178    |\n",
      "|    n_updates            | 820        |\n",
      "|    policy_gradient_loss | -0.0202    |\n",
      "|    std                  | 0.983      |\n",
      "|    value_loss           | 3.95e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 10752       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.096080355 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.943      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.324       |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | 0.4         |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 5.58e-08    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 10880       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.119037315 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.397       |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | 0.351       |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 2.81e-08    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 86         |\n",
      "|    time_elapsed         | 208        |\n",
      "|    total_timesteps      | 11008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12534127 |\n",
      "|    clip_fraction        | 0.319      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.965     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.403      |\n",
      "|    n_updates            | 850        |\n",
      "|    policy_gradient_loss | 0.393      |\n",
      "|    std                  | 0.983      |\n",
      "|    value_loss           | 4.8e-09    |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 52        |\n",
      "|    iterations           | 87        |\n",
      "|    time_elapsed         | 212       |\n",
      "|    total_timesteps      | 11136     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1570932 |\n",
      "|    clip_fraction        | 0.34      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.925    |\n",
      "|    explained_variance   | -3.2e+03  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0248   |\n",
      "|    n_updates            | 860       |\n",
      "|    policy_gradient_loss | -0.0205   |\n",
      "|    std                  | 0.983     |\n",
      "|    value_loss           | 3.33e-05  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 88         |\n",
      "|    time_elapsed         | 213        |\n",
      "|    total_timesteps      | 11264      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07039478 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.291      |\n",
      "|    n_updates            | 870        |\n",
      "|    policy_gradient_loss | 0.316      |\n",
      "|    std                  | 0.981      |\n",
      "|    value_loss           | 3.41e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 89         |\n",
      "|    time_elapsed         | 215        |\n",
      "|    total_timesteps      | 11392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09345385 |\n",
      "|    clip_fraction        | 0.293      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.322      |\n",
      "|    n_updates            | 880        |\n",
      "|    policy_gradient_loss | 0.356      |\n",
      "|    std                  | 0.98       |\n",
      "|    value_loss           | 1.35e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 90         |\n",
      "|    time_elapsed         | 216        |\n",
      "|    total_timesteps      | 11520      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12922306 |\n",
      "|    clip_fraction        | 0.419      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.874     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.395      |\n",
      "|    n_updates            | 890        |\n",
      "|    policy_gradient_loss | 0.426      |\n",
      "|    std                  | 0.978      |\n",
      "|    value_loss           | 1.15e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 91         |\n",
      "|    time_elapsed         | 220        |\n",
      "|    total_timesteps      | 11648      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15035681 |\n",
      "|    clip_fraction        | 0.383      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.876     |\n",
      "|    explained_variance   | -1.96e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0317    |\n",
      "|    n_updates            | 900        |\n",
      "|    policy_gradient_loss | -0.0246    |\n",
      "|    std                  | 0.978      |\n",
      "|    value_loss           | 2.95e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 92         |\n",
      "|    time_elapsed         | 221        |\n",
      "|    total_timesteps      | 11776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12035959 |\n",
      "|    clip_fraction        | 0.365      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.886     |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.409      |\n",
      "|    n_updates            | 910        |\n",
      "|    policy_gradient_loss | 0.421      |\n",
      "|    std                  | 0.977      |\n",
      "|    value_loss           | 1.84e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 93         |\n",
      "|    time_elapsed         | 223        |\n",
      "|    total_timesteps      | 11904      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12756334 |\n",
      "|    clip_fraction        | 0.378      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.868     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.429      |\n",
      "|    n_updates            | 920        |\n",
      "|    policy_gradient_loss | 0.445      |\n",
      "|    std                  | 0.977      |\n",
      "|    value_loss           | 9.38e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 94         |\n",
      "|    time_elapsed         | 224        |\n",
      "|    total_timesteps      | 12032      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17120348 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.998     |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.457      |\n",
      "|    n_updates            | 930        |\n",
      "|    policy_gradient_loss | 0.353      |\n",
      "|    std                  | 0.977      |\n",
      "|    value_loss           | 4.54e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 95         |\n",
      "|    time_elapsed         | 229        |\n",
      "|    total_timesteps      | 12160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20388219 |\n",
      "|    clip_fraction        | 0.502      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.695     |\n",
      "|    explained_variance   | -2.46e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0315    |\n",
      "|    n_updates            | 940        |\n",
      "|    policy_gradient_loss | -0.0265    |\n",
      "|    std                  | 0.978      |\n",
      "|    value_loss           | 2.24e-05   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 53        |\n",
      "|    iterations           | 96        |\n",
      "|    time_elapsed         | 230       |\n",
      "|    total_timesteps      | 12288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1192852 |\n",
      "|    clip_fraction        | 0.274     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.02     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.42      |\n",
      "|    n_updates            | 950       |\n",
      "|    policy_gradient_loss | 0.376     |\n",
      "|    std                  | 0.981     |\n",
      "|    value_loss           | 1.42e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 97         |\n",
      "|    time_elapsed         | 231        |\n",
      "|    total_timesteps      | 12416      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16774896 |\n",
      "|    clip_fraction        | 0.353      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.907     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.472      |\n",
      "|    n_updates            | 960        |\n",
      "|    policy_gradient_loss | 0.435      |\n",
      "|    std                  | 0.983      |\n",
      "|    value_loss           | 9.67e-09   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 12544       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021669138 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0439      |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | 0.352       |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 7.97e-09    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 99         |\n",
      "|    time_elapsed         | 237        |\n",
      "|    total_timesteps      | 12672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18971162 |\n",
      "|    clip_fraction        | 0.487      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.719     |\n",
      "|    explained_variance   | -1.57e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0231    |\n",
      "|    n_updates            | 980        |\n",
      "|    policy_gradient_loss | -0.0229    |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 2.18e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 100        |\n",
      "|    time_elapsed         | 239        |\n",
      "|    total_timesteps      | 12800      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14029193 |\n",
      "|    clip_fraction        | 0.332      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.937     |\n",
      "|    explained_variance   | 1.79e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.428      |\n",
      "|    n_updates            | 990        |\n",
      "|    policy_gradient_loss | 0.411      |\n",
      "|    std                  | 0.983      |\n",
      "|    value_loss           | 1.96e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 101        |\n",
      "|    time_elapsed         | 241        |\n",
      "|    total_timesteps      | 12928      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15854296 |\n",
      "|    clip_fraction        | 0.344      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.919     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.448      |\n",
      "|    n_updates            | 1000       |\n",
      "|    policy_gradient_loss | 0.425      |\n",
      "|    std                  | 0.98       |\n",
      "|    value_loss           | 8.23e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 102        |\n",
      "|    time_elapsed         | 243        |\n",
      "|    total_timesteps      | 13056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12381333 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.969     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.314      |\n",
      "|    n_updates            | 1010       |\n",
      "|    policy_gradient_loss | 0.384      |\n",
      "|    std                  | 0.977      |\n",
      "|    value_loss           | 1.29e-08   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 52        |\n",
      "|    iterations           | 103       |\n",
      "|    time_elapsed         | 248       |\n",
      "|    total_timesteps      | 13184     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2352863 |\n",
      "|    clip_fraction        | 0.532     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.653    |\n",
      "|    explained_variance   | -2.01e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0259   |\n",
      "|    n_updates            | 1020      |\n",
      "|    policy_gradient_loss | -0.0243   |\n",
      "|    std                  | 0.974     |\n",
      "|    value_loss           | 1.87e-05  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 251         |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.082250886 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.0001      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | 0.317       |\n",
      "|    std                  | 0.973       |\n",
      "|    value_loss           | 1.89e-08    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 53        |\n",
      "|    iterations           | 105       |\n",
      "|    time_elapsed         | 252       |\n",
      "|    total_timesteps      | 13440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1577104 |\n",
      "|    clip_fraction        | 0.388     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.858    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.411     |\n",
      "|    n_updates            | 1040      |\n",
      "|    policy_gradient_loss | 0.446     |\n",
      "|    std                  | 0.971     |\n",
      "|    value_loss           | 1.32e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 106        |\n",
      "|    time_elapsed         | 254        |\n",
      "|    total_timesteps      | 13568      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15075754 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.358      |\n",
      "|    n_updates            | 1050       |\n",
      "|    policy_gradient_loss | 0.367      |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 6.72e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 107        |\n",
      "|    time_elapsed         | 255        |\n",
      "|    total_timesteps      | 13696      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18083079 |\n",
      "|    clip_fraction        | 0.343      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.924     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.361      |\n",
      "|    n_updates            | 1060       |\n",
      "|    policy_gradient_loss | 0.414      |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 8.82e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 108        |\n",
      "|    time_elapsed         | 261        |\n",
      "|    total_timesteps      | 13824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26905802 |\n",
      "|    clip_fraction        | 0.503      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.703     |\n",
      "|    explained_variance   | -1.85e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0285    |\n",
      "|    n_updates            | 1070       |\n",
      "|    policy_gradient_loss | -0.0252    |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 1.89e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 109        |\n",
      "|    time_elapsed         | 262        |\n",
      "|    total_timesteps      | 13952      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18697943 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.402      |\n",
      "|    n_updates            | 1080       |\n",
      "|    policy_gradient_loss | 0.36       |\n",
      "|    std                  | 0.967      |\n",
      "|    value_loss           | 4.24e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 110        |\n",
      "|    time_elapsed         | 264        |\n",
      "|    total_timesteps      | 14080      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17542388 |\n",
      "|    clip_fraction        | 0.254      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.03      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.207      |\n",
      "|    n_updates            | 1090       |\n",
      "|    policy_gradient_loss | 0.34       |\n",
      "|    std                  | 0.965      |\n",
      "|    value_loss           | 2.03e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 111        |\n",
      "|    time_elapsed         | 268        |\n",
      "|    total_timesteps      | 14208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24068199 |\n",
      "|    clip_fraction        | 0.406      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.9       |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.291      |\n",
      "|    n_updates            | 1100       |\n",
      "|    policy_gradient_loss | 0.399      |\n",
      "|    std                  | 0.966      |\n",
      "|    value_loss           | 1.07e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 112        |\n",
      "|    time_elapsed         | 273        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33830276 |\n",
      "|    clip_fraction        | 0.49       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.707     |\n",
      "|    explained_variance   | -557       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0189    |\n",
      "|    n_updates            | 1110       |\n",
      "|    policy_gradient_loss | -0.0192    |\n",
      "|    std                  | 0.967      |\n",
      "|    value_loss           | 1.78e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 113        |\n",
      "|    time_elapsed         | 274        |\n",
      "|    total_timesteps      | 14464      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24228178 |\n",
      "|    clip_fraction        | 0.293      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.988     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.313      |\n",
      "|    n_updates            | 1120       |\n",
      "|    policy_gradient_loss | 0.381      |\n",
      "|    std                  | 0.967      |\n",
      "|    value_loss           | 6.82e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 114        |\n",
      "|    time_elapsed         | 276        |\n",
      "|    total_timesteps      | 14592      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25708795 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.968     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.404      |\n",
      "|    n_updates            | 1130       |\n",
      "|    policy_gradient_loss | 0.391      |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 5.38e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 115        |\n",
      "|    time_elapsed         | 277        |\n",
      "|    total_timesteps      | 14720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26889545 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.02      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.459      |\n",
      "|    n_updates            | 1140       |\n",
      "|    policy_gradient_loss | 0.352      |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 1.3e-08    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 116        |\n",
      "|    time_elapsed         | 282        |\n",
      "|    total_timesteps      | 14848      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35094166 |\n",
      "|    clip_fraction        | 0.489      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.712     |\n",
      "|    explained_variance   | -602       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.028     |\n",
      "|    n_updates            | 1150       |\n",
      "|    policy_gradient_loss | -0.0219    |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 1.67e-05   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 52        |\n",
      "|    iterations           | 117       |\n",
      "|    time_elapsed         | 283       |\n",
      "|    total_timesteps      | 14976     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2417387 |\n",
      "|    clip_fraction        | 0.275     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.04     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.471     |\n",
      "|    n_updates            | 1160      |\n",
      "|    policy_gradient_loss | 0.319     |\n",
      "|    std                  | 0.97      |\n",
      "|    value_loss           | 1.94e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 118        |\n",
      "|    time_elapsed         | 284        |\n",
      "|    total_timesteps      | 15104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22571036 |\n",
      "|    clip_fraction        | 0.311      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.956     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.461      |\n",
      "|    n_updates            | 1170       |\n",
      "|    policy_gradient_loss | 0.404      |\n",
      "|    std                  | 0.967      |\n",
      "|    value_loss           | 2.97e-08   |\n",
      "----------------------------------------\n",
      "day: 521, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999999.94\n",
      "total_reward: -0.06\n",
      "total_cost: 0.19\n",
      "total_trades: 2\n",
      "Sharpe: -0.413\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 119        |\n",
      "|    time_elapsed         | 286        |\n",
      "|    total_timesteps      | 15232      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20417967 |\n",
      "|    clip_fraction        | 0.342      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.911     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.342      |\n",
      "|    n_updates            | 1180       |\n",
      "|    policy_gradient_loss | 0.417      |\n",
      "|    std                  | 0.967      |\n",
      "|    value_loss           | 2.05e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 120        |\n",
      "|    time_elapsed         | 291        |\n",
      "|    total_timesteps      | 15360      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30024454 |\n",
      "|    clip_fraction        | 0.431      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.795     |\n",
      "|    explained_variance   | -356       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0275    |\n",
      "|    n_updates            | 1190       |\n",
      "|    policy_gradient_loss | -0.0183    |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 1.75e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 121        |\n",
      "|    time_elapsed         | 293        |\n",
      "|    total_timesteps      | 15488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17893094 |\n",
      "|    clip_fraction        | 0.308      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.978     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.408      |\n",
      "|    n_updates            | 1200       |\n",
      "|    policy_gradient_loss | 0.388      |\n",
      "|    std                  | 0.969      |\n",
      "|    value_loss           | 1.48e-08   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 52        |\n",
      "|    iterations           | 122       |\n",
      "|    time_elapsed         | 294       |\n",
      "|    total_timesteps      | 15616     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1971894 |\n",
      "|    clip_fraction        | 0.317     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.948    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.454     |\n",
      "|    n_updates            | 1210      |\n",
      "|    policy_gradient_loss | 0.4       |\n",
      "|    std                  | 0.97      |\n",
      "|    value_loss           | 2.15e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 123        |\n",
      "|    time_elapsed         | 296        |\n",
      "|    total_timesteps      | 15744      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22432803 |\n",
      "|    clip_fraction        | 0.405      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.828     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.468      |\n",
      "|    n_updates            | 1220       |\n",
      "|    policy_gradient_loss | 0.443      |\n",
      "|    std                  | 0.973      |\n",
      "|    value_loss           | 1.56e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 124        |\n",
      "|    time_elapsed         | 300        |\n",
      "|    total_timesteps      | 15872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30040848 |\n",
      "|    clip_fraction        | 0.392      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.846     |\n",
      "|    explained_variance   | -404       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0153    |\n",
      "|    n_updates            | 1230       |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    std                  | 0.974      |\n",
      "|    value_loss           | 1.77e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 125        |\n",
      "|    time_elapsed         | 302        |\n",
      "|    total_timesteps      | 16000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19886218 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.954     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.468      |\n",
      "|    n_updates            | 1240       |\n",
      "|    policy_gradient_loss | 0.393      |\n",
      "|    std                  | 0.971      |\n",
      "|    value_loss           | 1.71e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 126        |\n",
      "|    time_elapsed         | 303        |\n",
      "|    total_timesteps      | 16128      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16589074 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.11      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.345      |\n",
      "|    n_updates            | 1250       |\n",
      "|    policy_gradient_loss | 0.292      |\n",
      "|    std                  | 0.969      |\n",
      "|    value_loss           | 2.71e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 127        |\n",
      "|    time_elapsed         | 305        |\n",
      "|    total_timesteps      | 16256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16224924 |\n",
      "|    clip_fraction        | 0.341      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.914     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.342      |\n",
      "|    n_updates            | 1260       |\n",
      "|    policy_gradient_loss | 0.401      |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 4.99e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 128        |\n",
      "|    time_elapsed         | 309        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29886964 |\n",
      "|    clip_fraction        | 0.35       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.904     |\n",
      "|    explained_variance   | -1.27e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0259    |\n",
      "|    n_updates            | 1270       |\n",
      "|    policy_gradient_loss | -0.0202    |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 1.72e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 129        |\n",
      "|    time_elapsed         | 310        |\n",
      "|    total_timesteps      | 16512      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18994446 |\n",
      "|    clip_fraction        | 0.353      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.942     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.385      |\n",
      "|    n_updates            | 1280       |\n",
      "|    policy_gradient_loss | 0.395      |\n",
      "|    std                  | 0.967      |\n",
      "|    value_loss           | 2.3e-08    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 130        |\n",
      "|    time_elapsed         | 311        |\n",
      "|    total_timesteps      | 16640      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20036094 |\n",
      "|    clip_fraction        | 0.319      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.944     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.417      |\n",
      "|    n_updates            | 1290       |\n",
      "|    policy_gradient_loss | 0.401      |\n",
      "|    std                  | 0.966      |\n",
      "|    value_loss           | 4.31e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 131        |\n",
      "|    time_elapsed         | 313        |\n",
      "|    total_timesteps      | 16768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19303219 |\n",
      "|    clip_fraction        | 0.322      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.95      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.414      |\n",
      "|    n_updates            | 1300       |\n",
      "|    policy_gradient_loss | 0.386      |\n",
      "|    std                  | 0.966      |\n",
      "|    value_loss           | 6.88e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 132        |\n",
      "|    time_elapsed         | 316        |\n",
      "|    total_timesteps      | 16896      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28136742 |\n",
      "|    clip_fraction        | 0.333      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.923     |\n",
      "|    explained_variance   | -2e+03     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0203    |\n",
      "|    n_updates            | 1310       |\n",
      "|    policy_gradient_loss | -0.0203    |\n",
      "|    std                  | 0.965      |\n",
      "|    value_loss           | 1.58e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 133        |\n",
      "|    time_elapsed         | 317        |\n",
      "|    total_timesteps      | 17024      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15398653 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.986     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.366      |\n",
      "|    n_updates            | 1320       |\n",
      "|    policy_gradient_loss | 0.401      |\n",
      "|    std                  | 0.964      |\n",
      "|    value_loss           | 3.78e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 134        |\n",
      "|    time_elapsed         | 319        |\n",
      "|    total_timesteps      | 17152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06212515 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.07      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.101      |\n",
      "|    n_updates            | 1330       |\n",
      "|    policy_gradient_loss | 0.294      |\n",
      "|    std                  | 0.965      |\n",
      "|    value_loss           | 3.46e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 135        |\n",
      "|    time_elapsed         | 320        |\n",
      "|    total_timesteps      | 17280      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13536899 |\n",
      "|    clip_fraction        | 0.213      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.09      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.298      |\n",
      "|    n_updates            | 1340       |\n",
      "|    policy_gradient_loss | 0.317      |\n",
      "|    std                  | 0.966      |\n",
      "|    value_loss           | 3.93e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 136        |\n",
      "|    time_elapsed         | 323        |\n",
      "|    total_timesteps      | 17408      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21497847 |\n",
      "|    clip_fraction        | 0.344      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.907     |\n",
      "|    explained_variance   | -4.49e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0278    |\n",
      "|    n_updates            | 1350       |\n",
      "|    policy_gradient_loss | -0.0233    |\n",
      "|    std                  | 0.965      |\n",
      "|    value_loss           | 1.4e-05    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 137        |\n",
      "|    time_elapsed         | 325        |\n",
      "|    total_timesteps      | 17536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16601892 |\n",
      "|    clip_fraction        | 0.355      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.892     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.419      |\n",
      "|    n_updates            | 1360       |\n",
      "|    policy_gradient_loss | 0.428      |\n",
      "|    std                  | 0.965      |\n",
      "|    value_loss           | 2.28e-09   |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 138           |\n",
      "|    time_elapsed         | 326           |\n",
      "|    total_timesteps      | 17664         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6778318e-05 |\n",
      "|    clip_fraction        | 0.309         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.955        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.000509     |\n",
      "|    n_updates            | 1370          |\n",
      "|    policy_gradient_loss | 0.343         |\n",
      "|    std                  | 0.962         |\n",
      "|    value_loss           | 1.51e-09      |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 139        |\n",
      "|    time_elapsed         | 327        |\n",
      "|    total_timesteps      | 17792      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18648487 |\n",
      "|    clip_fraction        | 0.309      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.953     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.457      |\n",
      "|    n_updates            | 1380       |\n",
      "|    policy_gradient_loss | 0.396      |\n",
      "|    std                  | 0.963      |\n",
      "|    value_loss           | 4.94e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 140        |\n",
      "|    time_elapsed         | 330        |\n",
      "|    total_timesteps      | 17920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19754298 |\n",
      "|    clip_fraction        | 0.321      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.938     |\n",
      "|    explained_variance   | -3.34e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0107    |\n",
      "|    n_updates            | 1390       |\n",
      "|    policy_gradient_loss | -0.0204    |\n",
      "|    std                  | 0.963      |\n",
      "|    value_loss           | 1.3e-05    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 141        |\n",
      "|    time_elapsed         | 332        |\n",
      "|    total_timesteps      | 18048      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15839167 |\n",
      "|    clip_fraction        | 0.332      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.976     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.275      |\n",
      "|    n_updates            | 1400       |\n",
      "|    policy_gradient_loss | 0.376      |\n",
      "|    std                  | 0.963      |\n",
      "|    value_loss           | 4.52e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 142        |\n",
      "|    time_elapsed         | 333        |\n",
      "|    total_timesteps      | 18176      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17342357 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.03      |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.342      |\n",
      "|    n_updates            | 1410       |\n",
      "|    policy_gradient_loss | 0.357      |\n",
      "|    std                  | 0.965      |\n",
      "|    value_loss           | 1.8e-09    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 143        |\n",
      "|    time_elapsed         | 335        |\n",
      "|    total_timesteps      | 18304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20552282 |\n",
      "|    clip_fraction        | 0.335      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.923     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.429      |\n",
      "|    n_updates            | 1420       |\n",
      "|    policy_gradient_loss | 0.401      |\n",
      "|    std                  | 0.966      |\n",
      "|    value_loss           | 2.03e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 144        |\n",
      "|    time_elapsed         | 339        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26930004 |\n",
      "|    clip_fraction        | 0.457      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.797     |\n",
      "|    explained_variance   | -2.04e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0388    |\n",
      "|    n_updates            | 1430       |\n",
      "|    policy_gradient_loss | -0.0302    |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 9.85e-06   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 54        |\n",
      "|    iterations           | 145       |\n",
      "|    time_elapsed         | 340       |\n",
      "|    total_timesteps      | 18560     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2087599 |\n",
      "|    clip_fraction        | 0.272     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.08     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.277     |\n",
      "|    n_updates            | 1440      |\n",
      "|    policy_gradient_loss | 0.341     |\n",
      "|    std                  | 0.969     |\n",
      "|    value_loss           | 5.69e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 54        |\n",
      "|    iterations           | 146       |\n",
      "|    time_elapsed         | 342       |\n",
      "|    total_timesteps      | 18688     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2526217 |\n",
      "|    clip_fraction        | 0.272     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.01     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.31      |\n",
      "|    n_updates            | 1450      |\n",
      "|    policy_gradient_loss | 0.361     |\n",
      "|    std                  | 0.969     |\n",
      "|    value_loss           | 8.5e-09   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 147        |\n",
      "|    time_elapsed         | 343        |\n",
      "|    total_timesteps      | 18816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28696993 |\n",
      "|    clip_fraction        | 0.303      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.995     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.267      |\n",
      "|    n_updates            | 1460       |\n",
      "|    policy_gradient_loss | 0.369      |\n",
      "|    std                  | 0.969      |\n",
      "|    value_loss           | 2.11e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 148        |\n",
      "|    time_elapsed         | 347        |\n",
      "|    total_timesteps      | 18944      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37045002 |\n",
      "|    clip_fraction        | 0.5        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.694     |\n",
      "|    explained_variance   | -5.07e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0392    |\n",
      "|    n_updates            | 1470       |\n",
      "|    policy_gradient_loss | -0.0303    |\n",
      "|    std                  | 0.972      |\n",
      "|    value_loss           | 8.02e-06   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 149        |\n",
      "|    time_elapsed         | 349        |\n",
      "|    total_timesteps      | 19072      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21263412 |\n",
      "|    clip_fraction        | 0.375      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.886     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.347      |\n",
      "|    n_updates            | 1480       |\n",
      "|    policy_gradient_loss | 0.43       |\n",
      "|    std                  | 0.975      |\n",
      "|    value_loss           | 6.51e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 150        |\n",
      "|    time_elapsed         | 350        |\n",
      "|    total_timesteps      | 19200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24287042 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.98      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.397      |\n",
      "|    n_updates            | 1490       |\n",
      "|    policy_gradient_loss | 0.358      |\n",
      "|    std                  | 0.978      |\n",
      "|    value_loss           | 9.75e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 151        |\n",
      "|    time_elapsed         | 351        |\n",
      "|    total_timesteps      | 19328      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15489252 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.07      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.134      |\n",
      "|    n_updates            | 1500       |\n",
      "|    policy_gradient_loss | 0.323      |\n",
      "|    std                  | 0.978      |\n",
      "|    value_loss           | 1.05e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 152        |\n",
      "|    time_elapsed         | 355        |\n",
      "|    total_timesteps      | 19456      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33721283 |\n",
      "|    clip_fraction        | 0.454      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.763     |\n",
      "|    explained_variance   | -1.72e+04  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0375    |\n",
      "|    n_updates            | 1510       |\n",
      "|    policy_gradient_loss | -0.0338    |\n",
      "|    std                  | 0.98       |\n",
      "|    value_loss           | 8.44e-06   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 153        |\n",
      "|    time_elapsed         | 357        |\n",
      "|    total_timesteps      | 19584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20676519 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.08      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.163      |\n",
      "|    n_updates            | 1520       |\n",
      "|    policy_gradient_loss | 0.307      |\n",
      "|    std                  | 0.982      |\n",
      "|    value_loss           | 5.27e-09   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 358         |\n",
      "|    total_timesteps      | 19712       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.061283648 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0508      |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | 0.325       |\n",
      "|    std                  | 0.985       |\n",
      "|    value_loss           | 9.88e-09    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 155        |\n",
      "|    time_elapsed         | 359        |\n",
      "|    total_timesteps      | 19840      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27293795 |\n",
      "|    clip_fraction        | 0.259      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.465      |\n",
      "|    n_updates            | 1540       |\n",
      "|    policy_gradient_loss | 0.348      |\n",
      "|    std                  | 0.988      |\n",
      "|    value_loss           | 2.29e-08   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 54        |\n",
      "|    iterations           | 156       |\n",
      "|    time_elapsed         | 364       |\n",
      "|    total_timesteps      | 19968     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3291706 |\n",
      "|    clip_fraction        | 0.496     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.709    |\n",
      "|    explained_variance   | -1.59e+04 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0452   |\n",
      "|    n_updates            | 1550      |\n",
      "|    policy_gradient_loss | -0.0368   |\n",
      "|    std                  | 0.99      |\n",
      "|    value_loss           | 7.41e-06  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 157        |\n",
      "|    time_elapsed         | 365        |\n",
      "|    total_timesteps      | 20096      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22223936 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | 0.000278   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.425      |\n",
      "|    n_updates            | 1560       |\n",
      "|    policy_gradient_loss | 0.371      |\n",
      "|    std                  | 0.989      |\n",
      "|    value_loss           | 2.76e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 158       |\n",
      "|    time_elapsed         | 366       |\n",
      "|    total_timesteps      | 20224     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2952987 |\n",
      "|    clip_fraction        | 0.31      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.98     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.44      |\n",
      "|    n_updates            | 1570      |\n",
      "|    policy_gradient_loss | 0.387     |\n",
      "|    std                  | 0.989     |\n",
      "|    value_loss           | 9.83e-10  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 159        |\n",
      "|    time_elapsed         | 368        |\n",
      "|    total_timesteps      | 20352      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34380734 |\n",
      "|    clip_fraction        | 0.378      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.942     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.43       |\n",
      "|    n_updates            | 1580       |\n",
      "|    policy_gradient_loss | 0.397      |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 8.33e-10   |\n",
      "----------------------------------------\n",
      "day: 521, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999999.88\n",
      "total_reward: -0.12\n",
      "total_cost: 0.11\n",
      "total_trades: 6\n",
      "Sharpe: -1.325\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 160        |\n",
      "|    time_elapsed         | 369        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34046417 |\n",
      "|    clip_fraction        | 0.305      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.98      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.467      |\n",
      "|    n_updates            | 1590       |\n",
      "|    policy_gradient_loss | 0.391      |\n",
      "|    std                  | 0.991      |\n",
      "|    value_loss           | 4.38e-10   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 161       |\n",
      "|    time_elapsed         | 374       |\n",
      "|    total_timesteps      | 20608     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4440988 |\n",
      "|    clip_fraction        | 0.533     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.66     |\n",
      "|    explained_variance   | -7.35e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.034    |\n",
      "|    n_updates            | 1600      |\n",
      "|    policy_gradient_loss | -0.033    |\n",
      "|    std                  | 0.991     |\n",
      "|    value_loss           | 6.54e-06  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 162        |\n",
      "|    time_elapsed         | 375        |\n",
      "|    total_timesteps      | 20736      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27434355 |\n",
      "|    clip_fraction        | 0.365      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.919     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.429      |\n",
      "|    n_updates            | 1610       |\n",
      "|    policy_gradient_loss | 0.419      |\n",
      "|    std                  | 0.991      |\n",
      "|    value_loss           | 1.18e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 163        |\n",
      "|    time_elapsed         | 376        |\n",
      "|    total_timesteps      | 20864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22851957 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.167      |\n",
      "|    n_updates            | 1620       |\n",
      "|    policy_gradient_loss | 0.373      |\n",
      "|    std                  | 0.991      |\n",
      "|    value_loss           | 8.98e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 164       |\n",
      "|    time_elapsed         | 377       |\n",
      "|    total_timesteps      | 20992     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3191377 |\n",
      "|    clip_fraction        | 0.224     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.11     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.39      |\n",
      "|    n_updates            | 1630      |\n",
      "|    policy_gradient_loss | 0.329     |\n",
      "|    std                  | 0.992     |\n",
      "|    value_loss           | 1.16e-08  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 165       |\n",
      "|    time_elapsed         | 382       |\n",
      "|    total_timesteps      | 21120     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3930893 |\n",
      "|    clip_fraction        | 0.538     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.697    |\n",
      "|    explained_variance   | -2.74e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0425   |\n",
      "|    n_updates            | 1640      |\n",
      "|    policy_gradient_loss | -0.0344   |\n",
      "|    std                  | 0.992     |\n",
      "|    value_loss           | 6.36e-06  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 166        |\n",
      "|    time_elapsed         | 383        |\n",
      "|    total_timesteps      | 21248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32344392 |\n",
      "|    clip_fraction        | 0.387      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.865     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.272      |\n",
      "|    n_updates            | 1650       |\n",
      "|    policy_gradient_loss | 0.434      |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 3.2e-08    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 167        |\n",
      "|    time_elapsed         | 385        |\n",
      "|    total_timesteps      | 21376      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33000076 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.14      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.473     |\n",
      "|    n_updates            | 1660       |\n",
      "|    policy_gradient_loss | -0.304     |\n",
      "|    std                  | 0.994      |\n",
      "|    value_loss           | 1.77e-07   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 168       |\n",
      "|    time_elapsed         | 386       |\n",
      "|    total_timesteps      | 21504     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3363211 |\n",
      "|    clip_fraction        | 0.271     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.03     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.467    |\n",
      "|    n_updates            | 1670      |\n",
      "|    policy_gradient_loss | -0.366    |\n",
      "|    std                  | 0.995     |\n",
      "|    value_loss           | 6.49e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 169        |\n",
      "|    time_elapsed         | 389        |\n",
      "|    total_timesteps      | 21632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41651854 |\n",
      "|    clip_fraction        | 0.369      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.892     |\n",
      "|    explained_variance   | -2.2e+03   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0281    |\n",
      "|    n_updates            | 1680       |\n",
      "|    policy_gradient_loss | -0.0217    |\n",
      "|    std                  | 0.994      |\n",
      "|    value_loss           | 7.45e-06   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 170       |\n",
      "|    time_elapsed         | 391       |\n",
      "|    total_timesteps      | 21760     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3096369 |\n",
      "|    clip_fraction        | 0.352     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.915    |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.332     |\n",
      "|    n_updates            | 1690      |\n",
      "|    policy_gradient_loss | 0.412     |\n",
      "|    std                  | 0.992     |\n",
      "|    value_loss           | 1.11e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 171        |\n",
      "|    time_elapsed         | 392        |\n",
      "|    total_timesteps      | 21888      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32972544 |\n",
      "|    clip_fraction        | 0.359      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.904     |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.322      |\n",
      "|    n_updates            | 1700       |\n",
      "|    policy_gradient_loss | 0.432      |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 9.38e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 172       |\n",
      "|    time_elapsed         | 393       |\n",
      "|    total_timesteps      | 22016     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3317862 |\n",
      "|    clip_fraction        | 0.279     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.02     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.472     |\n",
      "|    n_updates            | 1710      |\n",
      "|    policy_gradient_loss | 0.349     |\n",
      "|    std                  | 0.994     |\n",
      "|    value_loss           | 1.09e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 173        |\n",
      "|    time_elapsed         | 397        |\n",
      "|    total_timesteps      | 22144      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48327363 |\n",
      "|    clip_fraction        | 0.46       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.763     |\n",
      "|    explained_variance   | -2.41e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.03      |\n",
      "|    n_updates            | 1720       |\n",
      "|    policy_gradient_loss | -0.0266    |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 5.6e-06    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 174        |\n",
      "|    time_elapsed         | 398        |\n",
      "|    total_timesteps      | 22272      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29790857 |\n",
      "|    clip_fraction        | 0.337      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.937     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.452      |\n",
      "|    n_updates            | 1730       |\n",
      "|    policy_gradient_loss | 0.411      |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 3.21e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 175        |\n",
      "|    time_elapsed         | 399        |\n",
      "|    total_timesteps      | 22400      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30037323 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.472      |\n",
      "|    n_updates            | 1740       |\n",
      "|    policy_gradient_loss | 0.368      |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 3.87e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 176        |\n",
      "|    time_elapsed         | 401        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30490935 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.973     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.467      |\n",
      "|    n_updates            | 1750       |\n",
      "|    policy_gradient_loss | 0.398      |\n",
      "|    std                  | 0.996      |\n",
      "|    value_loss           | 4.67e-10   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 177       |\n",
      "|    time_elapsed         | 405       |\n",
      "|    total_timesteps      | 22656     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3697189 |\n",
      "|    clip_fraction        | 0.387     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.867    |\n",
      "|    explained_variance   | -3.92e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0286   |\n",
      "|    n_updates            | 1760      |\n",
      "|    policy_gradient_loss | -0.0247   |\n",
      "|    std                  | 0.995     |\n",
      "|    value_loss           | 5.68e-06  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 178        |\n",
      "|    time_elapsed         | 406        |\n",
      "|    total_timesteps      | 22784      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31924066 |\n",
      "|    clip_fraction        | 0.33       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.963     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.468      |\n",
      "|    n_updates            | 1770       |\n",
      "|    policy_gradient_loss | 0.382      |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 4.63e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 179        |\n",
      "|    time_elapsed         | 407        |\n",
      "|    total_timesteps      | 22912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33983183 |\n",
      "|    clip_fraction        | 0.264      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.04      |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.387      |\n",
      "|    n_updates            | 1780       |\n",
      "|    policy_gradient_loss | 0.366      |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 3.71e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 180        |\n",
      "|    time_elapsed         | 408        |\n",
      "|    total_timesteps      | 23040      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36629054 |\n",
      "|    clip_fraction        | 0.346      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.936     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.448      |\n",
      "|    n_updates            | 1790       |\n",
      "|    policy_gradient_loss | 0.416      |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 1.73e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 181        |\n",
      "|    time_elapsed         | 411        |\n",
      "|    total_timesteps      | 23168      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.55090266 |\n",
      "|    clip_fraction        | 0.308      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.02      |\n",
      "|    explained_variance   | -1.58e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0209    |\n",
      "|    n_updates            | 1800       |\n",
      "|    policy_gradient_loss | -0.0194    |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 5.86e-06   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 56        |\n",
      "|    iterations           | 182       |\n",
      "|    time_elapsed         | 412       |\n",
      "|    total_timesteps      | 23296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3965247 |\n",
      "|    clip_fraction        | 0.31      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.976    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.361     |\n",
      "|    n_updates            | 1810      |\n",
      "|    policy_gradient_loss | 0.381     |\n",
      "|    std                  | 0.995     |\n",
      "|    value_loss           | 3.22e-08  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 56        |\n",
      "|    iterations           | 183       |\n",
      "|    time_elapsed         | 414       |\n",
      "|    total_timesteps      | 23424     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4192481 |\n",
      "|    clip_fraction        | 0.387     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.868    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.403     |\n",
      "|    n_updates            | 1820      |\n",
      "|    policy_gradient_loss | 0.443     |\n",
      "|    std                  | 0.996     |\n",
      "|    value_loss           | 1.38e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 184        |\n",
      "|    time_elapsed         | 415        |\n",
      "|    total_timesteps      | 23552      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48043942 |\n",
      "|    clip_fraction        | 0.282      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.03      |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.391      |\n",
      "|    n_updates            | 1830       |\n",
      "|    policy_gradient_loss | 0.356      |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 4.35e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 185        |\n",
      "|    time_elapsed         | 418        |\n",
      "|    total_timesteps      | 23680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.91052306 |\n",
      "|    clip_fraction        | 0.353      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.947     |\n",
      "|    explained_variance   | -7.24e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0327    |\n",
      "|    n_updates            | 1840       |\n",
      "|    policy_gradient_loss | -0.0282    |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 4.66e-06   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 56        |\n",
      "|    iterations           | 186       |\n",
      "|    time_elapsed         | 420       |\n",
      "|    total_timesteps      | 23808     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5430809 |\n",
      "|    clip_fraction        | 0.423     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.941    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.326     |\n",
      "|    n_updates            | 1850      |\n",
      "|    policy_gradient_loss | 0.392     |\n",
      "|    std                  | 0.999     |\n",
      "|    value_loss           | 3.04e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 56        |\n",
      "|    iterations           | 187       |\n",
      "|    time_elapsed         | 421       |\n",
      "|    total_timesteps      | 23936     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5553236 |\n",
      "|    clip_fraction        | 0.371     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.925    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.445     |\n",
      "|    n_updates            | 1860      |\n",
      "|    policy_gradient_loss | 0.42      |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.65e-09  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 188        |\n",
      "|    time_elapsed         | 422        |\n",
      "|    total_timesteps      | 24064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.63395566 |\n",
      "|    clip_fraction        | 0.346      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.979     |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.402      |\n",
      "|    n_updates            | 1870       |\n",
      "|    policy_gradient_loss | 0.403      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 7.38e-10   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 56        |\n",
      "|    iterations           | 189       |\n",
      "|    time_elapsed         | 425       |\n",
      "|    total_timesteps      | 24192     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9617386 |\n",
      "|    clip_fraction        | 0.337     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.966    |\n",
      "|    explained_variance   | -2.18e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0314   |\n",
      "|    n_updates            | 1880      |\n",
      "|    policy_gradient_loss | -0.0227   |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.1e-06   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 56        |\n",
      "|    iterations           | 190       |\n",
      "|    time_elapsed         | 427       |\n",
      "|    total_timesteps      | 24320     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6401445 |\n",
      "|    clip_fraction        | 0.302     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.03     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.31      |\n",
      "|    n_updates            | 1890      |\n",
      "|    policy_gradient_loss | 0.354     |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.88e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 191       |\n",
      "|    time_elapsed         | 428       |\n",
      "|    total_timesteps      | 24448     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7846434 |\n",
      "|    clip_fraction        | 0.25      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.07     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.236     |\n",
      "|    n_updates            | 1900      |\n",
      "|    policy_gradient_loss | 0.35      |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 2.4e-09   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 192        |\n",
      "|    time_elapsed         | 430        |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.68351024 |\n",
      "|    clip_fraction        | 0.299      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.999     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.442      |\n",
      "|    n_updates            | 1910       |\n",
      "|    policy_gradient_loss | 0.373      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 1.85e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 56        |\n",
      "|    iterations           | 193       |\n",
      "|    time_elapsed         | 433       |\n",
      "|    total_timesteps      | 24704     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1140721 |\n",
      "|    clip_fraction        | 0.294     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.01     |\n",
      "|    explained_variance   | -1.18e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0215   |\n",
      "|    n_updates            | 1920      |\n",
      "|    policy_gradient_loss | -0.0154   |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 3.7e-06   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 57       |\n",
      "|    iterations           | 194      |\n",
      "|    time_elapsed         | 435      |\n",
      "|    total_timesteps      | 24832    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.656644 |\n",
      "|    clip_fraction        | 0.311    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.09    |\n",
      "|    explained_variance   | 0        |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.368    |\n",
      "|    n_updates            | 1930     |\n",
      "|    policy_gradient_loss | 0.325    |\n",
      "|    std                  | 1.01     |\n",
      "|    value_loss           | 3.94e-09 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 57       |\n",
      "|    iterations           | 195      |\n",
      "|    time_elapsed         | 436      |\n",
      "|    total_timesteps      | 24960    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.814818 |\n",
      "|    clip_fraction        | 0.374    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.892   |\n",
      "|    explained_variance   | 5.96e-08 |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.193    |\n",
      "|    n_updates            | 1940     |\n",
      "|    policy_gradient_loss | 0.43     |\n",
      "|    std                  | 1.01     |\n",
      "|    value_loss           | 1.53e-09 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 196       |\n",
      "|    time_elapsed         | 438       |\n",
      "|    total_timesteps      | 25088     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6535764 |\n",
      "|    clip_fraction        | 0.359     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.917    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.465     |\n",
      "|    n_updates            | 1950      |\n",
      "|    policy_gradient_loss | 0.412     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 1.64e-10  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 56        |\n",
      "|    iterations           | 197       |\n",
      "|    time_elapsed         | 442       |\n",
      "|    total_timesteps      | 25216     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6299552 |\n",
      "|    clip_fraction        | 0.468     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.762    |\n",
      "|    explained_variance   | -5.39e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0323   |\n",
      "|    n_updates            | 1960      |\n",
      "|    policy_gradient_loss | -0.0291   |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 2.52e-06  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 198        |\n",
      "|    time_elapsed         | 444        |\n",
      "|    total_timesteps      | 25344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.64850056 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.981     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.216      |\n",
      "|    n_updates            | 1970       |\n",
      "|    policy_gradient_loss | 0.379      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 1.7e-08    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 199        |\n",
      "|    time_elapsed         | 445        |\n",
      "|    total_timesteps      | 25472      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.57667196 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.467      |\n",
      "|    n_updates            | 1980       |\n",
      "|    policy_gradient_loss | 0.344      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 2.75e-08   |\n",
      "----------------------------------------\n",
      "day: 521, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 200       |\n",
      "|    time_elapsed         | 447       |\n",
      "|    total_timesteps      | 25600     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7694656 |\n",
      "|    clip_fraction        | 0.249     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.07     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.214     |\n",
      "|    n_updates            | 1990      |\n",
      "|    policy_gradient_loss | 0.344     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 5.97e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 201       |\n",
      "|    time_elapsed         | 450       |\n",
      "|    total_timesteps      | 25728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7682879 |\n",
      "|    clip_fraction        | 0.438     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.801    |\n",
      "|    explained_variance   | -2.02e+04 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0396   |\n",
      "|    n_updates            | 2000      |\n",
      "|    policy_gradient_loss | -0.0331   |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 2.33e-06  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 202        |\n",
      "|    time_elapsed         | 452        |\n",
      "|    total_timesteps      | 25856      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49501824 |\n",
      "|    clip_fraction        | 0.37       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.946     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.421      |\n",
      "|    n_updates            | 2010       |\n",
      "|    policy_gradient_loss | 0.413      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 2.76e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 203        |\n",
      "|    time_elapsed         | 453        |\n",
      "|    total_timesteps      | 25984      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.58862543 |\n",
      "|    clip_fraction        | 0.41       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.901     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.386      |\n",
      "|    n_updates            | 2020       |\n",
      "|    policy_gradient_loss | 0.425      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 2.57e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 204        |\n",
      "|    time_elapsed         | 454        |\n",
      "|    total_timesteps      | 26112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.56267834 |\n",
      "|    clip_fraction        | 0.329      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.344      |\n",
      "|    n_updates            | 2030       |\n",
      "|    policy_gradient_loss | 0.401      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 4.08e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 205       |\n",
      "|    time_elapsed         | 458       |\n",
      "|    total_timesteps      | 26240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6168001 |\n",
      "|    clip_fraction        | 0.474     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.75     |\n",
      "|    explained_variance   | -2.85e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0278   |\n",
      "|    n_updates            | 2040      |\n",
      "|    policy_gradient_loss | -0.0244   |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 1.92e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 206       |\n",
      "|    time_elapsed         | 460       |\n",
      "|    total_timesteps      | 26368     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5407766 |\n",
      "|    clip_fraction        | 0.287     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.04     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.236     |\n",
      "|    n_updates            | 2050      |\n",
      "|    policy_gradient_loss | 0.353     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 1.28e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 207        |\n",
      "|    time_elapsed         | 461        |\n",
      "|    total_timesteps      | 26496      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.56975913 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.02      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.398      |\n",
      "|    n_updates            | 2060       |\n",
      "|    policy_gradient_loss | 0.388      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 1.15e-08   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 208       |\n",
      "|    time_elapsed         | 463       |\n",
      "|    total_timesteps      | 26624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5504507 |\n",
      "|    clip_fraction        | 0.267     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.05     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.465     |\n",
      "|    n_updates            | 2070      |\n",
      "|    policy_gradient_loss | 0.354     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 2.35e-09  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 209        |\n",
      "|    time_elapsed         | 466        |\n",
      "|    total_timesteps      | 26752      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.70430344 |\n",
      "|    clip_fraction        | 0.523      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.681     |\n",
      "|    explained_variance   | -589       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0141    |\n",
      "|    n_updates            | 2080       |\n",
      "|    policy_gradient_loss | -0.0156    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 1.5e-06    |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 210       |\n",
      "|    time_elapsed         | 468       |\n",
      "|    total_timesteps      | 26880     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4853171 |\n",
      "|    clip_fraction        | 0.2       |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.14     |\n",
      "|    explained_variance   | -2.15     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.146     |\n",
      "|    n_updates            | 2090      |\n",
      "|    policy_gradient_loss | 0.25      |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.23e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 211       |\n",
      "|    time_elapsed         | 469       |\n",
      "|    total_timesteps      | 27008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4926725 |\n",
      "|    clip_fraction        | 0.296     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1        |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.465     |\n",
      "|    n_updates            | 2100      |\n",
      "|    policy_gradient_loss | 0.379     |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.06e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 212       |\n",
      "|    time_elapsed         | 471       |\n",
      "|    total_timesteps      | 27136     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5488579 |\n",
      "|    clip_fraction        | 0.307     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.985    |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.468     |\n",
      "|    n_updates            | 2110      |\n",
      "|    policy_gradient_loss | 0.387     |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.45e-10  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 213        |\n",
      "|    time_elapsed         | 472        |\n",
      "|    total_timesteps      | 27264      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.56772786 |\n",
      "|    clip_fraction        | 0.313      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.976     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.466      |\n",
      "|    n_updates            | 2120       |\n",
      "|    policy_gradient_loss | 0.364      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 7.44e-10   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 214       |\n",
      "|    time_elapsed         | 476       |\n",
      "|    total_timesteps      | 27392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8684042 |\n",
      "|    clip_fraction        | 0.517     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.698    |\n",
      "|    explained_variance   | -1.05e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0361   |\n",
      "|    n_updates            | 2130      |\n",
      "|    policy_gradient_loss | -0.0289   |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.4e-06   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 215        |\n",
      "|    time_elapsed         | 477        |\n",
      "|    total_timesteps      | 27520      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.65590906 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.387      |\n",
      "|    n_updates            | 2140       |\n",
      "|    policy_gradient_loss | 0.343      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 2.05e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 216        |\n",
      "|    time_elapsed         | 479        |\n",
      "|    total_timesteps      | 27648      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.66171515 |\n",
      "|    clip_fraction        | 0.288      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.399      |\n",
      "|    n_updates            | 2150       |\n",
      "|    policy_gradient_loss | 0.375      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 9.84e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 217        |\n",
      "|    time_elapsed         | 480        |\n",
      "|    total_timesteps      | 27776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.57501084 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.162      |\n",
      "|    n_updates            | 2160       |\n",
      "|    policy_gradient_loss | 0.381      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 1.15e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 218       |\n",
      "|    time_elapsed         | 484       |\n",
      "|    total_timesteps      | 27904     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9506071 |\n",
      "|    clip_fraction        | 0.433     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.808    |\n",
      "|    explained_variance   | -566      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0244   |\n",
      "|    n_updates            | 2170      |\n",
      "|    policy_gradient_loss | -0.0192   |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.49e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 219       |\n",
      "|    time_elapsed         | 485       |\n",
      "|    total_timesteps      | 28032     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5832337 |\n",
      "|    clip_fraction        | 0.324     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.965    |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.468     |\n",
      "|    n_updates            | 2180      |\n",
      "|    policy_gradient_loss | 0.396     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 2.44e-09  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 220        |\n",
      "|    time_elapsed         | 487        |\n",
      "|    total_timesteps      | 28160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.68161386 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.972     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.386      |\n",
      "|    n_updates            | 2190       |\n",
      "|    policy_gradient_loss | 0.376      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 1.92e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 221        |\n",
      "|    time_elapsed         | 488        |\n",
      "|    total_timesteps      | 28288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.63812745 |\n",
      "|    clip_fraction        | 0.253      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.07      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.454      |\n",
      "|    n_updates            | 2200       |\n",
      "|    policy_gradient_loss | 0.329      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 1.94e-09   |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 57       |\n",
      "|    iterations           | 222      |\n",
      "|    time_elapsed         | 492      |\n",
      "|    total_timesteps      | 28416    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.280103 |\n",
      "|    clip_fraction        | 0.427    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.821   |\n",
      "|    explained_variance   | -955     |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | -0.0119  |\n",
      "|    n_updates            | 2210     |\n",
      "|    policy_gradient_loss | -0.0191  |\n",
      "|    std                  | 1.01     |\n",
      "|    value_loss           | 1.38e-06 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 223       |\n",
      "|    time_elapsed         | 493       |\n",
      "|    total_timesteps      | 28544     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5620362 |\n",
      "|    clip_fraction        | 0.251     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.07     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.469     |\n",
      "|    n_updates            | 2220      |\n",
      "|    policy_gradient_loss | 0.335     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 2.19e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 224        |\n",
      "|    time_elapsed         | 494        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.54357713 |\n",
      "|    clip_fraction        | 0.279      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.04      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.134      |\n",
      "|    n_updates            | 2230       |\n",
      "|    policy_gradient_loss | 0.37       |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 2.11e-08   |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 58       |\n",
      "|    iterations           | 225      |\n",
      "|    time_elapsed         | 496      |\n",
      "|    total_timesteps      | 28800    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.594316 |\n",
      "|    clip_fraction        | 0.365    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.986   |\n",
      "|    explained_variance   | 0        |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.138    |\n",
      "|    n_updates            | 2240     |\n",
      "|    policy_gradient_loss | 0.388    |\n",
      "|    std                  | 1.01     |\n",
      "|    value_loss           | 4.35e-08 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 226       |\n",
      "|    time_elapsed         | 499       |\n",
      "|    total_timesteps      | 28928     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6150743 |\n",
      "|    clip_fraction        | 0.371     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.9      |\n",
      "|    explained_variance   | -604      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.00682  |\n",
      "|    n_updates            | 2250      |\n",
      "|    policy_gradient_loss | -0.014    |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 1.32e-06  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 227        |\n",
      "|    time_elapsed         | 501        |\n",
      "|    total_timesteps      | 29056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.73910993 |\n",
      "|    clip_fraction        | 0.222      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.11      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.4        |\n",
      "|    n_updates            | 2260       |\n",
      "|    policy_gradient_loss | 0.331      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 9.32e-08   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 503         |\n",
      "|    total_timesteps      | 29184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004949847 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00644    |\n",
      "|    n_updates            | 2270        |\n",
      "|    policy_gradient_loss | -0.337      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.97e-07    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 229       |\n",
      "|    time_elapsed         | 504       |\n",
      "|    total_timesteps      | 29312     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8634894 |\n",
      "|    clip_fraction        | 0.36      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1        |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.468    |\n",
      "|    n_updates            | 2280      |\n",
      "|    policy_gradient_loss | -0.384    |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 1.48e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 230       |\n",
      "|    time_elapsed         | 508       |\n",
      "|    total_timesteps      | 29440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6564485 |\n",
      "|    clip_fraction        | 0.398     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.867    |\n",
      "|    explained_variance   | -95.6     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00105   |\n",
      "|    n_updates            | 2290      |\n",
      "|    policy_gradient_loss | 0.00614   |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 1.07e-06  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 231        |\n",
      "|    time_elapsed         | 509        |\n",
      "|    total_timesteps      | 29568      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.77273536 |\n",
      "|    clip_fraction        | 0.303      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.464      |\n",
      "|    n_updates            | 2300       |\n",
      "|    policy_gradient_loss | 0.386      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 3.99e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 232        |\n",
      "|    time_elapsed         | 511        |\n",
      "|    total_timesteps      | 29696      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.88814914 |\n",
      "|    clip_fraction        | 0.335      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.954     |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.458      |\n",
      "|    n_updates            | 2310       |\n",
      "|    policy_gradient_loss | 0.413      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 1.23e-08   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 233       |\n",
      "|    time_elapsed         | 512       |\n",
      "|    total_timesteps      | 29824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0878313 |\n",
      "|    clip_fraction        | 0.284     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.02     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.414     |\n",
      "|    n_updates            | 2320      |\n",
      "|    policy_gradient_loss | 0.395     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 6.34e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 234       |\n",
      "|    time_elapsed         | 516       |\n",
      "|    total_timesteps      | 29952     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.4569392 |\n",
      "|    clip_fraction        | 0.309     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.988    |\n",
      "|    explained_variance   | -164      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.00119  |\n",
      "|    n_updates            | 2330      |\n",
      "|    policy_gradient_loss | -0.00046  |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 1.01e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 235       |\n",
      "|    time_elapsed         | 518       |\n",
      "|    total_timesteps      | 30080     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8981521 |\n",
      "|    clip_fraction        | 0.266     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.05     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.434     |\n",
      "|    n_updates            | 2340      |\n",
      "|    policy_gradient_loss | 0.357     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 9.56e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 236       |\n",
      "|    time_elapsed         | 519       |\n",
      "|    total_timesteps      | 30208     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5346899 |\n",
      "|    clip_fraction        | 0.327     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.962    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0973    |\n",
      "|    n_updates            | 2350      |\n",
      "|    policy_gradient_loss | 0.393     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 7.75e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 237       |\n",
      "|    time_elapsed         | 521       |\n",
      "|    total_timesteps      | 30336     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9154713 |\n",
      "|    clip_fraction        | 0.354     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.924    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.468     |\n",
      "|    n_updates            | 2360      |\n",
      "|    policy_gradient_loss | 0.407     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 2.35e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 238       |\n",
      "|    time_elapsed         | 524       |\n",
      "|    total_timesteps      | 30464     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1819727 |\n",
      "|    clip_fraction        | 0.368     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.927    |\n",
      "|    explained_variance   | -249      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0126   |\n",
      "|    n_updates            | 2370      |\n",
      "|    policy_gradient_loss | -0.00827  |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 7.72e-07  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 239        |\n",
      "|    time_elapsed         | 526        |\n",
      "|    total_timesteps      | 30592      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.77687526 |\n",
      "|    clip_fraction        | 0.39       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.874     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.452      |\n",
      "|    n_updates            | 2380       |\n",
      "|    policy_gradient_loss | 0.449      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 9.23e-10   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 240       |\n",
      "|    time_elapsed         | 527       |\n",
      "|    total_timesteps      | 30720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0123351 |\n",
      "|    clip_fraction        | 0.305     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.997    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.419     |\n",
      "|    n_updates            | 2390      |\n",
      "|    policy_gradient_loss | 0.397     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 2.71e-09  |\n",
      "---------------------------------------\n",
      "day: 521, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 241       |\n",
      "|    time_elapsed         | 528       |\n",
      "|    total_timesteps      | 30848     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1402074 |\n",
      "|    clip_fraction        | 0.213     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.12     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.374     |\n",
      "|    n_updates            | 2400      |\n",
      "|    policy_gradient_loss | 0.31      |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 3.67e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 242       |\n",
      "|    time_elapsed         | 531       |\n",
      "|    total_timesteps      | 30976     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6469746 |\n",
      "|    clip_fraction        | 0.328     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.959    |\n",
      "|    explained_variance   | -509      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0117   |\n",
      "|    n_updates            | 2410      |\n",
      "|    policy_gradient_loss | -0.0107   |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 6.77e-07  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 243        |\n",
      "|    time_elapsed         | 532        |\n",
      "|    total_timesteps      | 31104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.91061103 |\n",
      "|    clip_fraction        | 0.334      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.949     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.441      |\n",
      "|    n_updates            | 2420       |\n",
      "|    policy_gradient_loss | 0.415      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 1.7e-08    |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 244       |\n",
      "|    time_elapsed         | 534       |\n",
      "|    total_timesteps      | 31232     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8676807 |\n",
      "|    clip_fraction        | 0.274     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.03     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.465     |\n",
      "|    n_updates            | 2430      |\n",
      "|    policy_gradient_loss | 0.365     |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.49e-10  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 245       |\n",
      "|    time_elapsed         | 535       |\n",
      "|    total_timesteps      | 31360     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9991127 |\n",
      "|    clip_fraction        | 0.371     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.895    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.455     |\n",
      "|    n_updates            | 2440      |\n",
      "|    policy_gradient_loss | 0.418     |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.92e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 246       |\n",
      "|    time_elapsed         | 538       |\n",
      "|    total_timesteps      | 31488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0603043 |\n",
      "|    clip_fraction        | 0.418     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.831    |\n",
      "|    explained_variance   | -2.44e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0284   |\n",
      "|    n_updates            | 2450      |\n",
      "|    policy_gradient_loss | -0.0232   |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.67e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 247       |\n",
      "|    time_elapsed         | 539       |\n",
      "|    total_timesteps      | 31616     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0459125 |\n",
      "|    clip_fraction        | 0.299     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.997    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.265     |\n",
      "|    n_updates            | 2460      |\n",
      "|    policy_gradient_loss | 0.391     |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.72e-10  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 248       |\n",
      "|    time_elapsed         | 541       |\n",
      "|    total_timesteps      | 31744     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1235235 |\n",
      "|    clip_fraction        | 0.286     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.02     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.254     |\n",
      "|    n_updates            | 2470      |\n",
      "|    policy_gradient_loss | 0.306     |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.73e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 249       |\n",
      "|    time_elapsed         | 542       |\n",
      "|    total_timesteps      | 31872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1091018 |\n",
      "|    clip_fraction        | 0.364     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.904    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.342    |\n",
      "|    n_updates            | 2480      |\n",
      "|    policy_gradient_loss | -0.422    |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.7e-08   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 250       |\n",
      "|    time_elapsed         | 546       |\n",
      "|    total_timesteps      | 32000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2834392 |\n",
      "|    clip_fraction        | 0.482     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.772    |\n",
      "|    explained_variance   | -168      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0772   |\n",
      "|    n_updates            | 2490      |\n",
      "|    policy_gradient_loss | -0.0678   |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.04e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 251       |\n",
      "|    time_elapsed         | 547       |\n",
      "|    total_timesteps      | 32128     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9004365 |\n",
      "|    clip_fraction        | 0.284     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.02     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.342     |\n",
      "|    n_updates            | 2500      |\n",
      "|    policy_gradient_loss | 0.387     |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.01e-07  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 58       |\n",
      "|    iterations           | 252      |\n",
      "|    time_elapsed         | 548      |\n",
      "|    total_timesteps      | 32256    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.893423 |\n",
      "|    clip_fraction        | 0.257    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.06    |\n",
      "|    explained_variance   | 0        |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.404    |\n",
      "|    n_updates            | 2510     |\n",
      "|    policy_gradient_loss | 0.33     |\n",
      "|    std                  | 1        |\n",
      "|    value_loss           | 1.92e-07 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 253       |\n",
      "|    time_elapsed         | 549       |\n",
      "|    total_timesteps      | 32384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0149485 |\n",
      "|    clip_fraction        | 0.232     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.09     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.237     |\n",
      "|    n_updates            | 2520      |\n",
      "|    policy_gradient_loss | 0.352     |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.54e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 254        |\n",
      "|    time_elapsed         | 554        |\n",
      "|    total_timesteps      | 32512      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.78166324 |\n",
      "|    clip_fraction        | 0.421      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.822     |\n",
      "|    explained_variance   | -18.3      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0402     |\n",
      "|    n_updates            | 2530       |\n",
      "|    policy_gradient_loss | 0.0636     |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 3.9e-07    |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 255       |\n",
      "|    time_elapsed         | 555       |\n",
      "|    total_timesteps      | 32640     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5592546 |\n",
      "|    clip_fraction        | 0.365     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.901    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.471     |\n",
      "|    n_updates            | 2540      |\n",
      "|    policy_gradient_loss | 0.411     |\n",
      "|    std                  | 0.999     |\n",
      "|    value_loss           | 4.34e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 256       |\n",
      "|    time_elapsed         | 557       |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8624814 |\n",
      "|    clip_fraction        | 0.312     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.977    |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.372     |\n",
      "|    n_updates            | 2550      |\n",
      "|    policy_gradient_loss | 0.391     |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.19e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 257       |\n",
      "|    time_elapsed         | 558       |\n",
      "|    total_timesteps      | 32896     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9521411 |\n",
      "|    clip_fraction        | 0.32      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.966    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.392    |\n",
      "|    n_updates            | 2560      |\n",
      "|    policy_gradient_loss | -0.414    |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.39e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 258       |\n",
      "|    time_elapsed         | 563       |\n",
      "|    total_timesteps      | 33024     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9869117 |\n",
      "|    clip_fraction        | 0.55      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.679    |\n",
      "|    explained_variance   | -18.5     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.155    |\n",
      "|    n_updates            | 2570      |\n",
      "|    policy_gradient_loss | -0.139    |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.16e-07  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 259        |\n",
      "|    time_elapsed         | 564        |\n",
      "|    total_timesteps      | 33152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48740366 |\n",
      "|    clip_fraction        | 0.197      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.14      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.097     |\n",
      "|    n_updates            | 2580       |\n",
      "|    policy_gradient_loss | -0.297     |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 1.64e-08   |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 58       |\n",
      "|    iterations           | 260      |\n",
      "|    time_elapsed         | 566      |\n",
      "|    total_timesteps      | 33280    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.014129 |\n",
      "|    clip_fraction        | 0.236    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.11    |\n",
      "|    explained_variance   | 0        |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | -0.3     |\n",
      "|    n_updates            | 2590     |\n",
      "|    policy_gradient_loss | -0.322   |\n",
      "|    std                  | 1        |\n",
      "|    value_loss           | 5.71e-08 |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 261        |\n",
      "|    time_elapsed         | 568        |\n",
      "|    total_timesteps      | 33408      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.98827136 |\n",
      "|    clip_fraction        | 0.25       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.36      |\n",
      "|    n_updates            | 2600       |\n",
      "|    policy_gradient_loss | -0.34      |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 4.63e-08   |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 58            |\n",
      "|    iterations           | 262           |\n",
      "|    time_elapsed         | 569           |\n",
      "|    total_timesteps      | 33536         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3653341e-06 |\n",
      "|    clip_fraction        | 0.173         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.17         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.000196     |\n",
      "|    n_updates            | 2610          |\n",
      "|    policy_gradient_loss | -0.174        |\n",
      "|    std                  | 0.996         |\n",
      "|    value_loss           | 1.17e-08      |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 263       |\n",
      "|    time_elapsed         | 573       |\n",
      "|    total_timesteps      | 33664     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8999911 |\n",
      "|    clip_fraction        | 0.323     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.956    |\n",
      "|    explained_variance   | -1.63e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0323   |\n",
      "|    n_updates            | 2620      |\n",
      "|    policy_gradient_loss | -0.0501   |\n",
      "|    std                  | 0.993     |\n",
      "|    value_loss           | 2.98e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 264       |\n",
      "|    time_elapsed         | 574       |\n",
      "|    total_timesteps      | 33792     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9828031 |\n",
      "|    clip_fraction        | 0.298     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.991    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.248    |\n",
      "|    n_updates            | 2630      |\n",
      "|    policy_gradient_loss | -0.39     |\n",
      "|    std                  | 0.992     |\n",
      "|    value_loss           | 2.16e-08  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 265       |\n",
      "|    time_elapsed         | 576       |\n",
      "|    total_timesteps      | 33920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8447335 |\n",
      "|    clip_fraction        | 0.366     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.894    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.458    |\n",
      "|    n_updates            | 2640      |\n",
      "|    policy_gradient_loss | -0.433    |\n",
      "|    std                  | 0.993     |\n",
      "|    value_loss           | 1.44e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 266       |\n",
      "|    time_elapsed         | 577       |\n",
      "|    total_timesteps      | 34048     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7984865 |\n",
      "|    clip_fraction        | 0.354     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.912    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.471    |\n",
      "|    n_updates            | 2650      |\n",
      "|    policy_gradient_loss | -0.425    |\n",
      "|    std                  | 0.993     |\n",
      "|    value_loss           | 5.71e-09  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 267        |\n",
      "|    time_elapsed         | 581        |\n",
      "|    total_timesteps      | 34176      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.98793155 |\n",
      "|    clip_fraction        | 0.504      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.737     |\n",
      "|    explained_variance   | -175       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0723    |\n",
      "|    n_updates            | 2660       |\n",
      "|    policy_gradient_loss | -0.062     |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 1.87e-07   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 268       |\n",
      "|    time_elapsed         | 582       |\n",
      "|    total_timesteps      | 34304     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6716171 |\n",
      "|    clip_fraction        | 0.307     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.981    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.467    |\n",
      "|    n_updates            | 2670      |\n",
      "|    policy_gradient_loss | -0.377    |\n",
      "|    std                  | 0.99      |\n",
      "|    value_loss           | 2.26e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 269       |\n",
      "|    time_elapsed         | 583       |\n",
      "|    total_timesteps      | 34432     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8340311 |\n",
      "|    clip_fraction        | 0.246     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.06     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.392     |\n",
      "|    n_updates            | 2680      |\n",
      "|    policy_gradient_loss | 0.362     |\n",
      "|    std                  | 0.987     |\n",
      "|    value_loss           | 1.44e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 270       |\n",
      "|    time_elapsed         | 584       |\n",
      "|    total_timesteps      | 34560     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7375957 |\n",
      "|    clip_fraction        | 0.28      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.01     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.467    |\n",
      "|    n_updates            | 2690      |\n",
      "|    policy_gradient_loss | -0.389    |\n",
      "|    std                  | 0.987     |\n",
      "|    value_loss           | 1.45e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 271       |\n",
      "|    time_elapsed         | 589       |\n",
      "|    total_timesteps      | 34688     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1073766 |\n",
      "|    clip_fraction        | 0.446     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.778    |\n",
      "|    explained_variance   | -2.87     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.21     |\n",
      "|    n_updates            | 2700      |\n",
      "|    policy_gradient_loss | -0.188    |\n",
      "|    std                  | 0.988     |\n",
      "|    value_loss           | 2.17e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 272       |\n",
      "|    time_elapsed         | 590       |\n",
      "|    total_timesteps      | 34816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7992867 |\n",
      "|    clip_fraction        | 0.318     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.96     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.254    |\n",
      "|    n_updates            | 2710      |\n",
      "|    policy_gradient_loss | -0.405    |\n",
      "|    std                  | 0.989     |\n",
      "|    value_loss           | 3.57e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 273       |\n",
      "|    time_elapsed         | 591       |\n",
      "|    total_timesteps      | 34944     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9013673 |\n",
      "|    clip_fraction        | 0.309     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.972    |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.234     |\n",
      "|    n_updates            | 2720      |\n",
      "|    policy_gradient_loss | 0.4       |\n",
      "|    std                  | 0.989     |\n",
      "|    value_loss           | 7.93e-05  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 274        |\n",
      "|    time_elapsed         | 592        |\n",
      "|    total_timesteps      | 35072      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.79139763 |\n",
      "|    clip_fraction        | 0.296      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.991     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.456      |\n",
      "|    n_updates            | 2730       |\n",
      "|    policy_gradient_loss | 0.39       |\n",
      "|    std                  | 0.989      |\n",
      "|    value_loss           | 1.07e-05   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 275       |\n",
      "|    time_elapsed         | 596       |\n",
      "|    total_timesteps      | 35200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2677237 |\n",
      "|    clip_fraction        | 0.459     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.772    |\n",
      "|    explained_variance   | -186      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0667   |\n",
      "|    n_updates            | 2740      |\n",
      "|    policy_gradient_loss | -0.0619   |\n",
      "|    std                  | 0.989     |\n",
      "|    value_loss           | 1.71e-07  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 276        |\n",
      "|    time_elapsed         | 597        |\n",
      "|    total_timesteps      | 35328      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.75358725 |\n",
      "|    clip_fraction        | 0.351      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.979     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.457     |\n",
      "|    n_updates            | 2750       |\n",
      "|    policy_gradient_loss | -0.404     |\n",
      "|    std                  | 0.989      |\n",
      "|    value_loss           | 1.31e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 277        |\n",
      "|    time_elapsed         | 599        |\n",
      "|    total_timesteps      | 35456      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.84472764 |\n",
      "|    clip_fraction        | 0.323      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.952     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.45      |\n",
      "|    n_updates            | 2760       |\n",
      "|    policy_gradient_loss | -0.388     |\n",
      "|    std                  | 0.987      |\n",
      "|    value_loss           | 6.62e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 278       |\n",
      "|    time_elapsed         | 600       |\n",
      "|    total_timesteps      | 35584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8588643 |\n",
      "|    clip_fraction        | 0.303     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.979    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.458     |\n",
      "|    n_updates            | 2770      |\n",
      "|    policy_gradient_loss | 0.384     |\n",
      "|    std                  | 0.986     |\n",
      "|    value_loss           | 2.74e-08  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 279       |\n",
      "|    time_elapsed         | 603       |\n",
      "|    total_timesteps      | 35712     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.5977148 |\n",
      "|    clip_fraction        | 0.368     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.887    |\n",
      "|    explained_variance   | -202      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.00154  |\n",
      "|    n_updates            | 2780      |\n",
      "|    policy_gradient_loss | -0.00172  |\n",
      "|    std                  | 0.984     |\n",
      "|    value_loss           | 4.91e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 280       |\n",
      "|    time_elapsed         | 604       |\n",
      "|    total_timesteps      | 35840     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8294645 |\n",
      "|    clip_fraction        | 0.297     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.986    |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.444     |\n",
      "|    n_updates            | 2790      |\n",
      "|    policy_gradient_loss | 0.382     |\n",
      "|    std                  | 0.983     |\n",
      "|    value_loss           | 1.66e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 281       |\n",
      "|    time_elapsed         | 606       |\n",
      "|    total_timesteps      | 35968     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7767693 |\n",
      "|    clip_fraction        | 0.301     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.981    |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.458     |\n",
      "|    n_updates            | 2800      |\n",
      "|    policy_gradient_loss | 0.404     |\n",
      "|    std                  | 0.985     |\n",
      "|    value_loss           | 1.13e-05  |\n",
      "---------------------------------------\n",
      "day: 521, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 282        |\n",
      "|    time_elapsed         | 608        |\n",
      "|    total_timesteps      | 36096      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.86415035 |\n",
      "|    clip_fraction        | 0.343      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.986     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.411     |\n",
      "|    n_updates            | 2810       |\n",
      "|    policy_gradient_loss | -0.374     |\n",
      "|    std                  | 0.986      |\n",
      "|    value_loss           | 1.49e-06   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 283       |\n",
      "|    time_elapsed         | 611       |\n",
      "|    total_timesteps      | 36224     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3341056 |\n",
      "|    clip_fraction        | 0.319     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.956    |\n",
      "|    explained_variance   | -9.89     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0935    |\n",
      "|    n_updates            | 2820      |\n",
      "|    policy_gradient_loss | 0.0706    |\n",
      "|    std                  | 0.984     |\n",
      "|    value_loss           | 3.9e-06   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 284        |\n",
      "|    time_elapsed         | 613        |\n",
      "|    total_timesteps      | 36352      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.79057086 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.366      |\n",
      "|    n_updates            | 2830       |\n",
      "|    policy_gradient_loss | 0.394      |\n",
      "|    std                  | 0.98       |\n",
      "|    value_loss           | 3.22e-06   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 285       |\n",
      "|    time_elapsed         | 615       |\n",
      "|    total_timesteps      | 36480     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7834477 |\n",
      "|    clip_fraction        | 0.293     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.992    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.411     |\n",
      "|    n_updates            | 2840      |\n",
      "|    policy_gradient_loss | 0.374     |\n",
      "|    std                  | 0.978     |\n",
      "|    value_loss           | 1.19e-07  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 286        |\n",
      "|    time_elapsed         | 616        |\n",
      "|    total_timesteps      | 36608      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.76702404 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.401      |\n",
      "|    n_updates            | 2850       |\n",
      "|    policy_gradient_loss | 0.341      |\n",
      "|    std                  | 0.979      |\n",
      "|    value_loss           | 8.11e-07   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 287       |\n",
      "|    time_elapsed         | 620       |\n",
      "|    total_timesteps      | 36736     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9560287 |\n",
      "|    clip_fraction        | 0.328     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.94     |\n",
      "|    explained_variance   | -0.837    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.19      |\n",
      "|    n_updates            | 2860      |\n",
      "|    policy_gradient_loss | 0.207     |\n",
      "|    std                  | 0.979     |\n",
      "|    value_loss           | 4.69e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 288       |\n",
      "|    time_elapsed         | 621       |\n",
      "|    total_timesteps      | 36864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6626382 |\n",
      "|    clip_fraction        | 0.299     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.98     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.373     |\n",
      "|    n_updates            | 2870      |\n",
      "|    policy_gradient_loss | 0.367     |\n",
      "|    std                  | 0.98      |\n",
      "|    value_loss           | 7.98e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 289       |\n",
      "|    time_elapsed         | 623       |\n",
      "|    total_timesteps      | 36992     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7661464 |\n",
      "|    clip_fraction        | 0.235     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.07     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.358    |\n",
      "|    n_updates            | 2880      |\n",
      "|    policy_gradient_loss | -0.309    |\n",
      "|    std                  | 0.983     |\n",
      "|    value_loss           | 2.69e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 290       |\n",
      "|    time_elapsed         | 624       |\n",
      "|    total_timesteps      | 37120     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8670008 |\n",
      "|    clip_fraction        | 0.309     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.977    |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.287    |\n",
      "|    n_updates            | 2890      |\n",
      "|    policy_gradient_loss | -0.394    |\n",
      "|    std                  | 0.986     |\n",
      "|    value_loss           | 1.65e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 291       |\n",
      "|    time_elapsed         | 627       |\n",
      "|    total_timesteps      | 37248     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6517926 |\n",
      "|    clip_fraction        | 0.337     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.932    |\n",
      "|    explained_variance   | -12.5     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.135    |\n",
      "|    n_updates            | 2900      |\n",
      "|    policy_gradient_loss | -0.116    |\n",
      "|    std                  | 0.988     |\n",
      "|    value_loss           | 5.97e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 292       |\n",
      "|    time_elapsed         | 629       |\n",
      "|    total_timesteps      | 37376     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5230057 |\n",
      "|    clip_fraction        | 0.389     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.913    |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.468    |\n",
      "|    n_updates            | 2910      |\n",
      "|    policy_gradient_loss | -0.427    |\n",
      "|    std                  | 0.989     |\n",
      "|    value_loss           | 7.46e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 293       |\n",
      "|    time_elapsed         | 630       |\n",
      "|    total_timesteps      | 37504     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6188519 |\n",
      "|    clip_fraction        | 0.346     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.923    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.464     |\n",
      "|    n_updates            | 2920      |\n",
      "|    policy_gradient_loss | 0.39      |\n",
      "|    std                  | 0.99      |\n",
      "|    value_loss           | 1.3e-07   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 294        |\n",
      "|    time_elapsed         | 631        |\n",
      "|    total_timesteps      | 37632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.70009154 |\n",
      "|    clip_fraction        | 0.365      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.9       |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.461      |\n",
      "|    n_updates            | 2930       |\n",
      "|    policy_gradient_loss | 0.419      |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 3.57e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 295       |\n",
      "|    time_elapsed         | 635       |\n",
      "|    total_timesteps      | 37760     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7285355 |\n",
      "|    clip_fraction        | 0.366     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.895    |\n",
      "|    explained_variance   | -9.37     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.101     |\n",
      "|    n_updates            | 2940      |\n",
      "|    policy_gradient_loss | 0.086     |\n",
      "|    std                  | 0.992     |\n",
      "|    value_loss           | 1.3e-07   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 296       |\n",
      "|    time_elapsed         | 636       |\n",
      "|    total_timesteps      | 37888     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7245778 |\n",
      "|    clip_fraction        | 0.223     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.1      |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.19      |\n",
      "|    n_updates            | 2950      |\n",
      "|    policy_gradient_loss | 0.319     |\n",
      "|    std                  | 0.99      |\n",
      "|    value_loss           | 2.64e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 297        |\n",
      "|    time_elapsed         | 637        |\n",
      "|    total_timesteps      | 38016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.67103565 |\n",
      "|    clip_fraction        | 0.324      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.952     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.446      |\n",
      "|    n_updates            | 2960       |\n",
      "|    policy_gradient_loss | 0.383      |\n",
      "|    std                  | 0.989      |\n",
      "|    value_loss           | 9.44e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 298        |\n",
      "|    time_elapsed         | 639        |\n",
      "|    total_timesteps      | 38144      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.78844935 |\n",
      "|    clip_fraction        | 0.346      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.92      |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.271      |\n",
      "|    n_updates            | 2970       |\n",
      "|    policy_gradient_loss | 0.405      |\n",
      "|    std                  | 0.989      |\n",
      "|    value_loss           | 1.28e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 299       |\n",
      "|    time_elapsed         | 642       |\n",
      "|    total_timesteps      | 38272     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9642831 |\n",
      "|    clip_fraction        | 0.305     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.979    |\n",
      "|    explained_variance   | -960      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0151   |\n",
      "|    n_updates            | 2980      |\n",
      "|    policy_gradient_loss | -0.0111   |\n",
      "|    std                  | 0.988     |\n",
      "|    value_loss           | 1.03e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 300       |\n",
      "|    time_elapsed         | 643       |\n",
      "|    total_timesteps      | 38400     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5571115 |\n",
      "|    clip_fraction        | 0.307     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.986    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.453     |\n",
      "|    n_updates            | 2990      |\n",
      "|    policy_gradient_loss | 0.392     |\n",
      "|    std                  | 0.988     |\n",
      "|    value_loss           | 2.22e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 301       |\n",
      "|    time_elapsed         | 645       |\n",
      "|    total_timesteps      | 38528     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5569621 |\n",
      "|    clip_fraction        | 0.31      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.972    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.472    |\n",
      "|    n_updates            | 3000      |\n",
      "|    policy_gradient_loss | -0.387    |\n",
      "|    std                  | 0.991     |\n",
      "|    value_loss           | 1e-06     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 302       |\n",
      "|    time_elapsed         | 646       |\n",
      "|    total_timesteps      | 38656     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6971529 |\n",
      "|    clip_fraction        | 0.327     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.949    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.271    |\n",
      "|    n_updates            | 3010      |\n",
      "|    policy_gradient_loss | -0.406    |\n",
      "|    std                  | 0.993     |\n",
      "|    value_loss           | 1.13e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 303       |\n",
      "|    time_elapsed         | 650       |\n",
      "|    total_timesteps      | 38784     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8133869 |\n",
      "|    clip_fraction        | 0.448     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.811    |\n",
      "|    explained_variance   | -0.26     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.287     |\n",
      "|    n_updates            | 3020      |\n",
      "|    policy_gradient_loss | 0.276     |\n",
      "|    std                  | 0.995     |\n",
      "|    value_loss           | 1.5e-05   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 304        |\n",
      "|    time_elapsed         | 651        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.57127625 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.07      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.214     |\n",
      "|    n_updates            | 3030       |\n",
      "|    policy_gradient_loss | -0.341     |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 3.01e-05   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 305       |\n",
      "|    time_elapsed         | 652       |\n",
      "|    total_timesteps      | 39040     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5250963 |\n",
      "|    clip_fraction        | 0.281     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.02     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.447    |\n",
      "|    n_updates            | 3040      |\n",
      "|    policy_gradient_loss | -0.375    |\n",
      "|    std                  | 0.995     |\n",
      "|    value_loss           | 1.94e-06  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 306        |\n",
      "|    time_elapsed         | 653        |\n",
      "|    total_timesteps      | 39168      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.53247356 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.462     |\n",
      "|    n_updates            | 3050       |\n",
      "|    policy_gradient_loss | -0.36      |\n",
      "|    std                  | 0.993      |\n",
      "|    value_loss           | 0.000297   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 307       |\n",
      "|    time_elapsed         | 657       |\n",
      "|    total_timesteps      | 39296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7863692 |\n",
      "|    clip_fraction        | 0.462     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.764    |\n",
      "|    explained_variance   | -0.143    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.269     |\n",
      "|    n_updates            | 3060      |\n",
      "|    policy_gradient_loss | 0.302     |\n",
      "|    std                  | 0.993     |\n",
      "|    value_loss           | 8.81e-05  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 308        |\n",
      "|    time_elapsed         | 659        |\n",
      "|    total_timesteps      | 39424      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36700124 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.13      |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.138      |\n",
      "|    n_updates            | 3070       |\n",
      "|    policy_gradient_loss | 0.276      |\n",
      "|    std                  | 0.993      |\n",
      "|    value_loss           | 0.000188   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 309        |\n",
      "|    time_elapsed         | 660        |\n",
      "|    total_timesteps      | 39552      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48637268 |\n",
      "|    clip_fraction        | 0.336      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.95      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.305     |\n",
      "|    n_updates            | 3080       |\n",
      "|    policy_gradient_loss | -0.421     |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 0.000274   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 310        |\n",
      "|    time_elapsed         | 661        |\n",
      "|    total_timesteps      | 39680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46343875 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.986     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.47       |\n",
      "|    n_updates            | 3090       |\n",
      "|    policy_gradient_loss | 0.399      |\n",
      "|    std                  | 0.991      |\n",
      "|    value_loss           | 5.69e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 311        |\n",
      "|    time_elapsed         | 665        |\n",
      "|    total_timesteps      | 39808      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.59232515 |\n",
      "|    clip_fraction        | 0.51       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.691     |\n",
      "|    explained_variance   | -0.148     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.322      |\n",
      "|    n_updates            | 3100       |\n",
      "|    policy_gradient_loss | 0.327      |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 6.44e-06   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 312       |\n",
      "|    time_elapsed         | 667       |\n",
      "|    total_timesteps      | 39936     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3746464 |\n",
      "|    clip_fraction        | 0.206     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.12     |\n",
      "|    explained_variance   | 8.29e-06  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.36      |\n",
      "|    n_updates            | 3110      |\n",
      "|    policy_gradient_loss | 0.297     |\n",
      "|    std                  | 0.993     |\n",
      "|    value_loss           | 3.87e-06  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 313        |\n",
      "|    time_elapsed         | 668        |\n",
      "|    total_timesteps      | 40064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42999992 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.472     |\n",
      "|    n_updates            | 3120       |\n",
      "|    policy_gradient_loss | -0.335     |\n",
      "|    std                  | 0.991      |\n",
      "|    value_loss           | 3.22e-06   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 314        |\n",
      "|    time_elapsed         | 670        |\n",
      "|    total_timesteps      | 40192      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44093585 |\n",
      "|    clip_fraction        | 0.33       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.944     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.471      |\n",
      "|    n_updates            | 3130       |\n",
      "|    policy_gradient_loss | 0.415      |\n",
      "|    std                  | 0.991      |\n",
      "|    value_loss           | 1.33e-08   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 315       |\n",
      "|    time_elapsed         | 671       |\n",
      "|    total_timesteps      | 40320     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4637959 |\n",
      "|    clip_fraction        | 0.358     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.919    |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.406     |\n",
      "|    n_updates            | 3140      |\n",
      "|    policy_gradient_loss | 0.43      |\n",
      "|    std                  | 0.992     |\n",
      "|    value_loss           | 9.62e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 316       |\n",
      "|    time_elapsed         | 675       |\n",
      "|    total_timesteps      | 40448     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6250188 |\n",
      "|    clip_fraction        | 0.473     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.75     |\n",
      "|    explained_variance   | -8.19     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.116     |\n",
      "|    n_updates            | 3150      |\n",
      "|    policy_gradient_loss | 0.13      |\n",
      "|    std                  | 0.992     |\n",
      "|    value_loss           | 6.65e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 317        |\n",
      "|    time_elapsed         | 676        |\n",
      "|    total_timesteps      | 40576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36779764 |\n",
      "|    clip_fraction        | 0.294      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.191      |\n",
      "|    n_updates            | 3160       |\n",
      "|    policy_gradient_loss | 0.377      |\n",
      "|    std                  | 0.993      |\n",
      "|    value_loss           | 3.26e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 318        |\n",
      "|    time_elapsed         | 677        |\n",
      "|    total_timesteps      | 40704      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38128653 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.986     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.461      |\n",
      "|    n_updates            | 3170       |\n",
      "|    policy_gradient_loss | 0.409      |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 1.06e-08   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 319       |\n",
      "|    time_elapsed         | 679       |\n",
      "|    total_timesteps      | 40832     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3887271 |\n",
      "|    clip_fraction        | 0.319     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.961    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.468     |\n",
      "|    n_updates            | 3180      |\n",
      "|    policy_gradient_loss | 0.384     |\n",
      "|    std                  | 0.991     |\n",
      "|    value_loss           | 3.13e-09  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 320        |\n",
      "|    time_elapsed         | 683        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44237542 |\n",
      "|    clip_fraction        | 0.519      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.678     |\n",
      "|    explained_variance   | -5.83      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.123      |\n",
      "|    n_updates            | 3190       |\n",
      "|    policy_gradient_loss | 0.114      |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 6.39e-08   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 321       |\n",
      "|    time_elapsed         | 684       |\n",
      "|    total_timesteps      | 41088     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3415067 |\n",
      "|    clip_fraction        | 0.239     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.07     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.47      |\n",
      "|    n_updates            | 3200      |\n",
      "|    policy_gradient_loss | 0.31      |\n",
      "|    std                  | 0.988     |\n",
      "|    value_loss           | 5.72e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 322        |\n",
      "|    time_elapsed         | 685        |\n",
      "|    total_timesteps      | 41216      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36804196 |\n",
      "|    clip_fraction        | 0.382      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.87      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.468      |\n",
      "|    n_updates            | 3210       |\n",
      "|    policy_gradient_loss | 0.432      |\n",
      "|    std                  | 0.989      |\n",
      "|    value_loss           | 1.06e-08   |\n",
      "----------------------------------------\n",
      "day: 521, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 323        |\n",
      "|    time_elapsed         | 687        |\n",
      "|    total_timesteps      | 41344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34694964 |\n",
      "|    clip_fraction        | 0.272      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.08      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.462      |\n",
      "|    n_updates            | 3220       |\n",
      "|    policy_gradient_loss | 0.31       |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 6.21e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 324        |\n",
      "|    time_elapsed         | 691        |\n",
      "|    total_timesteps      | 41472      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46356636 |\n",
      "|    clip_fraction        | 0.513      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.687     |\n",
      "|    explained_variance   | -30.1      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0449     |\n",
      "|    n_updates            | 3230       |\n",
      "|    policy_gradient_loss | 0.0424     |\n",
      "|    std                  | 0.991      |\n",
      "|    value_loss           | 3.98e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 325        |\n",
      "|    time_elapsed         | 692        |\n",
      "|    total_timesteps      | 41600      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29352596 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.04      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.408      |\n",
      "|    n_updates            | 3240       |\n",
      "|    policy_gradient_loss | 0.363      |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 3.16e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 326        |\n",
      "|    time_elapsed         | 694        |\n",
      "|    total_timesteps      | 41728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31810632 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.466      |\n",
      "|    n_updates            | 3250       |\n",
      "|    policy_gradient_loss | 0.358      |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 5.97e-10   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 327        |\n",
      "|    time_elapsed         | 695        |\n",
      "|    total_timesteps      | 41856      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33499432 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.988     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.451      |\n",
      "|    n_updates            | 3260       |\n",
      "|    policy_gradient_loss | 0.377      |\n",
      "|    std                  | 0.988      |\n",
      "|    value_loss           | 4.02e-10   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 328        |\n",
      "|    time_elapsed         | 699        |\n",
      "|    total_timesteps      | 41984      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43466693 |\n",
      "|    clip_fraction        | 0.463      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.764     |\n",
      "|    explained_variance   | -35.8      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0299     |\n",
      "|    n_updates            | 3270       |\n",
      "|    policy_gradient_loss | 0.0362     |\n",
      "|    std                  | 0.987      |\n",
      "|    value_loss           | 3.96e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 329        |\n",
      "|    time_elapsed         | 700        |\n",
      "|    total_timesteps      | 42112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28613365 |\n",
      "|    clip_fraction        | 0.314      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.964     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.464      |\n",
      "|    n_updates            | 3280       |\n",
      "|    policy_gradient_loss | 0.405      |\n",
      "|    std                  | 0.987      |\n",
      "|    value_loss           | 1.37e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 330       |\n",
      "|    time_elapsed         | 702       |\n",
      "|    total_timesteps      | 42240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3541858 |\n",
      "|    clip_fraction        | 0.386     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.963    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.437     |\n",
      "|    n_updates            | 3290      |\n",
      "|    policy_gradient_loss | 0.382     |\n",
      "|    std                  | 0.987     |\n",
      "|    value_loss           | 1.68e-09  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 331        |\n",
      "|    time_elapsed         | 703        |\n",
      "|    total_timesteps      | 42368      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37356204 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.217      |\n",
      "|    n_updates            | 3300       |\n",
      "|    policy_gradient_loss | 0.383      |\n",
      "|    std                  | 0.987      |\n",
      "|    value_loss           | 1.29e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 332       |\n",
      "|    time_elapsed         | 707       |\n",
      "|    total_timesteps      | 42496     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5889615 |\n",
      "|    clip_fraction        | 0.416     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.832    |\n",
      "|    explained_variance   | -59       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0216    |\n",
      "|    n_updates            | 3310      |\n",
      "|    policy_gradient_loss | 0.0211    |\n",
      "|    std                  | 0.987     |\n",
      "|    value_loss           | 3.9e-08   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 333        |\n",
      "|    time_elapsed         | 709        |\n",
      "|    total_timesteps      | 42624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37449718 |\n",
      "|    clip_fraction        | 0.379      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.879     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.472      |\n",
      "|    n_updates            | 3320       |\n",
      "|    policy_gradient_loss | 0.424      |\n",
      "|    std                  | 0.986      |\n",
      "|    value_loss           | 7.33e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 334       |\n",
      "|    time_elapsed         | 710       |\n",
      "|    total_timesteps      | 42752     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2756722 |\n",
      "|    clip_fraction        | 0.284     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.01     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.136     |\n",
      "|    n_updates            | 3330      |\n",
      "|    policy_gradient_loss | 0.371     |\n",
      "|    std                  | 0.986     |\n",
      "|    value_loss           | 2.84e-10  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 335        |\n",
      "|    time_elapsed         | 713        |\n",
      "|    total_timesteps      | 42880      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41884482 |\n",
      "|    clip_fraction        | 0.343      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.923     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.331      |\n",
      "|    n_updates            | 3340       |\n",
      "|    policy_gradient_loss | 0.424      |\n",
      "|    std                  | 0.987      |\n",
      "|    value_loss           | 2.09e-10   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 336       |\n",
      "|    time_elapsed         | 716       |\n",
      "|    total_timesteps      | 43008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6608801 |\n",
      "|    clip_fraction        | 0.302     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.983    |\n",
      "|    explained_variance   | -44.9     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0304    |\n",
      "|    n_updates            | 3350      |\n",
      "|    policy_gradient_loss | 0.0249    |\n",
      "|    std                  | 0.989     |\n",
      "|    value_loss           | 3.79e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 337        |\n",
      "|    time_elapsed         | 717        |\n",
      "|    total_timesteps      | 43136      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40796074 |\n",
      "|    clip_fraction        | 0.364      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.958     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.186      |\n",
      "|    n_updates            | 3360       |\n",
      "|    policy_gradient_loss | 0.392      |\n",
      "|    std                  | 0.989      |\n",
      "|    value_loss           | 3.68e-10   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 338        |\n",
      "|    time_elapsed         | 718        |\n",
      "|    total_timesteps      | 43264      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10453337 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.09      |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0561     |\n",
      "|    n_updates            | 3370       |\n",
      "|    policy_gradient_loss | 0.33       |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 1.63e-10   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 339       |\n",
      "|    time_elapsed         | 720       |\n",
      "|    total_timesteps      | 43392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4479579 |\n",
      "|    clip_fraction        | 0.286     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.01     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.329     |\n",
      "|    n_updates            | 3380      |\n",
      "|    policy_gradient_loss | 0.382     |\n",
      "|    std                  | 0.991     |\n",
      "|    value_loss           | 7.37e-10  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 340        |\n",
      "|    time_elapsed         | 723        |\n",
      "|    total_timesteps      | 43520      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.55022967 |\n",
      "|    clip_fraction        | 0.333      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.942     |\n",
      "|    explained_variance   | -56.4      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0155     |\n",
      "|    n_updates            | 3390       |\n",
      "|    policy_gradient_loss | 0.0234     |\n",
      "|    std                  | 0.994      |\n",
      "|    value_loss           | 3.23e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 341        |\n",
      "|    time_elapsed         | 725        |\n",
      "|    total_timesteps      | 43648      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36238724 |\n",
      "|    clip_fraction        | 0.344      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.927     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.449      |\n",
      "|    n_updates            | 3400       |\n",
      "|    policy_gradient_loss | 0.426      |\n",
      "|    std                  | 0.996      |\n",
      "|    value_loss           | 3.41e-10   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 342        |\n",
      "|    time_elapsed         | 726        |\n",
      "|    total_timesteps      | 43776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39094788 |\n",
      "|    clip_fraction        | 0.303      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.327      |\n",
      "|    n_updates            | 3410       |\n",
      "|    policy_gradient_loss | 0.333      |\n",
      "|    std                  | 0.996      |\n",
      "|    value_loss           | 1.53e-10   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 343        |\n",
      "|    time_elapsed         | 728        |\n",
      "|    total_timesteps      | 43904      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36831903 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.1       |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.193      |\n",
      "|    n_updates            | 3420       |\n",
      "|    policy_gradient_loss | 0.302      |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 2.26e-10   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 344        |\n",
      "|    time_elapsed         | 732        |\n",
      "|    total_timesteps      | 44032      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.52191496 |\n",
      "|    clip_fraction        | 0.375      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.909     |\n",
      "|    explained_variance   | -256       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0135    |\n",
      "|    n_updates            | 3430       |\n",
      "|    policy_gradient_loss | -0.00547   |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 2.87e-08   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 345          |\n",
      "|    time_elapsed         | 733          |\n",
      "|    total_timesteps      | 44160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057487655 |\n",
      "|    clip_fraction        | 0.268        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0109      |\n",
      "|    n_updates            | 3440         |\n",
      "|    policy_gradient_loss | 0.327        |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 8.99e-10     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 346        |\n",
      "|    time_elapsed         | 735        |\n",
      "|    total_timesteps      | 44288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29592016 |\n",
      "|    clip_fraction        | 0.324      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.991     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.387     |\n",
      "|    n_updates            | 3450       |\n",
      "|    policy_gradient_loss | -0.387     |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 2.48e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 347        |\n",
      "|    time_elapsed         | 737        |\n",
      "|    total_timesteps      | 44416      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31509545 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.08      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.238     |\n",
      "|    n_updates            | 3460       |\n",
      "|    policy_gradient_loss | -0.207     |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 4.08e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 348       |\n",
      "|    time_elapsed         | 740       |\n",
      "|    total_timesteps      | 44544     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5063339 |\n",
      "|    clip_fraction        | 0.407     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.86     |\n",
      "|    explained_variance   | -2.33e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0149   |\n",
      "|    n_updates            | 3470      |\n",
      "|    policy_gradient_loss | -0.0155   |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.44e-08  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 349       |\n",
      "|    time_elapsed         | 742       |\n",
      "|    total_timesteps      | 44672     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3094102 |\n",
      "|    clip_fraction        | 0.322     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.979    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.435     |\n",
      "|    n_updates            | 3480      |\n",
      "|    policy_gradient_loss | 0.372     |\n",
      "|    std                  | 0.998     |\n",
      "|    value_loss           | 1.52e-10  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 350       |\n",
      "|    time_elapsed         | 744       |\n",
      "|    total_timesteps      | 44800     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3847473 |\n",
      "|    clip_fraction        | 0.352     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.925    |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.327    |\n",
      "|    n_updates            | 3490      |\n",
      "|    policy_gradient_loss | -0.382    |\n",
      "|    std                  | 0.998     |\n",
      "|    value_loss           | 4.93e-11  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 351       |\n",
      "|    time_elapsed         | 745       |\n",
      "|    total_timesteps      | 44928     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3839739 |\n",
      "|    clip_fraction        | 0.302     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.989    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.443     |\n",
      "|    n_updates            | 3500      |\n",
      "|    policy_gradient_loss | 0.35      |\n",
      "|    std                  | 0.998     |\n",
      "|    value_loss           | 2.39e-12  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 352        |\n",
      "|    time_elapsed         | 749        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43068358 |\n",
      "|    clip_fraction        | 0.361      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.906     |\n",
      "|    explained_variance   | -8.37e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0246    |\n",
      "|    n_updates            | 3510       |\n",
      "|    policy_gradient_loss | -0.0174    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 2.14e-08   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 750         |\n",
      "|    total_timesteps      | 45184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008172968 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.994      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0185     |\n",
      "|    n_updates            | 3520        |\n",
      "|    policy_gradient_loss | 0.36        |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 1.72e-12    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 354        |\n",
      "|    time_elapsed         | 752        |\n",
      "|    total_timesteps      | 45312      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43027332 |\n",
      "|    clip_fraction        | 0.34       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.964     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.451      |\n",
      "|    n_updates            | 3530       |\n",
      "|    policy_gradient_loss | 0.387      |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 3.36e-12   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 355        |\n",
      "|    time_elapsed         | 753        |\n",
      "|    total_timesteps      | 45440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44055927 |\n",
      "|    clip_fraction        | 0.322      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.962     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.389      |\n",
      "|    n_updates            | 3540       |\n",
      "|    policy_gradient_loss | 0.394      |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 6.25e-12   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 356       |\n",
      "|    time_elapsed         | 758       |\n",
      "|    total_timesteps      | 45568     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5091808 |\n",
      "|    clip_fraction        | 0.514     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.73     |\n",
      "|    explained_variance   | -4.24e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0248   |\n",
      "|    n_updates            | 3550      |\n",
      "|    policy_gradient_loss | -0.0213   |\n",
      "|    std                  | 0.998     |\n",
      "|    value_loss           | 1.47e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 357        |\n",
      "|    time_elapsed         | 759        |\n",
      "|    total_timesteps      | 45696      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29524586 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.324      |\n",
      "|    n_updates            | 3560       |\n",
      "|    policy_gradient_loss | 0.338      |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 3.56e-10   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 358       |\n",
      "|    time_elapsed         | 760       |\n",
      "|    total_timesteps      | 45824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3202817 |\n",
      "|    clip_fraction        | 0.308     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.981    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.426    |\n",
      "|    n_updates            | 3570      |\n",
      "|    policy_gradient_loss | -0.406    |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.56e-09  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 359        |\n",
      "|    time_elapsed         | 762        |\n",
      "|    total_timesteps      | 45952      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33245072 |\n",
      "|    clip_fraction        | 0.361      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.907     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.457     |\n",
      "|    n_updates            | 3580       |\n",
      "|    policy_gradient_loss | -0.432     |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 5.49e-10   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 360       |\n",
      "|    time_elapsed         | 766       |\n",
      "|    total_timesteps      | 46080     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4090179 |\n",
      "|    clip_fraction        | 0.516     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.712    |\n",
      "|    explained_variance   | -114      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.076    |\n",
      "|    n_updates            | 3590      |\n",
      "|    policy_gradient_loss | -0.0675   |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.27e-08  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 361       |\n",
      "|    time_elapsed         | 768       |\n",
      "|    total_timesteps      | 46208     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2280317 |\n",
      "|    clip_fraction        | 0.314     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.984    |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.34     |\n",
      "|    n_updates            | 3600      |\n",
      "|    policy_gradient_loss | -0.386    |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.91e-10  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 362       |\n",
      "|    time_elapsed         | 769       |\n",
      "|    total_timesteps      | 46336     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3010364 |\n",
      "|    clip_fraction        | 0.365     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.903    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.421     |\n",
      "|    n_updates            | 3610      |\n",
      "|    policy_gradient_loss | 0.42      |\n",
      "|    std                  | 0.997     |\n",
      "|    value_loss           | 1.62e-09  |\n",
      "---------------------------------------\n",
      "day: 521, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999999.76\n",
      "total_reward: -0.24\n",
      "total_cost: 0.05\n",
      "total_trades: 2\n",
      "Sharpe: -0.779\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 363        |\n",
      "|    time_elapsed         | 770        |\n",
      "|    total_timesteps      | 46464      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35099933 |\n",
      "|    clip_fraction        | 0.388      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.935     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.287      |\n",
      "|    n_updates            | 3620       |\n",
      "|    policy_gradient_loss | 0.248      |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 1.93e-10   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 364        |\n",
      "|    time_elapsed         | 774        |\n",
      "|    total_timesteps      | 46592      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40184197 |\n",
      "|    clip_fraction        | 0.543      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.648     |\n",
      "|    explained_variance   | -1.94e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0136    |\n",
      "|    n_updates            | 3630       |\n",
      "|    policy_gradient_loss | -0.013     |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 1.03e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 365        |\n",
      "|    time_elapsed         | 776        |\n",
      "|    total_timesteps      | 46720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30689198 |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.989     |\n",
      "|    explained_variance   | -0.00413   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.4        |\n",
      "|    n_updates            | 3640       |\n",
      "|    policy_gradient_loss | 0.381      |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 2.52e-11   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 366         |\n",
      "|    time_elapsed         | 777         |\n",
      "|    total_timesteps      | 46848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.082984515 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.976      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0552      |\n",
      "|    n_updates            | 3650        |\n",
      "|    policy_gradient_loss | 0.36        |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 1.32e-10    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 367        |\n",
      "|    time_elapsed         | 779        |\n",
      "|    total_timesteps      | 46976      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33995974 |\n",
      "|    clip_fraction        | 0.36       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.905     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.46      |\n",
      "|    n_updates            | 3660       |\n",
      "|    policy_gradient_loss | -0.415     |\n",
      "|    std                  | 0.994      |\n",
      "|    value_loss           | 1.05e-10   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 368        |\n",
      "|    time_elapsed         | 780        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34414485 |\n",
      "|    clip_fraction        | 0.303      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.987     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.438     |\n",
      "|    n_updates            | 3670       |\n",
      "|    policy_gradient_loss | -0.347     |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 8.69e-11   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 369        |\n",
      "|    time_elapsed         | 785        |\n",
      "|    total_timesteps      | 47232      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40141895 |\n",
      "|    clip_fraction        | 0.587      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.583     |\n",
      "|    explained_variance   | -2.57e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.026     |\n",
      "|    n_updates            | 3680       |\n",
      "|    policy_gradient_loss | -0.0252    |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 8.21e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 370       |\n",
      "|    time_elapsed         | 786       |\n",
      "|    total_timesteps      | 47360     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3049496 |\n",
      "|    clip_fraction        | 0.316     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.964    |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.412     |\n",
      "|    n_updates            | 3690      |\n",
      "|    policy_gradient_loss | 0.351     |\n",
      "|    std                  | 0.988     |\n",
      "|    value_loss           | 5.8e-12   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 371        |\n",
      "|    time_elapsed         | 787        |\n",
      "|    total_timesteps      | 47488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33416706 |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.982     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.408      |\n",
      "|    n_updates            | 3700       |\n",
      "|    policy_gradient_loss | 0.375      |\n",
      "|    std                  | 0.987      |\n",
      "|    value_loss           | 3.67e-12   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 372       |\n",
      "|    time_elapsed         | 789       |\n",
      "|    total_timesteps      | 47616     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3834796 |\n",
      "|    clip_fraction        | 0.338     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.02     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.457    |\n",
      "|    n_updates            | 3710      |\n",
      "|    policy_gradient_loss | -0.338    |\n",
      "|    std                  | 0.986     |\n",
      "|    value_loss           | 4.32e-11  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 373        |\n",
      "|    time_elapsed         | 793        |\n",
      "|    total_timesteps      | 47744      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.58429575 |\n",
      "|    clip_fraction        | 0.449      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.779     |\n",
      "|    explained_variance   | -2.71e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0165    |\n",
      "|    n_updates            | 3720       |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 9.87e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 374        |\n",
      "|    time_elapsed         | 794        |\n",
      "|    total_timesteps      | 47872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37673903 |\n",
      "|    clip_fraction        | 0.356      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.912     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.375      |\n",
      "|    n_updates            | 3730       |\n",
      "|    policy_gradient_loss | 0.399      |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 3.51e-11   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 375        |\n",
      "|    time_elapsed         | 795        |\n",
      "|    total_timesteps      | 48000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42263043 |\n",
      "|    clip_fraction        | 0.314      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.961     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.357     |\n",
      "|    n_updates            | 3740       |\n",
      "|    policy_gradient_loss | -0.383     |\n",
      "|    std                  | 0.983      |\n",
      "|    value_loss           | 2.21e-10   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 376        |\n",
      "|    time_elapsed         | 796        |\n",
      "|    total_timesteps      | 48128      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42761675 |\n",
      "|    clip_fraction        | 0.276      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.368     |\n",
      "|    n_updates            | 3750       |\n",
      "|    policy_gradient_loss | -0.35      |\n",
      "|    std                  | 0.982      |\n",
      "|    value_loss           | 3.11e-10   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 377       |\n",
      "|    time_elapsed         | 800       |\n",
      "|    total_timesteps      | 48256     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6639662 |\n",
      "|    clip_fraction        | 0.37      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.883    |\n",
      "|    explained_variance   | -445      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0257   |\n",
      "|    n_updates            | 3760      |\n",
      "|    policy_gradient_loss | -0.0273   |\n",
      "|    std                  | 0.983     |\n",
      "|    value_loss           | 9.83e-09  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 378        |\n",
      "|    time_elapsed         | 801        |\n",
      "|    total_timesteps      | 48384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38205528 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.997     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.422     |\n",
      "|    n_updates            | 3770       |\n",
      "|    policy_gradient_loss | -0.358     |\n",
      "|    std                  | 0.985      |\n",
      "|    value_loss           | 7.01e-10   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 379        |\n",
      "|    time_elapsed         | 802        |\n",
      "|    total_timesteps      | 48512      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41196725 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.401      |\n",
      "|    n_updates            | 3780       |\n",
      "|    policy_gradient_loss | 0.366      |\n",
      "|    std                  | 0.982      |\n",
      "|    value_loss           | 2.36e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 380        |\n",
      "|    time_elapsed         | 803        |\n",
      "|    total_timesteps      | 48640      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39356244 |\n",
      "|    clip_fraction        | 0.332      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.938     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.467     |\n",
      "|    n_updates            | 3790       |\n",
      "|    policy_gradient_loss | -0.397     |\n",
      "|    std                  | 0.978      |\n",
      "|    value_loss           | 1.03e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 381        |\n",
      "|    time_elapsed         | 807        |\n",
      "|    total_timesteps      | 48768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.60330963 |\n",
      "|    clip_fraction        | 0.456      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.759     |\n",
      "|    explained_variance   | -385       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0303    |\n",
      "|    n_updates            | 3800       |\n",
      "|    policy_gradient_loss | -0.032     |\n",
      "|    std                  | 0.977      |\n",
      "|    value_loss           | 7.98e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 382        |\n",
      "|    time_elapsed         | 808        |\n",
      "|    total_timesteps      | 48896      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36943823 |\n",
      "|    clip_fraction        | 0.359      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.894     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.471     |\n",
      "|    n_updates            | 3810       |\n",
      "|    policy_gradient_loss | -0.415     |\n",
      "|    std                  | 0.976      |\n",
      "|    value_loss           | 6.91e-11   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 383        |\n",
      "|    time_elapsed         | 810        |\n",
      "|    total_timesteps      | 49024      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37278152 |\n",
      "|    clip_fraction        | 0.314      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.968     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.467     |\n",
      "|    n_updates            | 3820       |\n",
      "|    policy_gradient_loss | -0.399     |\n",
      "|    std                  | 0.976      |\n",
      "|    value_loss           | 3.48e-11   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 384        |\n",
      "|    time_elapsed         | 811        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35919914 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.412     |\n",
      "|    n_updates            | 3830       |\n",
      "|    policy_gradient_loss | -0.352     |\n",
      "|    std                  | 0.973      |\n",
      "|    value_loss           | 1.67e-11   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 385        |\n",
      "|    time_elapsed         | 815        |\n",
      "|    total_timesteps      | 49280      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42600113 |\n",
      "|    clip_fraction        | 0.353      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.973     |\n",
      "|    explained_variance   | -246       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0521    |\n",
      "|    n_updates            | 3840       |\n",
      "|    policy_gradient_loss | -0.0363    |\n",
      "|    std                  | 0.97       |\n",
      "|    value_loss           | 8.78e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 386        |\n",
      "|    time_elapsed         | 816        |\n",
      "|    total_timesteps      | 49408      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28649458 |\n",
      "|    clip_fraction        | 0.337      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.923     |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.444     |\n",
      "|    n_updates            | 3850       |\n",
      "|    policy_gradient_loss | -0.403     |\n",
      "|    std                  | 0.969      |\n",
      "|    value_loss           | 6.9e-12    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 387        |\n",
      "|    time_elapsed         | 817        |\n",
      "|    total_timesteps      | 49536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27231425 |\n",
      "|    clip_fraction        | 0.326      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.935     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.373     |\n",
      "|    n_updates            | 3860       |\n",
      "|    policy_gradient_loss | -0.405     |\n",
      "|    std                  | 0.967      |\n",
      "|    value_loss           | 2.86e-11   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 388       |\n",
      "|    time_elapsed         | 819       |\n",
      "|    total_timesteps      | 49664     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2895539 |\n",
      "|    clip_fraction        | 0.315     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.948    |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.452     |\n",
      "|    n_updates            | 3870      |\n",
      "|    policy_gradient_loss | 0.382     |\n",
      "|    std                  | 0.966     |\n",
      "|    value_loss           | 2.12e-11  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 389        |\n",
      "|    time_elapsed         | 822        |\n",
      "|    total_timesteps      | 49792      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.50697726 |\n",
      "|    clip_fraction        | 0.357      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.916     |\n",
      "|    explained_variance   | -260       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0113    |\n",
      "|    n_updates            | 3880       |\n",
      "|    policy_gradient_loss | -0.00561   |\n",
      "|    std                  | 0.966      |\n",
      "|    value_loss           | 7.49e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 390        |\n",
      "|    time_elapsed         | 823        |\n",
      "|    total_timesteps      | 49920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26360092 |\n",
      "|    clip_fraction        | 0.311      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.955     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.238      |\n",
      "|    n_updates            | 3890       |\n",
      "|    policy_gradient_loss | 0.377      |\n",
      "|    std                  | 0.969      |\n",
      "|    value_loss           | 7e-13      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 391        |\n",
      "|    time_elapsed         | 824        |\n",
      "|    total_timesteps      | 50048      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28797945 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.09      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.335     |\n",
      "|    n_updates            | 3900       |\n",
      "|    policy_gradient_loss | -0.218     |\n",
      "|    std                  | 0.971      |\n",
      "|    value_loss           | 2.62e-09   |\n",
      "----------------------------------------\n",
      "day: 521, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "day: 521, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "model = RecurrentPPO(\"MlpLstmPolicy\", env=env_train, verbose=1)\n",
    "model.learn(50000)\n",
    "model_version = '50000_iter_'\n",
    "model_name = 'recurrent_ppo'\n",
    "\n",
    "env = model.get_env()\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=20, warn=False)\n",
    "print(mean_reward)\n",
    "\n",
    "model.save(os.path.join(TRAINED_MODEL_DIR, model_version + model_name  + \".pth\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "f2wZgkQXh1jE"
   },
   "source": [
    "# Trading\n",
    "Assume that we have $1,000,000 initial capital at 2020-07-01. We use the DDPG model to trade Dow jones 30 stocks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "bEv5KGC8h1jE"
   },
   "source": [
    "### Set turbulence threshold\n",
    "Set the turbulence threshold to be greater than the maximum of insample turbulence data, if current turbulence index is greater than the threshold, then we assume that the current market is volatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "efwBi84ch1jE"
   },
   "outputs": [],
   "source": [
    "data_risk_indicator = processed_full[(processed_full.date<trade_end_date) & (processed_full.date> train_end_date)]\n",
    "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "VHZMBpSqh1jG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    250.000000\n",
       "mean      25.639720\n",
       "std        4.216336\n",
       "min       16.600000\n",
       "25%       22.230000\n",
       "50%       25.505000\n",
       "75%       28.930001\n",
       "max       36.450001\n",
       "Name: vix, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "BDkszkMloRWT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.13528106689452"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.quantile(0.996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "AL7hs7svnNWT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    250.000000\n",
       "mean      10.574578\n",
       "std       12.101466\n",
       "min        0.451542\n",
       "25%        4.143907\n",
       "50%        7.096417\n",
       "75%       13.162082\n",
       "max       89.601229\n",
       "Name: turbulence, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "N78hfHckoqJ9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.29403926590331"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.quantile(0.996)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "U5mmgQF_h1jQ"
   },
   "source": [
    "### Trade\n",
    "\n",
    "DRL model needs to update periodically in order to take full advantage of the data, ideally we need to retrain our model yearly, quarterly, or monthly. We also need to tune the parameters along the way, in this notebook I only use the in-sample data from 2009-01 to 2020-07 to tune the parameters once, so there is some alpha decay here as the length of trade date extends. \n",
    "\n",
    "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "cIqoV0GSI52v"
   },
   "outputs": [],
   "source": [
    "#trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70, risk_indicator_col='vix', **env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "W_XNgGsBMeVw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>adj close</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>macd</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.726818</td>\n",
       "      <td>0.726818</td>\n",
       "      <td>0.727908</td>\n",
       "      <td>0.718590</td>\n",
       "      <td>0.726850</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>51.288051</td>\n",
       "      <td>104.966545</td>\n",
       "      <td>3.520604</td>\n",
       "      <td>0.716629</td>\n",
       "      <td>0.728673</td>\n",
       "      <td>16.6</td>\n",
       "      <td>6.664439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>EURUSD=X</td>\n",
       "      <td>1.137346</td>\n",
       "      <td>1.137346</td>\n",
       "      <td>1.137592</td>\n",
       "      <td>1.128541</td>\n",
       "      <td>1.137385</td>\n",
       "      <td>-0.000456</td>\n",
       "      <td>47.814245</td>\n",
       "      <td>122.620797</td>\n",
       "      <td>9.183568</td>\n",
       "      <td>1.129750</td>\n",
       "      <td>1.141925</td>\n",
       "      <td>16.6</td>\n",
       "      <td>6.664439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>GBPUSD=X</td>\n",
       "      <td>1.352228</td>\n",
       "      <td>1.352228</td>\n",
       "      <td>1.353180</td>\n",
       "      <td>1.343274</td>\n",
       "      <td>1.352228</td>\n",
       "      <td>0.003050</td>\n",
       "      <td>53.283006</td>\n",
       "      <td>154.852691</td>\n",
       "      <td>21.800040</td>\n",
       "      <td>1.332292</td>\n",
       "      <td>1.346930</td>\n",
       "      <td>16.6</td>\n",
       "      <td>6.664439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>USDCAD=X</td>\n",
       "      <td>1.265880</td>\n",
       "      <td>1.265880</td>\n",
       "      <td>1.277810</td>\n",
       "      <td>1.264400</td>\n",
       "      <td>1.265710</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>48.905144</td>\n",
       "      <td>-87.188526</td>\n",
       "      <td>9.888084</td>\n",
       "      <td>1.277323</td>\n",
       "      <td>1.260846</td>\n",
       "      <td>16.6</td>\n",
       "      <td>6.664439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>USDCHF=X</td>\n",
       "      <td>0.911975</td>\n",
       "      <td>0.911975</td>\n",
       "      <td>0.919910</td>\n",
       "      <td>0.911500</td>\n",
       "      <td>0.912030</td>\n",
       "      <td>-0.002360</td>\n",
       "      <td>43.914787</td>\n",
       "      <td>-136.171788</td>\n",
       "      <td>14.666355</td>\n",
       "      <td>0.922099</td>\n",
       "      <td>0.921011</td>\n",
       "      <td>16.6</td>\n",
       "      <td>6.664439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       tic  adj close     close      high       low      open  \\\n",
       "0  2022-01-03  AUDUSD=X   0.726818  0.726818  0.727908  0.718590  0.726850   \n",
       "0  2022-01-03  EURUSD=X   1.137346  1.137346  1.137592  1.128541  1.137385   \n",
       "0  2022-01-03  GBPUSD=X   1.352228  1.352228  1.353180  1.343274  1.352228   \n",
       "0  2022-01-03  USDCAD=X   1.265880  1.265880  1.277810  1.264400  1.265710   \n",
       "0  2022-01-03  USDCHF=X   0.911975  0.911975  0.919910  0.911500  0.912030   \n",
       "\n",
       "       macd     rsi_30      cci_30      dx_30  close_30_sma  close_60_sma  \\\n",
       "0  0.001099  51.288051  104.966545   3.520604      0.716629      0.728673   \n",
       "0 -0.000456  47.814245  122.620797   9.183568      1.129750      1.141925   \n",
       "0  0.003050  53.283006  154.852691  21.800040      1.332292      1.346930   \n",
       "0  0.002133  48.905144  -87.188526   9.888084      1.277323      1.260846   \n",
       "0 -0.002360  43.914787 -136.171788  14.666355      0.922099      0.921011   \n",
       "\n",
       "    vix  turbulence  \n",
       "0  16.6    6.664439  \n",
       "0  16.6    6.664439  \n",
       "0  16.6    6.664439  \n",
       "0  16.6    6.664439  \n",
       "0  16.6    6.664439  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load model MARKETS/ForexMarket/TRAINED_MODEL_DIR/DDPG_100000.pth\n"
     ]
    }
   ],
   "source": [
    "model_name = 'DDPG_100000.pth'\n",
    "train_model_path = os.path.join(TRAINED_MODEL_DIR, model_name)\n",
    "trained_ddpg = DRLAgent.DRL_load_from_file(model_name = 'ddpg' ,\n",
    "    cwd=train_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "eLOnL5eYh1jR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_ddpg, \n",
    "    environment=e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "nFlK5hNbWVFk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "action_value_df = pd.merge(df_actions, df_account_value,on='date')\n",
    "action_value_df.to_csv(os.path.join(RESULTS_DIR,'ddpg_100000_total_timesteps_actions_account_value.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUDUSD=X</th>\n",
       "      <th>EURUSD=X</th>\n",
       "      <th>GBPUSD=X</th>\n",
       "      <th>USDCAD=X</th>\n",
       "      <th>USDCHF=X</th>\n",
       "      <th>USDJPY=X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-06</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-07</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AUDUSD=X  EURUSD=X  GBPUSD=X  USDCAD=X  USDCHF=X  USDJPY=X\n",
       "date                                                                  \n",
       "2022-01-03       100         0         0       100       100       100\n",
       "2022-01-04       100         0         0       100       100       100\n",
       "2022-01-05       100         0         0       100       100       100\n",
       "2022-01-06       100         0         0       100       100       100\n",
       "2022-01-07       100         0         0       100       100       100\n",
       "...              ...       ...       ...       ...       ...       ...\n",
       "2022-12-21         0         0         0         0         0         0\n",
       "2022-12-22         0         0         0         0         0         0\n",
       "2022-12-23         0         0         0         0         0         0\n",
       "2022-12-27         0         0         0         0         0         0\n",
       "2022-12-28         0         0         0         0         0         0\n",
       "\n",
       "[249 rows x 6 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trade by recurrentppo\n",
    "\n",
    "we use recurrent ppo as alternative to finrl's drl agents beacause our env is partially observable and we need memory so we use recurrent ppo (lstm ppo) for using of recurrent prediction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "e_trade_gym = StockTradingEnv(df = trade,  turbulence_threshold = 70,risk_indicator_col='vix', **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MARKETS/ForexMarket/TRAINED_MODEL_DIR/1000000DDPG_.pth'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(TRAINED_MODEL_DIR,  model_version + model_version + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TD3Policy.__init__() got an unexpected keyword argument 'use_sde'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_version \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m1000000\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      2\u001b[0m model_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDDPG_\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m model \u001b[39m=\u001b[39m RecurrentPPO\u001b[39m.\u001b[39;49mload(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(TRAINED_MODEL_DIR,  model_name \u001b[39m+\u001b[39;49m model_version \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.pth\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m~/miniconda3/envs/Finrl/lib/python3.10/site-packages/stable_baselines3/common/base_class.py:741\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[0;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m model\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m.\u001b[39mupdate(data)\n\u001b[1;32m    740\u001b[0m model\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[0;32m--> 741\u001b[0m model\u001b[39m.\u001b[39;49m_setup_model()\n\u001b[1;32m    743\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    744\u001b[0m     \u001b[39m# put state_dicts back in place\u001b[39;00m\n\u001b[1;32m    745\u001b[0m     model\u001b[39m.\u001b[39mset_parameters(params, exact_match\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, device\u001b[39m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/Finrl/lib/python3.10/site-packages/sb3_contrib/ppo_recurrent/ppo_recurrent.py:147\u001b[0m, in \u001b[0;36mRecurrentPPO._setup_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_random_seed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseed)\n\u001b[1;32m    145\u001b[0m buffer_cls \u001b[39m=\u001b[39m RecurrentDictRolloutBuffer \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_space, spaces\u001b[39m.\u001b[39mDict) \u001b[39melse\u001b[39;00m RecurrentRolloutBuffer\n\u001b[0;32m--> 147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy_class(\n\u001b[1;32m    148\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobservation_space,\n\u001b[1;32m    149\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_space,\n\u001b[1;32m    150\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlr_schedule,\n\u001b[1;32m    151\u001b[0m     use_sde\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muse_sde,\n\u001b[1;32m    152\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy_kwargs,  \u001b[39m# pytype:disable=not-instantiable\u001b[39;49;00m\n\u001b[1;32m    153\u001b[0m )\n\u001b[1;32m    154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    156\u001b[0m \u001b[39m# We assume that LSTM for the actor and the critic\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39m# have the same architecture\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: TD3Policy.__init__() got an unexpected keyword argument 'use_sde'"
     ]
    }
   ],
   "source": [
    "model_version = '1000000'\n",
    "model_name = 'DDPG_'\n",
    "model = RecurrentPPO.load(os.path.join(TRAINED_MODEL_DIR,  model_name + model_version + \".pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "account_memory = []\n",
    "actions_memory = []\n",
    "lstm_states = None\n",
    "num_envs = 1\n",
    "episode_starts = np.ones((num_envs,), dtype=bool)\n",
    "#         state_memory=[] #add memory pool to store states\n",
    "env_trade.reset()\n",
    "for i in range(len(e_trade_gym.df.index.unique())):\n",
    "    action, lstm_states = model.predict(obs_trade, state=lstm_states, episode_start=episode_starts, deterministic=True)\n",
    "            # account_memory = test_env.env_method(method_name=\"save_asset_memory\")\n",
    "            # actions_memory = test_env.env_method(method_name=\"save_action_memory\")\n",
    "    obs_trade, rewards, dones, info = env_trade.step(action)\n",
    "    episode_starts = dones\n",
    "    env_trade.render()\n",
    "    if i == (len(e_trade_gym.df.index.unique()) - 2):\n",
    "        account_memory = env_trade.env_method(method_name=\"save_asset_memory\")\n",
    "        actions_memory = env_trade.env_method(method_name=\"save_action_memory\")\n",
    "#                 state_memory=test_env.env_method(method_name=\"save_state_memory\") # add current state to state memory\n",
    "    if dones[0]:\n",
    "        print(i)\n",
    "        print(\"hit end!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'account_memory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_account_value \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(account_memory[\u001b[39m0\u001b[39m])\n\u001b[1;32m      2\u001b[0m df_actions_memory \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(actions_memory[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'account_memory' is not defined"
     ]
    }
   ],
   "source": [
    "df_account_value = pd.DataFrame(account_memory[0])\n",
    "df_actions_memory = pd.DataFrame(actions_memory[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-04-26</td>\n",
       "      <td>1.000000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-27</td>\n",
       "      <td>1.017711e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>1.014192e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-29</td>\n",
       "      <td>9.902239e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>1.067545e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2021-09-17</td>\n",
       "      <td>8.741583e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2021-09-20</td>\n",
       "      <td>7.944693e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2021-09-21</td>\n",
       "      <td>7.521426e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2021-09-22</td>\n",
       "      <td>8.052165e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2021-09-23</td>\n",
       "      <td>8.296022e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  account_value\n",
       "0    2021-04-26   1.000000e+06\n",
       "1    2021-04-27   1.017711e+06\n",
       "2    2021-04-28   1.014192e+06\n",
       "3    2021-04-29   9.902239e+05\n",
       "4    2021-04-30   1.067545e+06\n",
       "..          ...            ...\n",
       "101  2021-09-17   8.741583e+05\n",
       "102  2021-09-20   7.944693e+05\n",
       "103  2021-09-21   7.521426e+05\n",
       "104  2021-09-22   8.052165e+05\n",
       "105  2021-09-23   8.296022e+05\n",
       "\n",
       "[106 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Nzkr9yv-AdV_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.126088\n",
      "Cumulative returns     0.125027\n",
      "Annual volatility      0.111443\n",
      "Sharpe ratio           1.125815\n",
      "Calmar ratio           1.053380\n",
      "Stability              0.780501\n",
      "Max drawdown          -0.119698\n",
      "Omega ratio            1.230706\n",
      "Sortino ratio          1.533858\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.870876\n",
      "Daily value at risk   -0.013543\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>0.126088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>0.125027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>0.111443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>1.125815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>1.053380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.780501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-0.119698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>1.230706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>1.533858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>0.870876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-0.013543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0\n",
       "Annual return        0.126088\n",
       "Cumulative returns   0.125027\n",
       "Annual volatility    0.111443\n",
       "Sharpe ratio         1.125815\n",
       "Calmar ratio         1.053380\n",
       "Stability            0.780501\n",
       "Max drawdown        -0.119698\n",
       "Omega ratio          1.230706\n",
       "Sortino ratio        1.533858\n",
       "Skew                      NaN\n",
       "Kurtosis                  NaN\n",
       "Tail ratio           0.870876\n",
       "Daily value at risk -0.013543"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "QkV-LB66iwhD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n",
      "Annual return          1.402440e+00\n",
      "Cumulative returns     1.834120e+02\n",
      "Annual volatility      8.110592e+02\n",
      "Sharpe ratio           7.051340e+00\n",
      "Calmar ratio           1.408338e+00\n",
      "Stability              4.270229e-07\n",
      "Max drawdown          -9.958126e-01\n",
      "Omega ratio            1.079497e+02\n",
      "Sortino ratio          8.579339e+02\n",
      "Skew                            NaN\n",
      "Kurtosis                        NaN\n",
      "Tail ratio             1.433154e+02\n",
      "Daily value at risk   -7.948919e+01\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "\n",
    "stats = backtest_stats(trade, value_col_name = 'adj close')\n",
    "stats.to_csv(os.path.join(RESULTS_DIR,'baseline_stats' + \".csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Annual return          1.402440e+00\n",
       "Cumulative returns     1.834120e+02\n",
       "Annual volatility      8.110592e+02\n",
       "Sharpe ratio           7.051340e+00\n",
       "Calmar ratio           1.408338e+00\n",
       "Stability              4.270229e-07\n",
       "Max drawdown          -9.958126e-01\n",
       "Omega ratio            1.079497e+02\n",
       "Sortino ratio          8.579339e+02\n",
       "Skew                            NaN\n",
       "Kurtosis                        NaN\n",
       "Tail ratio             1.433154e+02\n",
       "Daily value at risk   -7.948919e+01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = trade['tic'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "tt1bzL5OrsTa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-12-29'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.loc[len(df_account_value)-1,'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_items = ['start']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1519/1491087412.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stock_data ['SMA'] = stock_data['adj close'].rolling(window=sma_period).mean()\n"
     ]
    }
   ],
   "source": [
    "sma_period = 1\n",
    "stock_symbol = stocks[0]\n",
    "stock_data = trade[trade['tic'] == stock_symbol]\n",
    "stock_data ['SMA'] = stock_data['adj close'].rolling(window=sma_period).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>adj close</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>macd</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "      <th>SMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.726818</td>\n",
       "      <td>0.726818</td>\n",
       "      <td>0.727908</td>\n",
       "      <td>0.718590</td>\n",
       "      <td>0.726850</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>51.288051</td>\n",
       "      <td>104.966545</td>\n",
       "      <td>3.520604</td>\n",
       "      <td>0.716629</td>\n",
       "      <td>0.728673</td>\n",
       "      <td>16.600000</td>\n",
       "      <td>6.664439</td>\n",
       "      <td>0.726818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.719800</td>\n",
       "      <td>0.719800</td>\n",
       "      <td>0.724900</td>\n",
       "      <td>0.718530</td>\n",
       "      <td>0.719690</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>47.194235</td>\n",
       "      <td>61.427910</td>\n",
       "      <td>3.674852</td>\n",
       "      <td>0.716529</td>\n",
       "      <td>0.728422</td>\n",
       "      <td>16.910000</td>\n",
       "      <td>6.206088</td>\n",
       "      <td>0.719800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.723880</td>\n",
       "      <td>0.723880</td>\n",
       "      <td>0.727180</td>\n",
       "      <td>0.722340</td>\n",
       "      <td>0.724108</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>49.613136</td>\n",
       "      <td>103.112212</td>\n",
       "      <td>2.658069</td>\n",
       "      <td>0.716584</td>\n",
       "      <td>0.728262</td>\n",
       "      <td>19.730000</td>\n",
       "      <td>13.829550</td>\n",
       "      <td>0.723880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.722080</td>\n",
       "      <td>0.722080</td>\n",
       "      <td>0.722300</td>\n",
       "      <td>0.714660</td>\n",
       "      <td>0.722300</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>48.597134</td>\n",
       "      <td>40.234807</td>\n",
       "      <td>15.847883</td>\n",
       "      <td>0.716647</td>\n",
       "      <td>0.727986</td>\n",
       "      <td>19.610001</td>\n",
       "      <td>7.176280</td>\n",
       "      <td>0.722080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.716260</td>\n",
       "      <td>0.716260</td>\n",
       "      <td>0.718592</td>\n",
       "      <td>0.713109</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>45.482040</td>\n",
       "      <td>-8.628733</td>\n",
       "      <td>18.999867</td>\n",
       "      <td>0.716610</td>\n",
       "      <td>0.727568</td>\n",
       "      <td>18.760000</td>\n",
       "      <td>13.874675</td>\n",
       "      <td>0.716260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2022-12-22</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.671682</td>\n",
       "      <td>0.671682</td>\n",
       "      <td>0.676800</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>0.671682</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>51.917093</td>\n",
       "      <td>-12.603217</td>\n",
       "      <td>0.841755</td>\n",
       "      <td>0.672561</td>\n",
       "      <td>0.655427</td>\n",
       "      <td>21.969999</td>\n",
       "      <td>6.532908</td>\n",
       "      <td>0.671682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.667800</td>\n",
       "      <td>0.667800</td>\n",
       "      <td>0.671321</td>\n",
       "      <td>0.666138</td>\n",
       "      <td>0.667800</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>50.526158</td>\n",
       "      <td>-67.043650</td>\n",
       "      <td>0.600092</td>\n",
       "      <td>0.672798</td>\n",
       "      <td>0.655702</td>\n",
       "      <td>20.870001</td>\n",
       "      <td>2.297701</td>\n",
       "      <td>0.667800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.674459</td>\n",
       "      <td>0.674459</td>\n",
       "      <td>0.678000</td>\n",
       "      <td>0.672580</td>\n",
       "      <td>0.674459</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>52.807147</td>\n",
       "      <td>29.541345</td>\n",
       "      <td>10.095464</td>\n",
       "      <td>0.673020</td>\n",
       "      <td>0.656593</td>\n",
       "      <td>21.650000</td>\n",
       "      <td>4.062184</td>\n",
       "      <td>0.674459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.672993</td>\n",
       "      <td>0.672993</td>\n",
       "      <td>0.680100</td>\n",
       "      <td>0.672011</td>\n",
       "      <td>0.672993</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>52.248812</td>\n",
       "      <td>30.985523</td>\n",
       "      <td>13.389150</td>\n",
       "      <td>0.672888</td>\n",
       "      <td>0.656952</td>\n",
       "      <td>22.139999</td>\n",
       "      <td>3.726654</td>\n",
       "      <td>0.672993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.674710</td>\n",
       "      <td>0.674710</td>\n",
       "      <td>0.677900</td>\n",
       "      <td>0.671130</td>\n",
       "      <td>0.674710</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>52.852837</td>\n",
       "      <td>22.174281</td>\n",
       "      <td>11.555769</td>\n",
       "      <td>0.672913</td>\n",
       "      <td>0.657343</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>6.166426</td>\n",
       "      <td>0.674710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date       tic  adj close     close      high       low      open  \\\n",
       "0    2022-01-03  AUDUSD=X   0.726818  0.726818  0.727908  0.718590  0.726850   \n",
       "1    2022-01-04  AUDUSD=X   0.719800  0.719800  0.724900  0.718530  0.719690   \n",
       "2    2022-01-05  AUDUSD=X   0.723880  0.723880  0.727180  0.722340  0.724108   \n",
       "3    2022-01-06  AUDUSD=X   0.722080  0.722080  0.722300  0.714660  0.722300   \n",
       "4    2022-01-07  AUDUSD=X   0.716260  0.716260  0.718592  0.713109  0.716399   \n",
       "..          ...       ...        ...       ...       ...       ...       ...   \n",
       "245  2022-12-22  AUDUSD=X   0.671682  0.671682  0.676800  0.667000  0.671682   \n",
       "246  2022-12-23  AUDUSD=X   0.667800  0.667800  0.671321  0.666138  0.667800   \n",
       "247  2022-12-27  AUDUSD=X   0.674459  0.674459  0.678000  0.672580  0.674459   \n",
       "248  2022-12-28  AUDUSD=X   0.672993  0.672993  0.680100  0.672011  0.672993   \n",
       "249  2022-12-29  AUDUSD=X   0.674710  0.674710  0.677900  0.671130  0.674710   \n",
       "\n",
       "         macd     rsi_30      cci_30      dx_30  close_30_sma  close_60_sma  \\\n",
       "0    0.001099  51.288051  104.966545   3.520604      0.716629      0.728673   \n",
       "1    0.000856  47.194235   61.427910   3.674852      0.716529      0.728422   \n",
       "2    0.000981  49.613136  103.112212   2.658069      0.716584      0.728262   \n",
       "3    0.000925  48.597134   40.234807  15.847883      0.716647      0.727986   \n",
       "4    0.000406  45.482040   -8.628733  18.999867      0.716610      0.727568   \n",
       "..        ...        ...         ...        ...           ...           ...   \n",
       "245  0.002759  51.917093  -12.603217   0.841755      0.672561      0.655427   \n",
       "246  0.002126  50.526158  -67.043650   0.600092      0.672798      0.655702   \n",
       "247  0.001923  52.807147   29.541345  10.095464      0.673020      0.656593   \n",
       "248  0.001817  52.248812   30.985523  13.389150      0.672888      0.656952   \n",
       "249  0.001851  52.852837   22.174281  11.555769      0.672913      0.657343   \n",
       "\n",
       "           vix  turbulence       SMA  \n",
       "0    16.600000    6.664439  0.726818  \n",
       "1    16.910000    6.206088  0.719800  \n",
       "2    19.730000   13.829550  0.723880  \n",
       "3    19.610001    7.176280  0.722080  \n",
       "4    18.760000   13.874675  0.716260  \n",
       "..         ...         ...       ...  \n",
       "245  21.969999    6.532908  0.671682  \n",
       "246  20.870001    2.297701  0.667800  \n",
       "247  21.650000    4.062184  0.674459  \n",
       "248  22.139999    3.726654  0.672993  \n",
       "249  21.440001    6.166426  0.674710  \n",
       "\n",
       "[250 rows x 16 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>adj close</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>macd</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "      <th>SMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>USDJPY=X</td>\n",
       "      <td>115.141998</td>\n",
       "      <td>115.141998</td>\n",
       "      <td>115.360001</td>\n",
       "      <td>114.973999</td>\n",
       "      <td>115.136002</td>\n",
       "      <td>0.336429</td>\n",
       "      <td>59.785097</td>\n",
       "      <td>119.022871</td>\n",
       "      <td>35.751020</td>\n",
       "      <td>114.057167</td>\n",
       "      <td>113.992867</td>\n",
       "      <td>16.600000</td>\n",
       "      <td>6.664439</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>USDJPY=X</td>\n",
       "      <td>115.328003</td>\n",
       "      <td>115.328003</td>\n",
       "      <td>116.339996</td>\n",
       "      <td>115.299004</td>\n",
       "      <td>115.316002</td>\n",
       "      <td>0.374949</td>\n",
       "      <td>60.706895</td>\n",
       "      <td>161.120593</td>\n",
       "      <td>52.119439</td>\n",
       "      <td>114.075101</td>\n",
       "      <td>114.025200</td>\n",
       "      <td>16.910000</td>\n",
       "      <td>6.206088</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>USDJPY=X</td>\n",
       "      <td>116.174004</td>\n",
       "      <td>116.174004</td>\n",
       "      <td>116.235001</td>\n",
       "      <td>115.626999</td>\n",
       "      <td>116.165001</td>\n",
       "      <td>0.468343</td>\n",
       "      <td>64.532095</td>\n",
       "      <td>185.233395</td>\n",
       "      <td>52.119439</td>\n",
       "      <td>114.109534</td>\n",
       "      <td>114.069451</td>\n",
       "      <td>19.730000</td>\n",
       "      <td>13.829550</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>USDJPY=X</td>\n",
       "      <td>116.127998</td>\n",
       "      <td>116.127998</td>\n",
       "      <td>116.179001</td>\n",
       "      <td>115.653999</td>\n",
       "      <td>116.128998</td>\n",
       "      <td>0.532507</td>\n",
       "      <td>64.180614</td>\n",
       "      <td>174.712336</td>\n",
       "      <td>52.119439</td>\n",
       "      <td>114.133534</td>\n",
       "      <td>114.116567</td>\n",
       "      <td>19.610001</td>\n",
       "      <td>7.176280</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>USDJPY=X</td>\n",
       "      <td>115.864998</td>\n",
       "      <td>115.864998</td>\n",
       "      <td>116.029999</td>\n",
       "      <td>115.591003</td>\n",
       "      <td>115.870003</td>\n",
       "      <td>0.555730</td>\n",
       "      <td>62.177831</td>\n",
       "      <td>143.956861</td>\n",
       "      <td>49.136100</td>\n",
       "      <td>114.160067</td>\n",
       "      <td>114.150417</td>\n",
       "      <td>18.760000</td>\n",
       "      <td>13.874675</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2022-12-22</td>\n",
       "      <td>USDJPY=X</td>\n",
       "      <td>132.369995</td>\n",
       "      <td>132.369995</td>\n",
       "      <td>132.681000</td>\n",
       "      <td>131.654999</td>\n",
       "      <td>132.369995</td>\n",
       "      <td>-1.924860</td>\n",
       "      <td>38.041798</td>\n",
       "      <td>-178.880110</td>\n",
       "      <td>43.783778</td>\n",
       "      <td>137.747166</td>\n",
       "      <td>142.335549</td>\n",
       "      <td>21.969999</td>\n",
       "      <td>6.532908</td>\n",
       "      <td>141.935759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>USDJPY=X</td>\n",
       "      <td>132.356995</td>\n",
       "      <td>132.356995</td>\n",
       "      <td>133.121002</td>\n",
       "      <td>132.291000</td>\n",
       "      <td>132.356995</td>\n",
       "      <td>-2.040124</td>\n",
       "      <td>38.025650</td>\n",
       "      <td>-156.463915</td>\n",
       "      <td>39.466543</td>\n",
       "      <td>137.434600</td>\n",
       "      <td>142.134316</td>\n",
       "      <td>20.870001</td>\n",
       "      <td>2.297701</td>\n",
       "      <td>141.648159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>USDJPY=X</td>\n",
       "      <td>132.764008</td>\n",
       "      <td>132.764008</td>\n",
       "      <td>133.587006</td>\n",
       "      <td>132.647995</td>\n",
       "      <td>132.764008</td>\n",
       "      <td>-2.076570</td>\n",
       "      <td>38.884193</td>\n",
       "      <td>-124.042215</td>\n",
       "      <td>34.652173</td>\n",
       "      <td>136.964133</td>\n",
       "      <td>141.737966</td>\n",
       "      <td>21.650000</td>\n",
       "      <td>4.062184</td>\n",
       "      <td>141.357579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>USDJPY=X</td>\n",
       "      <td>133.485992</td>\n",
       "      <td>133.485992</td>\n",
       "      <td>134.395004</td>\n",
       "      <td>133.410995</td>\n",
       "      <td>133.485992</td>\n",
       "      <td>-1.998389</td>\n",
       "      <td>40.415416</td>\n",
       "      <td>-93.656085</td>\n",
       "      <td>26.430901</td>\n",
       "      <td>136.781500</td>\n",
       "      <td>141.566282</td>\n",
       "      <td>22.139999</td>\n",
       "      <td>3.726654</td>\n",
       "      <td>141.054659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>USDJPY=X</td>\n",
       "      <td>134.033997</td>\n",
       "      <td>134.033997</td>\n",
       "      <td>134.188004</td>\n",
       "      <td>132.936005</td>\n",
       "      <td>134.033997</td>\n",
       "      <td>-1.870648</td>\n",
       "      <td>41.564990</td>\n",
       "      <td>-88.398318</td>\n",
       "      <td>29.149269</td>\n",
       "      <td>136.605233</td>\n",
       "      <td>141.392699</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>6.166426</td>\n",
       "      <td>140.755919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date       tic   adj close       close        high         low  \\\n",
       "0    2022-01-03  USDJPY=X  115.141998  115.141998  115.360001  114.973999   \n",
       "1    2022-01-04  USDJPY=X  115.328003  115.328003  116.339996  115.299004   \n",
       "2    2022-01-05  USDJPY=X  116.174004  116.174004  116.235001  115.626999   \n",
       "3    2022-01-06  USDJPY=X  116.127998  116.127998  116.179001  115.653999   \n",
       "4    2022-01-07  USDJPY=X  115.864998  115.864998  116.029999  115.591003   \n",
       "..          ...       ...         ...         ...         ...         ...   \n",
       "245  2022-12-22  USDJPY=X  132.369995  132.369995  132.681000  131.654999   \n",
       "246  2022-12-23  USDJPY=X  132.356995  132.356995  133.121002  132.291000   \n",
       "247  2022-12-27  USDJPY=X  132.764008  132.764008  133.587006  132.647995   \n",
       "248  2022-12-28  USDJPY=X  133.485992  133.485992  134.395004  133.410995   \n",
       "249  2022-12-29  USDJPY=X  134.033997  134.033997  134.188004  132.936005   \n",
       "\n",
       "           open      macd     rsi_30      cci_30      dx_30  close_30_sma  \\\n",
       "0    115.136002  0.336429  59.785097  119.022871  35.751020    114.057167   \n",
       "1    115.316002  0.374949  60.706895  161.120593  52.119439    114.075101   \n",
       "2    116.165001  0.468343  64.532095  185.233395  52.119439    114.109534   \n",
       "3    116.128998  0.532507  64.180614  174.712336  52.119439    114.133534   \n",
       "4    115.870003  0.555730  62.177831  143.956861  49.136100    114.160067   \n",
       "..          ...       ...        ...         ...        ...           ...   \n",
       "245  132.369995 -1.924860  38.041798 -178.880110  43.783778    137.747166   \n",
       "246  132.356995 -2.040124  38.025650 -156.463915  39.466543    137.434600   \n",
       "247  132.764008 -2.076570  38.884193 -124.042215  34.652173    136.964133   \n",
       "248  133.485992 -1.998389  40.415416  -93.656085  26.430901    136.781500   \n",
       "249  134.033997 -1.870648  41.564990  -88.398318  29.149269    136.605233   \n",
       "\n",
       "     close_60_sma        vix  turbulence         SMA  \n",
       "0      113.992867  16.600000    6.664439         NaN  \n",
       "1      114.025200  16.910000    6.206088         NaN  \n",
       "2      114.069451  19.730000   13.829550         NaN  \n",
       "3      114.116567  19.610001    7.176280         NaN  \n",
       "4      114.150417  18.760000   13.874675         NaN  \n",
       "..            ...        ...         ...         ...  \n",
       "245    142.335549  21.969999    6.532908  141.935759  \n",
       "246    142.134316  20.870001    2.297701  141.648159  \n",
       "247    141.737966  21.650000    4.062184  141.357579  \n",
       "248    141.566282  22.139999    3.726654  141.054659  \n",
       "249    141.392699  21.440001    6.166426  140.755919  \n",
       "\n",
       "[250 rows x 16 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "lKRGftSS7pNM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Compare to DJIA===========\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/Finrl/lib/python3.10/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/Finrl/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/Finrl/lib/python3.10/site-packages/pandas/_libs/index.pyx:155\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index_class_helper.pxi:70\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39m# S&P 500: ^GSPC\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Dow Jones Index: ^DJI\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# NASDAQ 100: ^NDX\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m backtest_plot(df_account_value,  \n\u001b[1;32m      7\u001b[0m              baseline_start \u001b[39m=\u001b[39;49m df_account_value\u001b[39m.\u001b[39;49mloc[\u001b[39m0\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      8\u001b[0m              baseline_end \u001b[39m=\u001b[39;49m df_account_value\u001b[39m.\u001b[39;49mloc[\u001b[39mlen\u001b[39;49m(df_account_value)\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      9\u001b[0m              baseline_ticker \u001b[39m=\u001b[39;49m stock_data[\u001b[39m'\u001b[39;49m\u001b[39mSMA\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m/mnt/f/financial_projects/Deep Reinforcement Learning Approaches on Stock Prediction/FinRL/finrl/plot.py:60\u001b[0m, in \u001b[0;36mbacktest_plot\u001b[0;34m(account_value, baseline_start, baseline_end, baseline_ticker, value_col_name)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m#baseline_df = get_baseline(\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m#    ticker=baseline_ticker, start=baseline_start, end=baseline_end\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m#)\u001b[39;00m\n\u001b[1;32m     58\u001b[0m baseline_df \u001b[39m=\u001b[39m baseline_ticker\n\u001b[0;32m---> 60\u001b[0m baseline_df[\u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(baseline_df[\u001b[39m\"\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m baseline_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(df[[\u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m]], baseline_df, how\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m\"\u001b[39m, on\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m baseline_df \u001b[39m=\u001b[39m baseline_df\u001b[39m.\u001b[39mfillna(method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mffill\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mfillna(method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbfill\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/Finrl/lib/python3.10/site-packages/pandas/core/series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m   1006\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m   1009\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m   1010\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1012\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/Finrl/lib/python3.10/site-packages/pandas/core/series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1115\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1116\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1118\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/miniconda3/envs/Finrl/lib/python3.10/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value,  \n",
    "             baseline_start = df_account_value.loc[0,'date'],\n",
    "             baseline_end = df_account_value.loc[len(df_account_value)-1,'date'],\n",
    "             baseline_ticker = stock_data,\n",
    "             value_col_name= 'SMA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>adj close</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>macd</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.726818</td>\n",
       "      <td>0.726818</td>\n",
       "      <td>0.727908</td>\n",
       "      <td>0.718590</td>\n",
       "      <td>0.726850</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>51.288051</td>\n",
       "      <td>104.966545</td>\n",
       "      <td>3.520604</td>\n",
       "      <td>0.716629</td>\n",
       "      <td>0.728673</td>\n",
       "      <td>16.600000</td>\n",
       "      <td>6.664439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.719800</td>\n",
       "      <td>0.719800</td>\n",
       "      <td>0.724900</td>\n",
       "      <td>0.718530</td>\n",
       "      <td>0.719690</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>47.194235</td>\n",
       "      <td>61.427910</td>\n",
       "      <td>3.674852</td>\n",
       "      <td>0.716529</td>\n",
       "      <td>0.728422</td>\n",
       "      <td>16.910000</td>\n",
       "      <td>6.206088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.723880</td>\n",
       "      <td>0.723880</td>\n",
       "      <td>0.727180</td>\n",
       "      <td>0.722340</td>\n",
       "      <td>0.724108</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>49.613136</td>\n",
       "      <td>103.112212</td>\n",
       "      <td>2.658069</td>\n",
       "      <td>0.716584</td>\n",
       "      <td>0.728262</td>\n",
       "      <td>19.730000</td>\n",
       "      <td>13.829550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.722080</td>\n",
       "      <td>0.722080</td>\n",
       "      <td>0.722300</td>\n",
       "      <td>0.714660</td>\n",
       "      <td>0.722300</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>48.597134</td>\n",
       "      <td>40.234807</td>\n",
       "      <td>15.847883</td>\n",
       "      <td>0.716647</td>\n",
       "      <td>0.727986</td>\n",
       "      <td>19.610001</td>\n",
       "      <td>7.176280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.716260</td>\n",
       "      <td>0.716260</td>\n",
       "      <td>0.718592</td>\n",
       "      <td>0.713109</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>45.482040</td>\n",
       "      <td>-8.628733</td>\n",
       "      <td>18.999867</td>\n",
       "      <td>0.716610</td>\n",
       "      <td>0.727568</td>\n",
       "      <td>18.760000</td>\n",
       "      <td>13.874675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2022-12-22</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.671682</td>\n",
       "      <td>0.671682</td>\n",
       "      <td>0.676800</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>0.671682</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>51.917093</td>\n",
       "      <td>-12.603217</td>\n",
       "      <td>0.841755</td>\n",
       "      <td>0.672561</td>\n",
       "      <td>0.655427</td>\n",
       "      <td>21.969999</td>\n",
       "      <td>6.532908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.667800</td>\n",
       "      <td>0.667800</td>\n",
       "      <td>0.671321</td>\n",
       "      <td>0.666138</td>\n",
       "      <td>0.667800</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>50.526158</td>\n",
       "      <td>-67.043650</td>\n",
       "      <td>0.600092</td>\n",
       "      <td>0.672798</td>\n",
       "      <td>0.655702</td>\n",
       "      <td>20.870001</td>\n",
       "      <td>2.297701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.674459</td>\n",
       "      <td>0.674459</td>\n",
       "      <td>0.678000</td>\n",
       "      <td>0.672580</td>\n",
       "      <td>0.674459</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>52.807147</td>\n",
       "      <td>29.541345</td>\n",
       "      <td>10.095464</td>\n",
       "      <td>0.673020</td>\n",
       "      <td>0.656593</td>\n",
       "      <td>21.650000</td>\n",
       "      <td>4.062184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.672993</td>\n",
       "      <td>0.672993</td>\n",
       "      <td>0.680100</td>\n",
       "      <td>0.672011</td>\n",
       "      <td>0.672993</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>52.248812</td>\n",
       "      <td>30.985523</td>\n",
       "      <td>13.389150</td>\n",
       "      <td>0.672888</td>\n",
       "      <td>0.656952</td>\n",
       "      <td>22.139999</td>\n",
       "      <td>3.726654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.674710</td>\n",
       "      <td>0.674710</td>\n",
       "      <td>0.677900</td>\n",
       "      <td>0.671130</td>\n",
       "      <td>0.674710</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>52.852837</td>\n",
       "      <td>22.174281</td>\n",
       "      <td>11.555769</td>\n",
       "      <td>0.672913</td>\n",
       "      <td>0.657343</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>6.166426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date       tic  adj close     close      high       low      open  \\\n",
       "0    2022-01-03  AUDUSD=X   0.726818  0.726818  0.727908  0.718590  0.726850   \n",
       "1    2022-01-04  AUDUSD=X   0.719800  0.719800  0.724900  0.718530  0.719690   \n",
       "2    2022-01-05  AUDUSD=X   0.723880  0.723880  0.727180  0.722340  0.724108   \n",
       "3    2022-01-06  AUDUSD=X   0.722080  0.722080  0.722300  0.714660  0.722300   \n",
       "4    2022-01-07  AUDUSD=X   0.716260  0.716260  0.718592  0.713109  0.716399   \n",
       "..          ...       ...        ...       ...       ...       ...       ...   \n",
       "245  2022-12-22  AUDUSD=X   0.671682  0.671682  0.676800  0.667000  0.671682   \n",
       "246  2022-12-23  AUDUSD=X   0.667800  0.667800  0.671321  0.666138  0.667800   \n",
       "247  2022-12-27  AUDUSD=X   0.674459  0.674459  0.678000  0.672580  0.674459   \n",
       "248  2022-12-28  AUDUSD=X   0.672993  0.672993  0.680100  0.672011  0.672993   \n",
       "249  2022-12-29  AUDUSD=X   0.674710  0.674710  0.677900  0.671130  0.674710   \n",
       "\n",
       "         macd     rsi_30      cci_30      dx_30  close_30_sma  close_60_sma  \\\n",
       "0    0.001099  51.288051  104.966545   3.520604      0.716629      0.728673   \n",
       "1    0.000856  47.194235   61.427910   3.674852      0.716529      0.728422   \n",
       "2    0.000981  49.613136  103.112212   2.658069      0.716584      0.728262   \n",
       "3    0.000925  48.597134   40.234807  15.847883      0.716647      0.727986   \n",
       "4    0.000406  45.482040   -8.628733  18.999867      0.716610      0.727568   \n",
       "..        ...        ...         ...        ...           ...           ...   \n",
       "245  0.002759  51.917093  -12.603217   0.841755      0.672561      0.655427   \n",
       "246  0.002126  50.526158  -67.043650   0.600092      0.672798      0.655702   \n",
       "247  0.001923  52.807147   29.541345  10.095464      0.673020      0.656593   \n",
       "248  0.001817  52.248812   30.985523  13.389150      0.672888      0.656952   \n",
       "249  0.001851  52.852837   22.174281  11.555769      0.672913      0.657343   \n",
       "\n",
       "           vix  turbulence  \n",
       "0    16.600000    6.664439  \n",
       "1    16.910000    6.206088  \n",
       "2    19.730000   13.829550  \n",
       "3    19.610001    7.176280  \n",
       "4    18.760000   13.874675  \n",
       "..         ...         ...  \n",
       "245  21.969999    6.532908  \n",
       "246  20.870001    2.297701  \n",
       "247  21.650000    4.062184  \n",
       "248  22.139999    3.726654  \n",
       "249  21.440001    6.166426  \n",
       "\n",
       "[250 rows x 15 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade[trade['tic'] == stocks[0]] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part7 : manual backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'transactions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/Finrl/lib/python3.10/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/Finrl/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/Finrl/lib/python3.10/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'transactions'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trx_plot(trade, df_actions, \u001b[39mlist\u001b[39;49m(processed_full[\u001b[39m'\u001b[39;49m\u001b[39mtic\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49munique()) )\n",
      "File \u001b[0;32m/mnt/f/financial_projects/Deep Reinforcement Learning Approaches on Stock Prediction/FinRL/finrl/plot.py:78\u001b[0m, in \u001b[0;36mtrx_plot\u001b[0;34m(df_trade, df_actions, ticker_list)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrx_plot\u001b[39m(df_trade, df_actions, ticker_list):\n\u001b[0;32m---> 78\u001b[0m     df_trx \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(np\u001b[39m.\u001b[39marray(df_actions[\u001b[39m\"\u001b[39;49m\u001b[39mtransactions\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mto_list()))\n\u001b[1;32m     79\u001b[0m     df_trx\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m ticker_list\n\u001b[1;32m     80\u001b[0m     df_trx\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m df_actions[\u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/Finrl/lib/python3.10/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/Finrl/lib/python3.10/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'transactions'"
     ]
    }
   ],
   "source": [
    "trx_plot(trade, df_actions, list(processed_full['tic'].unique()) )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'recurrent_ppo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SaveResultsByTensorboard.tflogtodf import tflog2pandas\n",
    "path=\"/mnt/f/financial_projects/Deep Reinforcement Learning Approaches on Stock Prediction/FinRL/Crypto_market/TENSORBOARD_LOG_DIR/ppo_1/events.out.tfevents.1660815830.mohammad-pc.257.0\"\n",
    "df=tflog2pandas(path)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding training_metric to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/f/financial_projects/Deep Reinforcement Learning Approaches on Stock Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb Cell 129\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bu18/mnt/f/financial_projects/Deep%20Reinforcement%20Learning%20Approaches%20on%20Stock%20Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb#Y243sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m         writer\u001b[39m.\u001b[39madd_scalars(\u001b[39m'\u001b[39m\u001b[39mtrain_info\u001b[39m\u001b[39m'\u001b[39m, {info[\u001b[39m'\u001b[39m\u001b[39mmetric\u001b[39m\u001b[39m'\u001b[39m] : info[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m] } , info[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bu18/mnt/f/financial_projects/Deep%20Reinforcement%20Learning%20Approaches%20on%20Stock%20Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb#Y243sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m writer \u001b[39m=\u001b[39m SummaryWriter(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(TENSORBOARD_LOG_DIR, model_name))\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bu18/mnt/f/financial_projects/Deep%20Reinforcement%20Learning%20Approaches%20on%20Stock%20Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb#Y243sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m metric \u001b[39min\u001b[39;00m df[\u001b[39m'\u001b[39m\u001b[39mmetric\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique() :\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bu18/mnt/f/financial_projects/Deep%20Reinforcement%20Learning%20Approaches%20on%20Stock%20Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb#Y243sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     train_info \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39mmetric\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m metric]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bu18/mnt/f/financial_projects/Deep%20Reinforcement%20Learning%20Approaches%20on%20Stock%20Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb#Y243sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     add_scalar(writer, train_info)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "def add_scalar(writer, informations):\n",
    "    for i in range(len(informations)) :\n",
    "        info = informations.loc[i]\n",
    "        writer.add_scalars('train_info', {info['metric'] : info['value'] } , info['step'])\n",
    "\n",
    "writer = SummaryWriter(os.path.join(TENSORBOARD_LOG_DIR, model_name))\n",
    "for metric in df['metric'].unique() :\n",
    "    train_info = df[df['metric']== metric]\n",
    "    add_scalar(writer, train_info)\n",
    "writer.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding test time info to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(os.path.join(TENSORBOARD_LOG_DIR, model_name))\n",
    "for i in range(len(df_account_value)) :\n",
    "    date, account_value = df_account_value.loc[i] \n",
    "    writer.add_scalars(main_tag='test', tag_scalar_dict = {'account_value': account_value}, global_step = i) \n",
    "writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding portfolio visualization to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_portfolio(total, tickers):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16,8))\n",
    "    ax.set_facecolor('black')\n",
    "    ax.figure.set_facecolor('#121212')\n",
    "    ax.tick_params(axis='x', colors='white')\n",
    "    ax.tick_params(axis='y', colors='white')\n",
    "    ax.set_title(\"NEURALNINE PORTFOLIO VISUALIZER\", color='#EF6C35', fontsize=20)\n",
    "\n",
    "    patches, texts, autotexts = ax.pie([abs(total_element) for total_element in total], labels=tickers, autopct='%1.1f%%', pctdistance=0.8)\n",
    "    [text.set_color('white') for text in texts]\n",
    "    my_circle = plt.Circle((0, 0), 0.55, color='black')\n",
    "    plt.gca().add_artist(my_circle)\n",
    "\n",
    "    ax.text(-2,1, 'PORTFOLIO OVERVIEW:', fontsize=14, color=\"#ffe536\", horizontalalignment='center', verticalalignment='center')\n",
    "    ax.text(-2,0.85, f'Total USD Amount: {sum(total):.2f} $', fontsize=12, color=\"white\", horizontalalignment='center', verticalalignment='center')\n",
    "    counter = 0.15\n",
    "    for ticker in tickers:\n",
    "        ax.text(-2, 0.85 - counter, f'{ticker}: {total[tickers.index(ticker)]:.2f} $', fontsize=12, color=\"white\",\n",
    "        horizontalalignment='center', verticalalignment='center')\n",
    "        counter += 0.15\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_image_to_tensorboard(specific_tag ,specific_figure):\n",
    "    writer = SummaryWriter(os.path.join(TENSORBOARD_LOG_DIR, model_name, 'image'))\n",
    "    writer.add_figure(tag= specific_tag, figure = specific_figure)\n",
    "    print('done')\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BINANCE:ADABNB      0\n",
       "BINANCE:ADABTC      0\n",
       "BINANCE:ADAETH      0\n",
       "BINANCE:ADAUSDC     0\n",
       "BINANCE:ADAUSDT     0\n",
       "BINANCE:BNBBTC      0\n",
       "BINANCE:BNBBUSD     0\n",
       "BINANCE:BNBETH      0\n",
       "BINANCE:BNBUSDC     0\n",
       "BINANCE:BNBUSDT     0\n",
       "BINANCE:BTCBUSD     0\n",
       "BINANCE:BTCUSDC     0\n",
       "BINANCE:BTCUSDT     0\n",
       "BINANCE:BUSDUSDT    0\n",
       "BINANCE:ETHBTC      0\n",
       "BINANCE:ETHBUSD     0\n",
       "BINANCE:ETHUSDC     0\n",
       "BINANCE:ETHUSDT     0\n",
       "BINANCE:USDCUSDT    0\n",
       "BINANCE:XRPBNB      0\n",
       "BINANCE:XRPBTC      0\n",
       "BINANCE:XRPBUSD     0\n",
       "BINANCE:XRPETH      0\n",
       "BINANCE:XRPUSDC     0\n",
       "BINANCE:XRPUSDT     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_process(total_val) :\n",
    "    if total_val == 0 :\n",
    "        return 0 , 'white'\n",
    "    elif total_val > 0:\n",
    "        return 1 , 'green'\n",
    "    elif total_val < 0 :\n",
    "        return -1 , 'red'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1519/3637531764.py:16: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  flag, color = visualize_process(int(amounts * prices))\n",
      "/tmp/ipykernel_1519/3637531764.py:18: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  buy_total.append(int(amounts * prices))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'add_image_to_tensorboard' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(buy_total) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m :\n\u001b[1;32m     25\u001b[0m     buy_fig \u001b[39m=\u001b[39m visualize_portfolio(total\u001b[39m=\u001b[39mbuy_total, tickers\u001b[39m=\u001b[39m buy_position_tickers)\n\u001b[0;32m---> 26\u001b[0m     add_image_to_tensorboard(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbuy_portfolio:\u001b[39m\u001b[39m{\u001b[39;00mstep\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, buy_fig)\n\u001b[1;32m     28\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(sell_total) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m :\n\u001b[1;32m     29\u001b[0m     sell_fig \u001b[39m=\u001b[39m visualize_portfolio(total\u001b[39m=\u001b[39msell_total, tickers\u001b[39m=\u001b[39m sell_position_tickers)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'add_image_to_tensorboard' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "tickers = list(trade['tic'].unique())\n",
    "dates = df_actions.index\n",
    "step = 0\n",
    "for date in dates :\n",
    "    sell_total = []\n",
    "    sell_position_tickers = []\n",
    "    buy_total = []\n",
    "    buy_position_tickers = []\n",
    "    step += 1\n",
    "    for tic in tickers :\n",
    "        amounts = df_actions.loc[date, tic]\n",
    "        choosen_trade = trade[trade['date'] == date] \n",
    "        choosen_trade = choosen_trade[choosen_trade['tic'] == tic]\n",
    "        prices = choosen_trade['close']\n",
    "        flag, color = visualize_process(int(amounts * prices))\n",
    "        if flag == 1:\n",
    "            buy_total.append(int(amounts * prices))\n",
    "            buy_position_tickers.append(tic)\n",
    "        elif flag == -1:\n",
    "            sell_total.append(int(amounts * prices))\n",
    "            sell_position_tickers.append(tic)\n",
    "\n",
    "    if len(buy_total) != 0 :\n",
    "        buy_fig = visualize_portfolio(total=buy_total, tickers= buy_position_tickers)\n",
    "        add_image_to_tensorboard(f\"buy_portfolio:{step}\", buy_fig)\n",
    "\n",
    "    if len(sell_total) != 0 :\n",
    "        sell_fig = visualize_portfolio(total=sell_total, tickers= sell_position_tickers)\n",
    "        add_image_to_tensorboard(f\"sell_portfolio:{step}\", sell_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'metanet_pb2' from partially initialized module 'caffe2.proto' (most likely due to a circular import) (/home/mohammad/anaconda3/envs/FinRl/lib/python3.8/site-packages/caffe2/proto/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/mnt/f/financial_projects/Deep Reinforcement Learning Approaches on Stock Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb Cell 134\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bu18/mnt/f/financial_projects/Deep%20Reinforcement%20Learning%20Approaches%20on%20Stock%20Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb#Y263sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m writer \u001b[39m=\u001b[39m SummaryWriter(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(TENSORBOARD_LOG_DIR, \u001b[39m'\u001b[39m\u001b[39mppo\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGraph\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bu18/mnt/f/financial_projects/Deep%20Reinforcement%20Learning%20Approaches%20on%20Stock%20Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb#Y263sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m writer\u001b[39m.\u001b[39;49madd_graph(trained_ppo, e_trade_gym)\n",
      "File \u001b[0;32m~/anaconda3/envs/FinRl/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py:739\u001b[0m, in \u001b[0;36mSummaryWriter.add_graph\u001b[0;34m(self, model, input_to_model, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_file_writer()\u001b[39m.\u001b[39madd_graph(graph(model, input_to_model, verbose, use_strict_trace))\n\u001b[1;32m    737\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    738\u001b[0m     \u001b[39m# Caffe2 models do not have the 'forward' method\u001b[39;00m\n\u001b[0;32m--> 739\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mcaffe2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproto\u001b[39;00m \u001b[39mimport\u001b[39;00m caffe2_pb2\n\u001b[1;32m    740\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mcaffe2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m core\n\u001b[1;32m    741\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_caffe2_graph\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    742\u001b[0m         model_to_graph_def, nets_to_graph_def, protos_to_graph_def\n\u001b[1;32m    743\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/FinRl/lib/python3.8/site-packages/caffe2/proto/__init__.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# NOTE: we have to import python protobuf here **before** we load cpp extension.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Otherwise it breaks under certain build conditions if cpp implementation of\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# protobuf is used. Presumably there's some registry in protobuf library and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# This has to be done for all python targets, so listing them here\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcaffe2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproto\u001b[39;00m \u001b[39mimport\u001b[39;00m caffe2_pb2, metanet_pb2, torch_pb2\n\u001b[1;32m     12\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mcaffe2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcaffe2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msession\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproto\u001b[39;00m \u001b[39mimport\u001b[39;00m session_pb2\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'metanet_pb2' from partially initialized module 'caffe2.proto' (most likely due to a circular import) (/home/mohammad/anaconda3/envs/FinRl/lib/python3.8/site-packages/caffe2/proto/__init__.py)"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(os.path.join(TENSORBOARD_LOG_DIR, 'ppo', 'Graph'))\n",
    "writer.add_graph(trained_ppo, e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.9.1 at http://localhost:6007/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir==runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
       " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1.], (28,), float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_full['tic'].unique())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Uy5_PTmOh1hj",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "include_colab_link": true,
   "name": "FinRL_StockTrading_NeurIPS_2018.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a913f0b5b2020ea25813dce4293e7824585e87f8cd8de80d0bb160f8ff78697"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
