{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL/blob/master/FinRL_StockTrading_NeurIPS_2018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading\n",
    "\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "\n",
    "%matplotlib inline\n",
    "from preprocess.default_preprocessors import data_split \n",
    "from finrl.metaFinrl.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1.Build Environment](#0)  \n",
    "    * [1.1. Training & Trade Data Split](#0.1)\n",
    "    * [1.2. User-defined Environment](#0.2)   \n",
    "    * [1.3. Initialize Environment](#0.3)    \n",
    "* [2.Implement DRL Algorithms](#1) \n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_path = 'full_preprocessed_data.csv'\n",
    "processed_full = pd.read_csv(os.path.join(config.DATA_SAVE_DIR, data_path), index_col=[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "5TOhcryx44bb"
   },
   "source": [
    "## Training data and Trading data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0qaVGjLtgbI",
    "outputId": "ca8d1a43-ffc3-4fc3-efa9-4de9a9065842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4536\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "# from config.py TRAIN_START_DATE is a string\n",
    "#config.TRAIN_START_DATE\n",
    "train_start_date = datetime.datetime(2019,1,1).strftime('%Y-%m-%d')\n",
    "# from config.py TRAIN_END_DATE is a string\n",
    "train_end_date = datetime.datetime(2022,1,1).strftime('%Y-%m-%d')\n",
    "trade_end_date = datetime.datetime(2023,1,1).strftime('%Y-%m-%d')\n",
    "train = data_split(processed_full, train_start_date ,train_end_date)\n",
    "trade = data_split(processed_full, train_end_date ,trade_end_date)\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "p52zNCOhTtLR",
    "outputId": "b3ad3e10-376f-4186-f875-0331708c5e14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>adj close</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>macd</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>EURUSD=X</td>\n",
       "      <td>1.132503</td>\n",
       "      <td>1.132503</td>\n",
       "      <td>1.137915</td>\n",
       "      <td>1.130506</td>\n",
       "      <td>1.132323</td>\n",
       "      <td>-0.000965</td>\n",
       "      <td>44.911151</td>\n",
       "      <td>109.118753</td>\n",
       "      <td>16.257448</td>\n",
       "      <td>1.129425</td>\n",
       "      <td>1.142246</td>\n",
       "      <td>17.219999</td>\n",
       "      <td>3.822869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>GBPUSD=X</td>\n",
       "      <td>1.349837</td>\n",
       "      <td>1.349837</td>\n",
       "      <td>1.354848</td>\n",
       "      <td>1.346747</td>\n",
       "      <td>1.349892</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>52.327576</td>\n",
       "      <td>171.604444</td>\n",
       "      <td>30.393030</td>\n",
       "      <td>1.332000</td>\n",
       "      <td>1.347087</td>\n",
       "      <td>17.219999</td>\n",
       "      <td>3.822869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>USDCAD=X</td>\n",
       "      <td>1.274440</td>\n",
       "      <td>1.274440</td>\n",
       "      <td>1.275000</td>\n",
       "      <td>1.262680</td>\n",
       "      <td>1.274300</td>\n",
       "      <td>0.003544</td>\n",
       "      <td>52.687505</td>\n",
       "      <td>-70.077708</td>\n",
       "      <td>14.859173</td>\n",
       "      <td>1.277305</td>\n",
       "      <td>1.260555</td>\n",
       "      <td>17.219999</td>\n",
       "      <td>3.822869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>USDCHF=X</td>\n",
       "      <td>0.913700</td>\n",
       "      <td>0.913700</td>\n",
       "      <td>0.914740</td>\n",
       "      <td>0.910470</td>\n",
       "      <td>0.913900</td>\n",
       "      <td>-0.002014</td>\n",
       "      <td>44.964408</td>\n",
       "      <td>-170.194575</td>\n",
       "      <td>37.535785</td>\n",
       "      <td>0.922676</td>\n",
       "      <td>0.921276</td>\n",
       "      <td>17.219999</td>\n",
       "      <td>3.822869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>USDJPY=X</td>\n",
       "      <td>115.063004</td>\n",
       "      <td>115.063004</td>\n",
       "      <td>115.192001</td>\n",
       "      <td>115.004997</td>\n",
       "      <td>115.058998</td>\n",
       "      <td>0.301309</td>\n",
       "      <td>59.394022</td>\n",
       "      <td>120.417399</td>\n",
       "      <td>32.024355</td>\n",
       "      <td>114.023701</td>\n",
       "      <td>113.945000</td>\n",
       "      <td>17.219999</td>\n",
       "      <td>3.822869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date       tic   adj close       close        high         low  \\\n",
       "755  2021-12-31  EURUSD=X    1.132503    1.132503    1.137915    1.130506   \n",
       "755  2021-12-31  GBPUSD=X    1.349837    1.349837    1.354848    1.346747   \n",
       "755  2021-12-31  USDCAD=X    1.274440    1.274440    1.275000    1.262680   \n",
       "755  2021-12-31  USDCHF=X    0.913700    0.913700    0.914740    0.910470   \n",
       "755  2021-12-31  USDJPY=X  115.063004  115.063004  115.192001  115.004997   \n",
       "\n",
       "           open      macd     rsi_30      cci_30      dx_30  close_30_sma  \\\n",
       "755    1.132323 -0.000965  44.911151  109.118753  16.257448      1.129425   \n",
       "755    1.349892  0.002156  52.327576  171.604444  30.393030      1.332000   \n",
       "755    1.274300  0.003544  52.687505  -70.077708  14.859173      1.277305   \n",
       "755    0.913900 -0.002014  44.964408 -170.194575  37.535785      0.922676   \n",
       "755  115.058998  0.301309  59.394022  120.417399  32.024355    114.023701   \n",
       "\n",
       "     close_60_sma        vix  turbulence  \n",
       "755      1.142246  17.219999    3.822869  \n",
       "755      1.347087  17.219999    3.822869  \n",
       "755      1.260555  17.219999    3.822869  \n",
       "755      0.921276  17.219999    3.822869  \n",
       "755    113.945000  17.219999    3.822869  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "k9zU9YaTTvFq",
    "outputId": "72213585-39a3-4bff-c031-874ec0ca06f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>adj close</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>macd</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>EURUSD=X</td>\n",
       "      <td>1.062925</td>\n",
       "      <td>1.062925</td>\n",
       "      <td>1.067019</td>\n",
       "      <td>1.061233</td>\n",
       "      <td>1.062925</td>\n",
       "      <td>0.008925</td>\n",
       "      <td>60.167083</td>\n",
       "      <td>78.327051</td>\n",
       "      <td>49.139568</td>\n",
       "      <td>1.050900</td>\n",
       "      <td>1.022255</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>6.166426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>GBPUSD=X</td>\n",
       "      <td>1.202848</td>\n",
       "      <td>1.202848</td>\n",
       "      <td>1.207584</td>\n",
       "      <td>1.201548</td>\n",
       "      <td>1.203297</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>52.732919</td>\n",
       "      <td>-46.930901</td>\n",
       "      <td>3.480165</td>\n",
       "      <td>1.211069</td>\n",
       "      <td>1.176042</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>6.166426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>USDCAD=X</td>\n",
       "      <td>1.359940</td>\n",
       "      <td>1.359940</td>\n",
       "      <td>1.360760</td>\n",
       "      <td>1.354450</td>\n",
       "      <td>1.359940</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>52.738428</td>\n",
       "      <td>36.079932</td>\n",
       "      <td>8.181686</td>\n",
       "      <td>1.353157</td>\n",
       "      <td>1.357071</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>6.166426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>USDCHF=X</td>\n",
       "      <td>0.927710</td>\n",
       "      <td>0.927710</td>\n",
       "      <td>0.928720</td>\n",
       "      <td>0.921190</td>\n",
       "      <td>0.927710</td>\n",
       "      <td>-0.006936</td>\n",
       "      <td>40.654053</td>\n",
       "      <td>-97.756970</td>\n",
       "      <td>35.855458</td>\n",
       "      <td>0.938252</td>\n",
       "      <td>0.963402</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>6.166426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>USDJPY=X</td>\n",
       "      <td>134.033997</td>\n",
       "      <td>134.033997</td>\n",
       "      <td>134.188004</td>\n",
       "      <td>132.936005</td>\n",
       "      <td>134.033997</td>\n",
       "      <td>-1.870648</td>\n",
       "      <td>41.564990</td>\n",
       "      <td>-88.398318</td>\n",
       "      <td>29.149269</td>\n",
       "      <td>136.605233</td>\n",
       "      <td>141.392699</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>6.166426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date       tic   adj close       close        high         low  \\\n",
       "249  2022-12-29  EURUSD=X    1.062925    1.062925    1.067019    1.061233   \n",
       "249  2022-12-29  GBPUSD=X    1.202848    1.202848    1.207584    1.201548   \n",
       "249  2022-12-29  USDCAD=X    1.359940    1.359940    1.360760    1.354450   \n",
       "249  2022-12-29  USDCHF=X    0.927710    0.927710    0.928720    0.921190   \n",
       "249  2022-12-29  USDJPY=X  134.033997  134.033997  134.188004  132.936005   \n",
       "\n",
       "           open      macd     rsi_30     cci_30      dx_30  close_30_sma  \\\n",
       "249    1.062925  0.008925  60.167083  78.327051  49.139568      1.050900   \n",
       "249    1.203297  0.003764  52.732919 -46.930901   3.480165      1.211069   \n",
       "249    1.359940  0.002138  52.738428  36.079932   8.181686      1.353157   \n",
       "249    0.927710 -0.006936  40.654053 -97.756970  35.855458      0.938252   \n",
       "249  134.033997 -1.870648  41.564990 -88.398318  29.149269    136.605233   \n",
       "\n",
       "     close_60_sma        vix  turbulence  \n",
       "249      1.022255  21.440001    6.166426  \n",
       "249      1.176042  21.440001    6.166426  \n",
       "249      1.357071  21.440001    6.166426  \n",
       "249      0.963402  21.440001    6.166426  \n",
       "249    141.392699  21.440001    6.166426  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "7f228183-abe3-4477-f574-3c9b25c62cd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "1f54d044-e2d3-4a34-c041-e913d686654e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 6, State Space: 49\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + len(config.INDICATORS)*stock_dimension + 2*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "64EoqOrQjiVf"
   },
   "source": [
    "## Environment for Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwSvvPjutpqS",
    "outputId": "deeaef07-afda-4ca1-fea8-99384224c7cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "YDmqOyF9h1iz"
   },
   "source": [
    "### Model Training: 5 models, A2C DDPG, PPO, TD3, SAC\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "uijiWgkuh1jB"
   },
   "source": [
    "### Model 1: A2C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUCnkn-HIbmj",
    "outputId": "a90a7a60-21a5-47e1-b683-1f7cbb4b8bc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "model_a2c.pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0GVpkWGqH4-D",
    "outputId": "570d540f-abe9-402b-e0cc-f9b007228e8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 58          |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 8           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -96.5       |\n",
      "|    explained_variance | -52.8       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -16.7       |\n",
      "|    reward             | 0.044553936 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.0917      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 69           |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -97.4        |\n",
      "|    explained_variance | -9.89        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | 3.2          |\n",
      "|    reward             | -0.015797459 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 0.00661      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 21         |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -98        |\n",
      "|    explained_variance | -4.21      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | 5.7        |\n",
      "|    reward             | 0.01450776 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.0173     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 73          |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -98.7       |\n",
      "|    explained_variance | -51.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -1.55       |\n",
      "|    reward             | -0.10984398 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.0376      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 75          |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 33          |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -99.3       |\n",
      "|    explained_variance | -3.75       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | 21.5        |\n",
      "|    reward             | -0.02329195 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.0704      |\n",
      "---------------------------------------\n",
      "day: 325, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 997125.73\n",
      "total_reward: -2874.27\n",
      "total_cost: 14981.98\n",
      "total_trades: 17064\n",
      "Sharpe: -0.149\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 77         |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 38         |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -100       |\n",
      "|    explained_variance | -0.895     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | 6.88       |\n",
      "|    reward             | 0.09444232 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.00818    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 78          |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 44          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -101        |\n",
      "|    explained_variance | -0.00131    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | -28         |\n",
      "|    reward             | -0.12089544 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.0764      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -102        |\n",
      "|    explained_variance | 0.0122      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 19.3        |\n",
      "|    reward             | 0.057961393 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 0.0612      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 56          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -103        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -0.609      |\n",
      "|    reward             | -0.05697777 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 0.000473    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 79            |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 63            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -104          |\n",
      "|    explained_variance | -1.09         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | 15.4          |\n",
      "|    reward             | -0.0060025565 |\n",
      "|    std                | 1.14          |\n",
      "|    value_loss         | 0.0281        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 78          |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 69          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -105        |\n",
      "|    explained_variance | -0.569      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | 0.417       |\n",
      "|    reward             | 0.048435513 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 0.000814    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 78         |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 76         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -106       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | 7.17       |\n",
      "|    reward             | 0.08244916 |\n",
      "|    std                | 1.17       |\n",
      "|    value_loss         | 0.0208     |\n",
      "--------------------------------------\n",
      "day: 325, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1001062.14\n",
      "total_reward: 1062.14\n",
      "total_cost: 9043.68\n",
      "total_trades: 14910\n",
      "Sharpe: 0.070\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 78          |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -106        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | 1.75        |\n",
      "|    reward             | 0.058699276 |\n",
      "|    std                | 1.19        |\n",
      "|    value_loss         | 0.00114     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 78          |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -107        |\n",
      "|    explained_variance | 0.000685    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 17.6        |\n",
      "|    reward             | 0.003506949 |\n",
      "|    std                | 1.2         |\n",
      "|    value_loss         | 0.0311      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 78           |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 94           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -108         |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.223       |\n",
      "|    reward             | 0.0011988588 |\n",
      "|    std                | 1.22         |\n",
      "|    value_loss         | 0.000432     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 78         |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 101        |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -109       |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | -30        |\n",
      "|    reward             | 0.08882735 |\n",
      "|    std                | 1.24       |\n",
      "|    value_loss         | 0.0849     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 79         |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 107        |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -110       |\n",
      "|    explained_variance | -1.75      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | 15.2       |\n",
      "|    reward             | 0.07436467 |\n",
      "|    std                | 1.25       |\n",
      "|    value_loss         | 0.0257     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 78           |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 114          |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -111         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.00714      |\n",
      "|    reward             | -0.039154794 |\n",
      "|    std                | 1.27         |\n",
      "|    value_loss         | 0.00137      |\n",
      "----------------------------------------\n",
      "day: 325, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000650.74\n",
      "total_reward: 650.74\n",
      "total_cost: 8004.09\n",
      "total_trades: 14055\n",
      "Sharpe: 0.040\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 78          |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 121         |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -112        |\n",
      "|    explained_variance | 0.0193      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | 11.5        |\n",
      "|    reward             | 0.085746616 |\n",
      "|    std                | 1.28        |\n",
      "|    value_loss         | 0.0119      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 78           |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -112         |\n",
      "|    explained_variance | 0.57         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | 14.2         |\n",
      "|    reward             | -0.021977013 |\n",
      "|    std                | 1.3          |\n",
      "|    value_loss         | 0.0187       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 77           |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 134          |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -113         |\n",
      "|    explained_variance | -0.886       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2099         |\n",
      "|    policy_loss        | 4.88         |\n",
      "|    reward             | -0.028431328 |\n",
      "|    std                | 1.31         |\n",
      "|    value_loss         | 0.0138       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 78           |\n",
      "|    iterations         | 2200         |\n",
      "|    time_elapsed       | 140          |\n",
      "|    total_timesteps    | 11000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -114         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2199         |\n",
      "|    policy_loss        | -1.55        |\n",
      "|    reward             | -0.066542126 |\n",
      "|    std                | 1.32         |\n",
      "|    value_loss         | 0.00226      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 78          |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -114        |\n",
      "|    explained_variance | 0.21        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2299        |\n",
      "|    policy_loss        | 12.4        |\n",
      "|    reward             | -0.09345006 |\n",
      "|    std                | 1.34        |\n",
      "|    value_loss         | 0.018       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 78            |\n",
      "|    iterations         | 2400          |\n",
      "|    time_elapsed       | 151           |\n",
      "|    total_timesteps    | 12000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -115          |\n",
      "|    explained_variance | -0.493        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2399          |\n",
      "|    policy_loss        | -2.24         |\n",
      "|    reward             | -0.0030777536 |\n",
      "|    std                | 1.35          |\n",
      "|    value_loss         | 0.00227       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 2500        |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 12500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -116        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2499        |\n",
      "|    policy_loss        | 8.36        |\n",
      "|    reward             | 0.026250772 |\n",
      "|    std                | 1.37        |\n",
      "|    value_loss         | 0.00864     |\n",
      "---------------------------------------\n",
      "day: 325, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1005846.42\n",
      "total_reward: 5846.42\n",
      "total_cost: 6409.88\n",
      "total_trades: 13706\n",
      "Sharpe: 0.279\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 79         |\n",
      "|    iterations         | 2600       |\n",
      "|    time_elapsed       | 164        |\n",
      "|    total_timesteps    | 13000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -117       |\n",
      "|    explained_variance | 0.255      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2599       |\n",
      "|    policy_loss        | 3.96       |\n",
      "|    reward             | 0.09710817 |\n",
      "|    std                | 1.38       |\n",
      "|    value_loss         | 0.00135    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 79           |\n",
      "|    iterations         | 2700         |\n",
      "|    time_elapsed       | 170          |\n",
      "|    total_timesteps    | 13500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -118         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2699         |\n",
      "|    policy_loss        | 20.1         |\n",
      "|    reward             | -0.014896936 |\n",
      "|    std                | 1.4          |\n",
      "|    value_loss         | 0.0408       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 79         |\n",
      "|    iterations         | 2800       |\n",
      "|    time_elapsed       | 175        |\n",
      "|    total_timesteps    | 14000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -118       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2799       |\n",
      "|    policy_loss        | -4.09      |\n",
      "|    reward             | 0.09568252 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 0.0014     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 2900        |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 14500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -119        |\n",
      "|    explained_variance | 0.377       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2899        |\n",
      "|    policy_loss        | -14.2       |\n",
      "|    reward             | -0.07864827 |\n",
      "|    std                | 1.43        |\n",
      "|    value_loss         | 0.0173      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 3000        |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 15000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -120        |\n",
      "|    explained_variance | -1.4        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2999        |\n",
      "|    policy_loss        | -15.5       |\n",
      "|    reward             | -0.06088617 |\n",
      "|    std                | 1.45        |\n",
      "|    value_loss         | 0.0292      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 79           |\n",
      "|    iterations         | 3100         |\n",
      "|    time_elapsed       | 194          |\n",
      "|    total_timesteps    | 15500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -121         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3099         |\n",
      "|    policy_loss        | -18.8        |\n",
      "|    reward             | -0.016993023 |\n",
      "|    std                | 1.47         |\n",
      "|    value_loss         | 0.0504       |\n",
      "----------------------------------------\n",
      "day: 325, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 996928.75\n",
      "total_reward: -3071.25\n",
      "total_cost: 8902.68\n",
      "total_trades: 13935\n",
      "Sharpe: -0.122\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 79           |\n",
      "|    iterations         | 3200         |\n",
      "|    time_elapsed       | 200          |\n",
      "|    total_timesteps    | 16000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -121         |\n",
      "|    explained_variance | 0.263        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3199         |\n",
      "|    policy_loss        | 0.4          |\n",
      "|    reward             | -0.092677295 |\n",
      "|    std                | 1.48         |\n",
      "|    value_loss         | 0.00187      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 207       |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -122      |\n",
      "|    explained_variance | 0.395     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 16.6      |\n",
      "|    reward             | 0.1896723 |\n",
      "|    std                | 1.5       |\n",
      "|    value_loss         | 0.0232    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -123        |\n",
      "|    explained_variance | 0.753       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3399        |\n",
      "|    policy_loss        | 22.1        |\n",
      "|    reward             | -0.07774133 |\n",
      "|    std                | 1.52        |\n",
      "|    value_loss         | 0.0334      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 3500        |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 17500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -124        |\n",
      "|    explained_variance | 0.0553      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3499        |\n",
      "|    policy_loss        | 42.3        |\n",
      "|    reward             | 0.055191994 |\n",
      "|    std                | 1.54        |\n",
      "|    value_loss         | 0.131       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 80          |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -125        |\n",
      "|    explained_variance | -7.65       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | -26.1       |\n",
      "|    reward             | -0.06462753 |\n",
      "|    std                | 1.56        |\n",
      "|    value_loss         | 0.0583      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 80           |\n",
      "|    iterations         | 3700         |\n",
      "|    time_elapsed       | 230          |\n",
      "|    total_timesteps    | 18500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -126         |\n",
      "|    explained_variance | 0.000239     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3699         |\n",
      "|    policy_loss        | -10.2        |\n",
      "|    reward             | -0.015423859 |\n",
      "|    std                | 1.58         |\n",
      "|    value_loss         | 0.00762      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 3800       |\n",
      "|    time_elapsed       | 237        |\n",
      "|    total_timesteps    | 19000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -127       |\n",
      "|    explained_variance | 3.58e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3799       |\n",
      "|    policy_loss        | -1.6       |\n",
      "|    reward             | 0.09261574 |\n",
      "|    std                | 1.6        |\n",
      "|    value_loss         | 0.00437    |\n",
      "--------------------------------------\n",
      "day: 325, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1009951.96\n",
      "total_reward: 9951.96\n",
      "total_cost: 6110.00\n",
      "total_trades: 13919\n",
      "Sharpe: 0.578\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 243        |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -128       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | 3.87       |\n",
      "|    reward             | 0.02725004 |\n",
      "|    std                | 1.63       |\n",
      "|    value_loss         | 0.00172    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 4000       |\n",
      "|    time_elapsed       | 249        |\n",
      "|    total_timesteps    | 20000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -128       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3999       |\n",
      "|    policy_loss        | -5.52      |\n",
      "|    reward             | 0.12782644 |\n",
      "|    std                | 1.65       |\n",
      "|    value_loss         | 0.00199    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 80          |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -129        |\n",
      "|    explained_variance | -1.57       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | -9.7        |\n",
      "|    reward             | -0.01622392 |\n",
      "|    std                | 1.67        |\n",
      "|    value_loss         | 0.0083      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 4200       |\n",
      "|    time_elapsed       | 261        |\n",
      "|    total_timesteps    | 21000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -130       |\n",
      "|    explained_variance | -0.0566    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4199       |\n",
      "|    policy_loss        | -10.4      |\n",
      "|    reward             | 0.08525824 |\n",
      "|    std                | 1.69       |\n",
      "|    value_loss         | 0.00886    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 80           |\n",
      "|    iterations         | 4300         |\n",
      "|    time_elapsed       | 267          |\n",
      "|    total_timesteps    | 21500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -131         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4299         |\n",
      "|    policy_loss        | -1.2         |\n",
      "|    reward             | -0.063264504 |\n",
      "|    std                | 1.71         |\n",
      "|    value_loss         | 0.00071      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 80          |\n",
      "|    iterations         | 4400        |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 22000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -132        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4399        |\n",
      "|    policy_loss        | 2.76        |\n",
      "|    reward             | -0.06586589 |\n",
      "|    std                | 1.73        |\n",
      "|    value_loss         | 0.00622     |\n",
      "---------------------------------------\n",
      "day: 325, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1006461.44\n",
      "total_reward: 6461.44\n",
      "total_cost: 8401.39\n",
      "total_trades: 13832\n",
      "Sharpe: 0.350\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 280        |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -133       |\n",
      "|    explained_variance | -0.894     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4499       |\n",
      "|    policy_loss        | -35        |\n",
      "|    reward             | -0.0704834 |\n",
      "|    std                | 1.75       |\n",
      "|    value_loss         | 0.0971     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 80           |\n",
      "|    iterations         | 4600         |\n",
      "|    time_elapsed       | 287          |\n",
      "|    total_timesteps    | 23000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -133         |\n",
      "|    explained_variance | -0.0995      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4599         |\n",
      "|    policy_loss        | -13.6        |\n",
      "|    reward             | -0.063179575 |\n",
      "|    std                | 1.77         |\n",
      "|    value_loss         | 0.0191       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 80            |\n",
      "|    iterations         | 4700          |\n",
      "|    time_elapsed       | 293           |\n",
      "|    total_timesteps    | 23500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -134          |\n",
      "|    explained_variance | -239          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4699          |\n",
      "|    policy_loss        | 67.1          |\n",
      "|    reward             | -0.0028111953 |\n",
      "|    std                | 1.79          |\n",
      "|    value_loss         | 0.314         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 80          |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 299         |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -135        |\n",
      "|    explained_variance | 0.253       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | 23.7        |\n",
      "|    reward             | 0.002634839 |\n",
      "|    std                | 1.82        |\n",
      "|    value_loss         | 0.0326      |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 305      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -136     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 14.8     |\n",
      "|    reward             | -0.44721 |\n",
      "|    std                | 1.84     |\n",
      "|    value_loss         | 0.0248   |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 5000       |\n",
      "|    time_elapsed       | 312        |\n",
      "|    total_timesteps    | 25000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -137       |\n",
      "|    explained_variance | 0.0648     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4999       |\n",
      "|    policy_loss        | 6.56       |\n",
      "|    reward             | 0.06591305 |\n",
      "|    std                | 1.86       |\n",
      "|    value_loss         | 0.0188     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 5100       |\n",
      "|    time_elapsed       | 318        |\n",
      "|    total_timesteps    | 25500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -138       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5099       |\n",
      "|    policy_loss        | -35.6      |\n",
      "|    reward             | 0.23811533 |\n",
      "|    std                | 1.89       |\n",
      "|    value_loss         | 0.0754     |\n",
      "--------------------------------------\n",
      "day: 325, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 998124.33\n",
      "total_reward: -1875.67\n",
      "total_cost: 7503.01\n",
      "total_trades: 14475\n",
      "Sharpe: -0.084\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 80        |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 324       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -138      |\n",
      "|    explained_variance | 0.258     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | 10.3      |\n",
      "|    reward             | 0.0854351 |\n",
      "|    std                | 1.91      |\n",
      "|    value_loss         | 0.0161    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 79           |\n",
      "|    iterations         | 5300         |\n",
      "|    time_elapsed       | 332          |\n",
      "|    total_timesteps    | 26500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -139         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5299         |\n",
      "|    policy_loss        | 3.36         |\n",
      "|    reward             | -0.034995917 |\n",
      "|    std                | 1.94         |\n",
      "|    value_loss         | 0.0012       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -140        |\n",
      "|    explained_variance | 0.0977      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | -6.47       |\n",
      "|    reward             | -0.14480287 |\n",
      "|    std                | 1.96        |\n",
      "|    value_loss         | 0.00265     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 79         |\n",
      "|    iterations         | 5500       |\n",
      "|    time_elapsed       | 345        |\n",
      "|    total_timesteps    | 27500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -141       |\n",
      "|    explained_variance | -0.542     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5499       |\n",
      "|    policy_loss        | 0.356      |\n",
      "|    reward             | -0.3527186 |\n",
      "|    std                | 1.98       |\n",
      "|    value_loss         | 0.00103    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 79         |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 352        |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -142       |\n",
      "|    explained_variance | -0.287     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5599       |\n",
      "|    policy_loss        | -17        |\n",
      "|    reward             | 0.02866846 |\n",
      "|    std                | 2          |\n",
      "|    value_loss         | 0.0183     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 358         |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -142        |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5699        |\n",
      "|    policy_loss        | -0.969      |\n",
      "|    reward             | 0.012986316 |\n",
      "|    std                | 2.03        |\n",
      "|    value_loss         | 0.00195     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 79         |\n",
      "|    iterations         | 5800       |\n",
      "|    time_elapsed       | 365        |\n",
      "|    total_timesteps    | 29000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -143       |\n",
      "|    explained_variance | 0.121      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5799       |\n",
      "|    policy_loss        | -13.3      |\n",
      "|    reward             | 0.11760746 |\n",
      "|    std                | 2.05       |\n",
      "|    value_loss         | 0.00853    |\n",
      "--------------------------------------\n",
      "day: 325, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 997293.17\n",
      "total_reward: -2706.83\n",
      "total_cost: 7881.25\n",
      "total_trades: 14579\n",
      "Sharpe: -0.120\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 79           |\n",
      "|    iterations         | 5900         |\n",
      "|    time_elapsed       | 371          |\n",
      "|    total_timesteps    | 29500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -144         |\n",
      "|    explained_variance | 0.00623      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5899         |\n",
      "|    policy_loss        | -7.15        |\n",
      "|    reward             | -0.020696951 |\n",
      "|    std                | 2.07         |\n",
      "|    value_loss         | 0.00688      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 6000        |\n",
      "|    time_elapsed       | 377         |\n",
      "|    total_timesteps    | 30000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -145        |\n",
      "|    explained_variance | 0.837       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5999        |\n",
      "|    policy_loss        | -6.48       |\n",
      "|    reward             | -0.14656143 |\n",
      "|    std                | 2.1         |\n",
      "|    value_loss         | 0.00328     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 384       |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -145      |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | 41.1      |\n",
      "|    reward             | 0.0618338 |\n",
      "|    std                | 2.13      |\n",
      "|    value_loss         | 0.0828    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 390         |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -146        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6199        |\n",
      "|    policy_loss        | 121         |\n",
      "|    reward             | 0.031480942 |\n",
      "|    std                | 2.15        |\n",
      "|    value_loss         | 0.708       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 397         |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -147        |\n",
      "|    explained_variance | 0.0472      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6299        |\n",
      "|    policy_loss        | 8.02        |\n",
      "|    reward             | -0.06042169 |\n",
      "|    std                | 2.18        |\n",
      "|    value_loss         | 0.00938     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 403       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -148      |\n",
      "|    explained_variance | 0.000239  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 9.33      |\n",
      "|    reward             | 0.1208408 |\n",
      "|    std                | 2.2       |\n",
      "|    value_loss         | 0.00894   |\n",
      "-------------------------------------\n",
      "day: 325, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999030.39\n",
      "total_reward: -969.61\n",
      "total_cost: 7880.40\n",
      "total_trades: 13898\n",
      "Sharpe: -0.042\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 6500        |\n",
      "|    time_elapsed       | 410         |\n",
      "|    total_timesteps    | 32500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -149        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6499        |\n",
      "|    policy_loss        | -21         |\n",
      "|    reward             | -0.17246264 |\n",
      "|    std                | 2.23        |\n",
      "|    value_loss         | 0.0226      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 417         |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -149        |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | -11.2       |\n",
      "|    reward             | -0.22344671 |\n",
      "|    std                | 2.25        |\n",
      "|    value_loss         | 0.0217      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 78         |\n",
      "|    iterations         | 6700       |\n",
      "|    time_elapsed       | 425        |\n",
      "|    total_timesteps    | 33500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -150       |\n",
      "|    explained_variance | -0.00827   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6699       |\n",
      "|    policy_loss        | 15.8       |\n",
      "|    reward             | 0.18044727 |\n",
      "|    std                | 2.28       |\n",
      "|    value_loss         | 0.0227     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 78          |\n",
      "|    iterations         | 6800        |\n",
      "|    time_elapsed       | 431         |\n",
      "|    total_timesteps    | 34000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -151        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6799        |\n",
      "|    policy_loss        | -8.27       |\n",
      "|    reward             | -0.11957112 |\n",
      "|    std                | 2.31        |\n",
      "|    value_loss         | 0.00449     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 78           |\n",
      "|    iterations         | 6900         |\n",
      "|    time_elapsed       | 437          |\n",
      "|    total_timesteps    | 34500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -152         |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6899         |\n",
      "|    policy_loss        | 13.6         |\n",
      "|    reward             | 0.0025138045 |\n",
      "|    std                | 2.34         |\n",
      "|    value_loss         | 0.00866      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 78          |\n",
      "|    iterations         | 7000        |\n",
      "|    time_elapsed       | 443         |\n",
      "|    total_timesteps    | 35000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -153        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6999        |\n",
      "|    policy_loss        | -5.35       |\n",
      "|    reward             | -0.10785075 |\n",
      "|    std                | 2.37        |\n",
      "|    value_loss         | 0.00199     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 7100        |\n",
      "|    time_elapsed       | 448         |\n",
      "|    total_timesteps    | 35500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -154        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7099        |\n",
      "|    policy_loss        | 7.95        |\n",
      "|    reward             | 0.018192958 |\n",
      "|    std                | 2.4         |\n",
      "|    value_loss         | 0.00419     |\n",
      "---------------------------------------\n",
      "day: 325, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 997816.32\n",
      "total_reward: -2183.68\n",
      "total_cost: 7703.39\n",
      "total_trades: 13708\n",
      "Sharpe: -0.115\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 454         |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -154        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7199        |\n",
      "|    policy_loss        | -11.6       |\n",
      "|    reward             | 0.054953314 |\n",
      "|    std                | 2.43        |\n",
      "|    value_loss         | 0.00677     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 79         |\n",
      "|    iterations         | 7300       |\n",
      "|    time_elapsed       | 460        |\n",
      "|    total_timesteps    | 36500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -155       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7299       |\n",
      "|    policy_loss        | 2.44       |\n",
      "|    reward             | 0.10644107 |\n",
      "|    std                | 2.47       |\n",
      "|    value_loss         | 0.000922   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 79           |\n",
      "|    iterations         | 7400         |\n",
      "|    time_elapsed       | 466          |\n",
      "|    total_timesteps    | 37000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -156         |\n",
      "|    explained_variance | 0.0929       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7399         |\n",
      "|    policy_loss        | -14.1        |\n",
      "|    reward             | -0.022051882 |\n",
      "|    std                | 2.5          |\n",
      "|    value_loss         | 0.00882      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 79           |\n",
      "|    iterations         | 7500         |\n",
      "|    time_elapsed       | 472          |\n",
      "|    total_timesteps    | 37500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -157         |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7499         |\n",
      "|    policy_loss        | -8.62        |\n",
      "|    reward             | -0.006015171 |\n",
      "|    std                | 2.54         |\n",
      "|    value_loss         | 0.0052       |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 479       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -158      |\n",
      "|    explained_variance | -0.478    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | 17.4      |\n",
      "|    reward             | 0.0540547 |\n",
      "|    std                | 2.57      |\n",
      "|    value_loss         | 0.0169    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 79           |\n",
      "|    iterations         | 7700         |\n",
      "|    time_elapsed       | 485          |\n",
      "|    total_timesteps    | 38500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -159         |\n",
      "|    explained_variance | -0.0659      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7699         |\n",
      "|    policy_loss        | 8.58         |\n",
      "|    reward             | -0.005875446 |\n",
      "|    std                | 2.61         |\n",
      "|    value_loss         | 0.0147       |\n",
      "----------------------------------------\n",
      "day: 325, episode: 120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1005201.07\n",
      "total_reward: 5201.07\n",
      "total_cost: 7400.16\n",
      "total_trades: 13231\n",
      "Sharpe: 0.326\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 7800        |\n",
      "|    time_elapsed       | 491         |\n",
      "|    total_timesteps    | 39000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -160        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7799        |\n",
      "|    policy_loss        | -1.46       |\n",
      "|    reward             | 0.024679447 |\n",
      "|    std                | 2.64        |\n",
      "|    value_loss         | 0.00173     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 79         |\n",
      "|    iterations         | 7900       |\n",
      "|    time_elapsed       | 496        |\n",
      "|    total_timesteps    | 39500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -161       |\n",
      "|    explained_variance | -0.0668    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7899       |\n",
      "|    policy_loss        | -59        |\n",
      "|    reward             | -0.1057444 |\n",
      "|    std                | 2.68       |\n",
      "|    value_loss         | 0.134      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 502         |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -162        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7999        |\n",
      "|    policy_loss        | -2.76       |\n",
      "|    reward             | 0.074616134 |\n",
      "|    std                | 2.72        |\n",
      "|    value_loss         | 0.000674    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 508         |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -163        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8099        |\n",
      "|    policy_loss        | -28.6       |\n",
      "|    reward             | -0.09276098 |\n",
      "|    std                | 2.76        |\n",
      "|    value_loss         | 0.044       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 8200        |\n",
      "|    time_elapsed       | 513         |\n",
      "|    total_timesteps    | 41000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -164        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8199        |\n",
      "|    policy_loss        | 2.91        |\n",
      "|    reward             | -0.02269935 |\n",
      "|    std                | 2.79        |\n",
      "|    value_loss         | 0.00809     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 8300        |\n",
      "|    time_elapsed       | 519         |\n",
      "|    total_timesteps    | 41500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -165        |\n",
      "|    explained_variance | -0.802      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8299        |\n",
      "|    policy_loss        | 17.6        |\n",
      "|    reward             | 0.017249057 |\n",
      "|    std                | 2.83        |\n",
      "|    value_loss         | 0.0177      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 79         |\n",
      "|    iterations         | 8400       |\n",
      "|    time_elapsed       | 525        |\n",
      "|    total_timesteps    | 42000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -165       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8399       |\n",
      "|    policy_loss        | 20.5       |\n",
      "|    reward             | 0.01790307 |\n",
      "|    std                | 2.86       |\n",
      "|    value_loss         | 0.016      |\n",
      "--------------------------------------\n",
      "day: 325, episode: 130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999935.90\n",
      "total_reward: -64.10\n",
      "total_cost: 8020.77\n",
      "total_trades: 12957\n",
      "Sharpe: 0.005\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 79         |\n",
      "|    iterations         | 8500       |\n",
      "|    time_elapsed       | 531        |\n",
      "|    total_timesteps    | 42500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -166       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8499       |\n",
      "|    policy_loss        | 16.3       |\n",
      "|    reward             | 0.03369065 |\n",
      "|    std                | 2.89       |\n",
      "|    value_loss         | 0.012      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 537        |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -167       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | 58.5       |\n",
      "|    reward             | 0.07048566 |\n",
      "|    std                | 2.92       |\n",
      "|    value_loss         | 0.129      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 80           |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 542          |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -168         |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8699         |\n",
      "|    policy_loss        | 10.1         |\n",
      "|    reward             | -0.009022867 |\n",
      "|    std                | 2.96         |\n",
      "|    value_loss         | 0.00446      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 80          |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 549         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -168        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | -10         |\n",
      "|    reward             | -0.16628057 |\n",
      "|    std                | 2.99        |\n",
      "|    value_loss         | 0.00558     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 8900       |\n",
      "|    time_elapsed       | 555        |\n",
      "|    total_timesteps    | 44500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -169       |\n",
      "|    explained_variance | 0.159      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8899       |\n",
      "|    policy_loss        | -17.6      |\n",
      "|    reward             | 0.03691724 |\n",
      "|    std                | 3.03       |\n",
      "|    value_loss         | 0.0161     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 80          |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 560         |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -170        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8999        |\n",
      "|    policy_loss        | -8.59       |\n",
      "|    reward             | 0.024818545 |\n",
      "|    std                | 3.07        |\n",
      "|    value_loss         | 0.00409     |\n",
      "---------------------------------------\n",
      "day: 325, episode: 140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1004351.92\n",
      "total_reward: 4351.92\n",
      "total_cost: 6894.43\n",
      "total_trades: 12557\n",
      "Sharpe: 0.225\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 9100       |\n",
      "|    time_elapsed       | 566        |\n",
      "|    total_timesteps    | 45500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -171       |\n",
      "|    explained_variance | 0.00334    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9099       |\n",
      "|    policy_loss        | -5.96      |\n",
      "|    reward             | 0.11579938 |\n",
      "|    std                | 3.1        |\n",
      "|    value_loss         | 0.00194    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 80           |\n",
      "|    iterations         | 9200         |\n",
      "|    time_elapsed       | 573          |\n",
      "|    total_timesteps    | 46000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -171         |\n",
      "|    explained_variance | -0.265       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9199         |\n",
      "|    policy_loss        | 1.86         |\n",
      "|    reward             | -0.011156072 |\n",
      "|    std                | 3.13         |\n",
      "|    value_loss         | 0.00647      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 9300       |\n",
      "|    time_elapsed       | 578        |\n",
      "|    total_timesteps    | 46500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -172       |\n",
      "|    explained_variance | -0.00572   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9299       |\n",
      "|    policy_loss        | 8.06       |\n",
      "|    reward             | 0.07710647 |\n",
      "|    std                | 3.18       |\n",
      "|    value_loss         | 0.00636    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 80          |\n",
      "|    iterations         | 9400        |\n",
      "|    time_elapsed       | 583         |\n",
      "|    total_timesteps    | 47000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -173        |\n",
      "|    explained_variance | -0.404      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9399        |\n",
      "|    policy_loss        | -65.5       |\n",
      "|    reward             | 0.061751492 |\n",
      "|    std                | 3.21        |\n",
      "|    value_loss         | 0.176       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 80           |\n",
      "|    iterations         | 9500         |\n",
      "|    time_elapsed       | 589          |\n",
      "|    total_timesteps    | 47500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -174         |\n",
      "|    explained_variance | -3.58e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9499         |\n",
      "|    policy_loss        | 11.2         |\n",
      "|    reward             | -0.015867148 |\n",
      "|    std                | 3.25         |\n",
      "|    value_loss         | 0.00697      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 80           |\n",
      "|    iterations         | 9600         |\n",
      "|    time_elapsed       | 596          |\n",
      "|    total_timesteps    | 48000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -175         |\n",
      "|    explained_variance | -0.173       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9599         |\n",
      "|    policy_loss        | 19.1         |\n",
      "|    reward             | -0.043441076 |\n",
      "|    std                | 3.29         |\n",
      "|    value_loss         | 0.0206       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 80          |\n",
      "|    iterations         | 9700        |\n",
      "|    time_elapsed       | 603         |\n",
      "|    total_timesteps    | 48500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -176        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9699        |\n",
      "|    policy_loss        | -18.5       |\n",
      "|    reward             | 0.008588206 |\n",
      "|    std                | 3.33        |\n",
      "|    value_loss         | 0.0139      |\n",
      "---------------------------------------\n",
      "day: 325, episode: 150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1001651.66\n",
      "total_reward: 1651.66\n",
      "total_cost: 8699.30\n",
      "total_trades: 13079\n",
      "Sharpe: 0.093\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 80          |\n",
      "|    iterations         | 9800        |\n",
      "|    time_elapsed       | 609         |\n",
      "|    total_timesteps    | 49000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -176        |\n",
      "|    explained_variance | -0.266      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9799        |\n",
      "|    policy_loss        | 30.9        |\n",
      "|    reward             | -0.19544636 |\n",
      "|    std                | 3.37        |\n",
      "|    value_loss         | 0.0316      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 80          |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 618         |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -177        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | -22.1       |\n",
      "|    reward             | -0.09898668 |\n",
      "|    std                | 3.41        |\n",
      "|    value_loss         | 0.0188      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 80          |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 624         |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -178        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9999        |\n",
      "|    policy_loss        | -49.3       |\n",
      "|    reward             | -0.03631921 |\n",
      "|    std                | 3.45        |\n",
      "|    value_loss         | 0.0913      |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_name = 'a2c_'\n",
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=50000)\n",
    "trained_a2c.save(os.path.join(config.TRAINED_MODEL_DIR, model_name + \".pth\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "MRiOtrywfAo1"
   },
   "source": [
    "### Model 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "M2YadjfnLwgt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 50, 'learning_rate': 0.0025}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.utils import get_schedule_fn\n",
    "agent = DRLAgent(env = env_train)\n",
    "DDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50, \"learning_rate\": 0.0025}\n",
    "model_ddpg = agent.get_model(\"ddpg\",model_kwargs= DDPG_PARAMS,  tensorboard_log = config.TENSORBOARD_LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "tCDa78rqfO_a",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to MARKETS/ForexMarket/TENSORBOARD_LOG_DIR/ddpg_3\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 16        |\n",
      "|    total_timesteps | 3024      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -88.2     |\n",
      "|    critic_loss     | 22.3      |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 2268      |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 196       |\n",
      "|    time_elapsed    | 30        |\n",
      "|    total_timesteps | 6048      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -51       |\n",
      "|    critic_loss     | 19.8      |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 5292      |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 200       |\n",
      "|    time_elapsed    | 45        |\n",
      "|    total_timesteps | 9072      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -24       |\n",
      "|    critic_loss     | 1.21      |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 8316      |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 200       |\n",
      "|    time_elapsed    | 60        |\n",
      "|    total_timesteps | 12096     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -6.15     |\n",
      "|    critic_loss     | 0.572     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 11340     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 200       |\n",
      "|    time_elapsed    | 75        |\n",
      "|    total_timesteps | 15120     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.24     |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 14364     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 200       |\n",
      "|    time_elapsed    | 90        |\n",
      "|    total_timesteps | 18144     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.972    |\n",
      "|    critic_loss     | 0.109     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 17388     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 28        |\n",
      "|    fps             | 200       |\n",
      "|    time_elapsed    | 105       |\n",
      "|    total_timesteps | 21168     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -4.18     |\n",
      "|    critic_loss     | 0.212     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 20412     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 32        |\n",
      "|    fps             | 199       |\n",
      "|    time_elapsed    | 121       |\n",
      "|    total_timesteps | 24192     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -2.17     |\n",
      "|    critic_loss     | 0.116     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 23436     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 36        |\n",
      "|    fps             | 198       |\n",
      "|    time_elapsed    | 136       |\n",
      "|    total_timesteps | 27216     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.46     |\n",
      "|    critic_loss     | 0.0123    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 26460     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 40        |\n",
      "|    fps             | 198       |\n",
      "|    time_elapsed    | 152       |\n",
      "|    total_timesteps | 30240     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.18     |\n",
      "|    critic_loss     | 0.00662   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 29484     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 44        |\n",
      "|    fps             | 198       |\n",
      "|    time_elapsed    | 167       |\n",
      "|    total_timesteps | 33264     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.814    |\n",
      "|    critic_loss     | 0.00192   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 32508     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 48        |\n",
      "|    fps             | 195       |\n",
      "|    time_elapsed    | 185       |\n",
      "|    total_timesteps | 36288     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.889    |\n",
      "|    critic_loss     | 0.0207    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 35532     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 52        |\n",
      "|    fps             | 194       |\n",
      "|    time_elapsed    | 202       |\n",
      "|    total_timesteps | 39312     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.962    |\n",
      "|    critic_loss     | 0.00103   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 38556     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 56        |\n",
      "|    fps             | 192       |\n",
      "|    time_elapsed    | 219       |\n",
      "|    total_timesteps | 42336     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.978    |\n",
      "|    critic_loss     | 0.00151   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 41580     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 60        |\n",
      "|    fps             | 192       |\n",
      "|    time_elapsed    | 236       |\n",
      "|    total_timesteps | 45360     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.954    |\n",
      "|    critic_loss     | 0.00124   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 44604     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 64        |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 253       |\n",
      "|    total_timesteps | 48384     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.904    |\n",
      "|    critic_loss     | 0.00129   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 47628     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 68        |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 268       |\n",
      "|    total_timesteps | 51408     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.878    |\n",
      "|    critic_loss     | 0.00105   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 50652     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 72        |\n",
      "|    fps             | 192       |\n",
      "|    time_elapsed    | 283       |\n",
      "|    total_timesteps | 54432     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.889    |\n",
      "|    critic_loss     | 0.000129  |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 53676     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 76        |\n",
      "|    fps             | 192       |\n",
      "|    time_elapsed    | 298       |\n",
      "|    total_timesteps | 57456     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.904    |\n",
      "|    critic_loss     | 0.000565  |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 56700     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 80        |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 315       |\n",
      "|    total_timesteps | 60480     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.89     |\n",
      "|    critic_loss     | 0.000893  |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 59724     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 84        |\n",
      "|    fps             | 192       |\n",
      "|    time_elapsed    | 330       |\n",
      "|    total_timesteps | 63504     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.94     |\n",
      "|    critic_loss     | 0.0239    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 62748     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 88        |\n",
      "|    fps             | 192       |\n",
      "|    time_elapsed    | 345       |\n",
      "|    total_timesteps | 66528     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.08     |\n",
      "|    critic_loss     | 0.0328    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 65772     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 92        |\n",
      "|    fps             | 192       |\n",
      "|    time_elapsed    | 360       |\n",
      "|    total_timesteps | 69552     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.04     |\n",
      "|    critic_loss     | 0.0177    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 68796     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 96        |\n",
      "|    fps             | 193       |\n",
      "|    time_elapsed    | 375       |\n",
      "|    total_timesteps | 72576     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.06     |\n",
      "|    critic_loss     | 0.0091    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 71820     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 100       |\n",
      "|    fps             | 193       |\n",
      "|    time_elapsed    | 389       |\n",
      "|    total_timesteps | 75600     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.957    |\n",
      "|    critic_loss     | 0.0158    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 74844     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 104       |\n",
      "|    fps             | 194       |\n",
      "|    time_elapsed    | 404       |\n",
      "|    total_timesteps | 78624     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.927    |\n",
      "|    critic_loss     | 0.0102    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 77868     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 108       |\n",
      "|    fps             | 194       |\n",
      "|    time_elapsed    | 420       |\n",
      "|    total_timesteps | 81648     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.892    |\n",
      "|    critic_loss     | 0.0074    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 80892     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 112       |\n",
      "|    fps             | 193       |\n",
      "|    time_elapsed    | 438       |\n",
      "|    total_timesteps | 84672     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.878    |\n",
      "|    critic_loss     | 0.0064    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 83916     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 116       |\n",
      "|    fps             | 192       |\n",
      "|    time_elapsed    | 455       |\n",
      "|    total_timesteps | 87696     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.861    |\n",
      "|    critic_loss     | 0.00514   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 86940     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 120       |\n",
      "|    fps             | 192       |\n",
      "|    time_elapsed    | 471       |\n",
      "|    total_timesteps | 90720     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.851    |\n",
      "|    critic_loss     | 0.00453   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 89964     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 124       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 488       |\n",
      "|    total_timesteps | 93744     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.84     |\n",
      "|    critic_loss     | 0.00397   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 92988     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 128       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 504       |\n",
      "|    total_timesteps | 96768     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.839    |\n",
      "|    critic_loss     | 0.00406   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 96012     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 132       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 520       |\n",
      "|    total_timesteps | 99792     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.856    |\n",
      "|    critic_loss     | 0.00399   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 99036     |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 136       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 535       |\n",
      "|    total_timesteps | 102816    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.861    |\n",
      "|    critic_loss     | 0.00481   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 102060    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 140       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 552       |\n",
      "|    total_timesteps | 105840    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.87     |\n",
      "|    critic_loss     | 0.00447   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 105084    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 144       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 567       |\n",
      "|    total_timesteps | 108864    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.869    |\n",
      "|    critic_loss     | 0.0152    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 108108    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 148       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 583       |\n",
      "|    total_timesteps | 111888    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.892    |\n",
      "|    critic_loss     | 0.00647   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 111132    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 152       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 599       |\n",
      "|    total_timesteps | 114912    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.899    |\n",
      "|    critic_loss     | 0.0151    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 114156    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 156       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 614       |\n",
      "|    total_timesteps | 117936    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.899    |\n",
      "|    critic_loss     | 0.00409   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 117180    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 160       |\n",
      "|    fps             | 192       |\n",
      "|    time_elapsed    | 629       |\n",
      "|    total_timesteps | 120960    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.869    |\n",
      "|    critic_loss     | 0.00279   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 120204    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 164       |\n",
      "|    fps             | 192       |\n",
      "|    time_elapsed    | 644       |\n",
      "|    total_timesteps | 123984    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.861    |\n",
      "|    critic_loss     | 0.00234   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 123228    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 168       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 662       |\n",
      "|    total_timesteps | 127008    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.862    |\n",
      "|    critic_loss     | 0.00209   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 126252    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 172       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 679       |\n",
      "|    total_timesteps | 130032    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.874    |\n",
      "|    critic_loss     | 0.00241   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 129276    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 176       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 697       |\n",
      "|    total_timesteps | 133056    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.867    |\n",
      "|    critic_loss     | 0.00127   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 132300    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 180       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 713       |\n",
      "|    total_timesteps | 136080    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.86     |\n",
      "|    critic_loss     | 0.00197   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 135324    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 184       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 730       |\n",
      "|    total_timesteps | 139104    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.86     |\n",
      "|    critic_loss     | 0.000987  |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 138348    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 188       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 748       |\n",
      "|    total_timesteps | 142128    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.874    |\n",
      "|    critic_loss     | 0.00136   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 141372    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 192       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 765       |\n",
      "|    total_timesteps | 145152    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.887    |\n",
      "|    critic_loss     | 0.00125   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 144396    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 196       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 781       |\n",
      "|    total_timesteps | 148176    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.891    |\n",
      "|    critic_loss     | 0.00142   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 147420    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 200       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 797       |\n",
      "|    total_timesteps | 151200    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.886    |\n",
      "|    critic_loss     | 0.00187   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 150444    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 204       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 812       |\n",
      "|    total_timesteps | 154224    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.897    |\n",
      "|    critic_loss     | 0.00206   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 153468    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 208       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 828       |\n",
      "|    total_timesteps | 157248    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.902    |\n",
      "|    critic_loss     | 0.00187   |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 156492    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 212       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 843       |\n",
      "|    total_timesteps | 160272    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.902    |\n",
      "|    critic_loss     | 0.0017    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 159516    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 216       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 858       |\n",
      "|    total_timesteps | 163296    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.93     |\n",
      "|    critic_loss     | 0.0109    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 162540    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 220\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 220       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 873       |\n",
      "|    total_timesteps | 166320    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.998    |\n",
      "|    critic_loss     | 0.0665    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 165564    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 224       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 887       |\n",
      "|    total_timesteps | 169344    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.977    |\n",
      "|    critic_loss     | 0.063     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 168588    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 228       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 904       |\n",
      "|    total_timesteps | 172368    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.973    |\n",
      "|    critic_loss     | 0.0785    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 171612    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 230\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 232       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 921       |\n",
      "|    total_timesteps | 175392    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.968    |\n",
      "|    critic_loss     | 0.0597    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 174636    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 236       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 938       |\n",
      "|    total_timesteps | 178416    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.93     |\n",
      "|    critic_loss     | 0.0834    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 177660    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 240\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 240       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 955       |\n",
      "|    total_timesteps | 181440    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.913    |\n",
      "|    critic_loss     | 0.0588    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 180684    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 244       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 972       |\n",
      "|    total_timesteps | 184464    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.911    |\n",
      "|    critic_loss     | 0.066     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 183708    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 248       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 988       |\n",
      "|    total_timesteps | 187488    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.972    |\n",
      "|    critic_loss     | 0.0708    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 186732    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 250\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 252       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1002      |\n",
      "|    total_timesteps | 190512    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.98     |\n",
      "|    critic_loss     | 0.0783    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 189756    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 256       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1017      |\n",
      "|    total_timesteps | 193536    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.02     |\n",
      "|    critic_loss     | 0.0717    |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 192780    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 260\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 260       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1033      |\n",
      "|    total_timesteps | 196560    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.831    |\n",
      "|    critic_loss     | 0.134     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 195804    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 264       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1049      |\n",
      "|    total_timesteps | 199584    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.693    |\n",
      "|    critic_loss     | 0.133     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 198828    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 268       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1065      |\n",
      "|    total_timesteps | 202608    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.603    |\n",
      "|    critic_loss     | 0.131     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 201852    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 270\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 272       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1080      |\n",
      "|    total_timesteps | 205632    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.557    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 204876    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 276       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1095      |\n",
      "|    total_timesteps | 208656    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.545    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 207900    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 280\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 280       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1110      |\n",
      "|    total_timesteps | 211680    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.521    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 210924    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 284       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1126      |\n",
      "|    total_timesteps | 214704    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.505    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 213948    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 288       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1142      |\n",
      "|    total_timesteps | 217728    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.49     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 216972    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 290\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 292       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1159      |\n",
      "|    total_timesteps | 220752    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 219996    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 296       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1177      |\n",
      "|    total_timesteps | 223776    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 223020    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 300\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 300       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 1194      |\n",
      "|    total_timesteps | 226800    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 226044    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 304       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 1210      |\n",
      "|    total_timesteps | 229824    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 229068    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 308       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 1226      |\n",
      "|    total_timesteps | 232848    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 232092    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 310\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 312       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1240      |\n",
      "|    total_timesteps | 235872    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 235116    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 316       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1256      |\n",
      "|    total_timesteps | 238896    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.484    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 238140    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 320\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 320       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1271      |\n",
      "|    total_timesteps | 241920    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.467    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 241164    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 324       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1286      |\n",
      "|    total_timesteps | 244944    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.462    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 244188    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 328       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1301      |\n",
      "|    total_timesteps | 247968    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.455    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 247212    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 330\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 332       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1317      |\n",
      "|    total_timesteps | 250992    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.464    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 250236    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 336       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1332      |\n",
      "|    total_timesteps | 254016    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.469    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 253260    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 340\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 340       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1346      |\n",
      "|    total_timesteps | 257040    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 256284    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 344       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1361      |\n",
      "|    total_timesteps | 260064    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 259308    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 348       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1378      |\n",
      "|    total_timesteps | 263088    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.488    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 262332    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 350\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 352       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1395      |\n",
      "|    total_timesteps | 266112    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.492    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 265356    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 356       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1412      |\n",
      "|    total_timesteps | 269136    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.499    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 268380    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 360\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 360       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1428      |\n",
      "|    total_timesteps | 272160    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.483    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 271404    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 364       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1444      |\n",
      "|    total_timesteps | 275184    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 274428    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 368       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1460      |\n",
      "|    total_timesteps | 278208    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.478    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 277452    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 370\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 372       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1475      |\n",
      "|    total_timesteps | 281232    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.491    |\n",
      "|    critic_loss     | 0.13      |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 280476    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 376       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1489      |\n",
      "|    total_timesteps | 284256    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.485    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 283500    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 380\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 380       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1505      |\n",
      "|    total_timesteps | 287280    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.484    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 286524    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 384       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1521      |\n",
      "|    total_timesteps | 290304    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.482    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 289548    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 388       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1536      |\n",
      "|    total_timesteps | 293328    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 292572    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 390\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 392       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1551      |\n",
      "|    total_timesteps | 296352    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 295596    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 396       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1565      |\n",
      "|    total_timesteps | 299376    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 298620    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 400\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 400       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1580      |\n",
      "|    total_timesteps | 302400    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.473    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 301644    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 404       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1594      |\n",
      "|    total_timesteps | 305424    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.476    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 304668    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 408       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1608      |\n",
      "|    total_timesteps | 308448    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.478    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 307692    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 410\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 412       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1624      |\n",
      "|    total_timesteps | 311472    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 310716    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 416       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1640      |\n",
      "|    total_timesteps | 314496    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 313740    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 420\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 420       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1657      |\n",
      "|    total_timesteps | 317520    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.478    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 316764    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 424       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1675      |\n",
      "|    total_timesteps | 320544    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 319788    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 428       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1692      |\n",
      "|    total_timesteps | 323568    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 322812    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 430\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 432       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1709      |\n",
      "|    total_timesteps | 326592    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 325836    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 436       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1726      |\n",
      "|    total_timesteps | 329616    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.483    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 328860    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 440\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 440       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1743      |\n",
      "|    total_timesteps | 332640    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.49     |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 331884    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 444       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1759      |\n",
      "|    total_timesteps | 335664    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 334908    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 448       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1775      |\n",
      "|    total_timesteps | 338688    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.484    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 337932    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 450\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 452       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1790      |\n",
      "|    total_timesteps | 341712    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 340956    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 456       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1804      |\n",
      "|    total_timesteps | 344736    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 343980    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 460\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 460       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1819      |\n",
      "|    total_timesteps | 347760    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 347004    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 464       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1833      |\n",
      "|    total_timesteps | 350784    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.46     |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 350028    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 468       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1848      |\n",
      "|    total_timesteps | 353808    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.469    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 353052    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 470\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 472       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1865      |\n",
      "|    total_timesteps | 356832    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 356076    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 476       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1882      |\n",
      "|    total_timesteps | 359856    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.486    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 359100    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 480\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 480       |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 1899      |\n",
      "|    total_timesteps | 362880    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.476    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 362124    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 484       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1916      |\n",
      "|    total_timesteps | 365904    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.464    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 365148    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 488       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1934      |\n",
      "|    total_timesteps | 368928    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.466    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 368172    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 490\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 492       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1949      |\n",
      "|    total_timesteps | 371952    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.473    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 371196    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 496       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1963      |\n",
      "|    total_timesteps | 374976    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.476    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 374220    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 500\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 500       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 1984      |\n",
      "|    total_timesteps | 378000    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.478    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 377244    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 504       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 2004      |\n",
      "|    total_timesteps | 381024    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.493    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 380268    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 508       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 2020      |\n",
      "|    total_timesteps | 384048    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.487    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 383292    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 510\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 512       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2037      |\n",
      "|    total_timesteps | 387072    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.483    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 386316    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 516       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 2053      |\n",
      "|    total_timesteps | 390096    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.494    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 389340    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 520\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 520       |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 2068      |\n",
      "|    total_timesteps | 393120    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.493    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 392364    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 524       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2085      |\n",
      "|    total_timesteps | 396144    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.495    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 395388    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 528       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2107      |\n",
      "|    total_timesteps | 399168    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.486    |\n",
      "|    critic_loss     | 0.13      |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 398412    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 530\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 532       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2128      |\n",
      "|    total_timesteps | 402192    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.484    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 401436    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 536       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2144      |\n",
      "|    total_timesteps | 405216    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.49     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 404460    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 540\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 540       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2160      |\n",
      "|    total_timesteps | 408240    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.489    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 407484    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 544       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2177      |\n",
      "|    total_timesteps | 411264    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.493    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 410508    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 548       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2192      |\n",
      "|    total_timesteps | 414288    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.491    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 413532    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 550\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 552       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2206      |\n",
      "|    total_timesteps | 417312    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.484    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 416556    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 556       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2223      |\n",
      "|    total_timesteps | 420336    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 419580    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 560\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 560       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2241      |\n",
      "|    total_timesteps | 423360    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.482    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 422604    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 564       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2257      |\n",
      "|    total_timesteps | 426384    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 425628    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 568       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2272      |\n",
      "|    total_timesteps | 429408    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.467    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 428652    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 570\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 572       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2287      |\n",
      "|    total_timesteps | 432432    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.473    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 431676    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 576       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2302      |\n",
      "|    total_timesteps | 435456    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.476    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 434700    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 580\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 580       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2318      |\n",
      "|    total_timesteps | 438480    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 437724    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 584       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2334      |\n",
      "|    total_timesteps | 441504    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.47     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 440748    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 588       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2351      |\n",
      "|    total_timesteps | 444528    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.467    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 443772    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 590\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 592       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2369      |\n",
      "|    total_timesteps | 447552    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.478    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 446796    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 596       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2386      |\n",
      "|    total_timesteps | 450576    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.478    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 449820    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 600\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 600       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2402      |\n",
      "|    total_timesteps | 453600    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 452844    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 604       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2419      |\n",
      "|    total_timesteps | 456624    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 455868    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 608       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2434      |\n",
      "|    total_timesteps | 459648    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 458892    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 610\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 612       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2448      |\n",
      "|    total_timesteps | 462672    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.46     |\n",
      "|    critic_loss     | 0.125     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 461916    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 616       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2466      |\n",
      "|    total_timesteps | 465696    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.465    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 464940    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 620\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 620       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2483      |\n",
      "|    total_timesteps | 468720    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 467964    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 624       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2499      |\n",
      "|    total_timesteps | 471744    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 470988    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 628       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2514      |\n",
      "|    total_timesteps | 474768    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.474    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 474012    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 630\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 632       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2529      |\n",
      "|    total_timesteps | 477792    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.469    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 477036    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 636       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2543      |\n",
      "|    total_timesteps | 480816    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 480060    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 640\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 640       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2558      |\n",
      "|    total_timesteps | 483840    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.464    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 483084    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 644       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2573      |\n",
      "|    total_timesteps | 486864    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.473    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 486108    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 648       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2590      |\n",
      "|    total_timesteps | 489888    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.472    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 489132    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 650\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 652       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2608      |\n",
      "|    total_timesteps | 492912    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 492156    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 656       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2625      |\n",
      "|    total_timesteps | 495936    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 495180    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 660\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 660       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2642      |\n",
      "|    total_timesteps | 498960    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.488    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 498204    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 664       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2659      |\n",
      "|    total_timesteps | 501984    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.493    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 501228    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 668       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2674      |\n",
      "|    total_timesteps | 505008    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.49     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 504252    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 670\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 672       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2690      |\n",
      "|    total_timesteps | 508032    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.493    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 507276    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 676       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2705      |\n",
      "|    total_timesteps | 511056    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.495    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 510300    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 680\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 680       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2722      |\n",
      "|    total_timesteps | 514080    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.488    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 513324    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 684       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2738      |\n",
      "|    total_timesteps | 517104    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.488    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 516348    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 688       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2753      |\n",
      "|    total_timesteps | 520128    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.489    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 519372    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 690\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 692       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2768      |\n",
      "|    total_timesteps | 523152    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 522396    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 696       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2783      |\n",
      "|    total_timesteps | 526176    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 525420    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 700\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 700       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2797      |\n",
      "|    total_timesteps | 529200    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 528444    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 704       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2812      |\n",
      "|    total_timesteps | 532224    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.469    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 531468    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 708       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2829      |\n",
      "|    total_timesteps | 535248    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.469    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 534492    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 710\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 712       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2846      |\n",
      "|    total_timesteps | 538272    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.478    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 537516    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 716       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2863      |\n",
      "|    total_timesteps | 541296    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.468    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 540540    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 720\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 720       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2880      |\n",
      "|    total_timesteps | 544320    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.46     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 543564    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 724       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2897      |\n",
      "|    total_timesteps | 547344    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.47     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 546588    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 728       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2911      |\n",
      "|    total_timesteps | 550368    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.469    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 549612    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 730\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 732       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2926      |\n",
      "|    total_timesteps | 553392    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.466    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 552636    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 736       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2943      |\n",
      "|    total_timesteps | 556416    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.471    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 555660    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 740\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 740       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2960      |\n",
      "|    total_timesteps | 559440    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.468    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 558684    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 744       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 2976      |\n",
      "|    total_timesteps | 562464    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.47     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 561708    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 748       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 2991      |\n",
      "|    total_timesteps | 565488    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.476    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 564732    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 750\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 752       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3006      |\n",
      "|    total_timesteps | 568512    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 567756    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 756       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3020      |\n",
      "|    total_timesteps | 571536    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.485    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 570780    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 760\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 760       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3035      |\n",
      "|    total_timesteps | 574560    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 573804    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 764       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3050      |\n",
      "|    total_timesteps | 577584    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.483    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 576828    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 768       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3068      |\n",
      "|    total_timesteps | 580608    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.487    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 579852    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 770\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 772       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3085      |\n",
      "|    total_timesteps | 583632    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 582876    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 776       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3102      |\n",
      "|    total_timesteps | 586656    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.488    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 585900    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 780\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 780       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3119      |\n",
      "|    total_timesteps | 589680    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.493    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 588924    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 784       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3137      |\n",
      "|    total_timesteps | 592704    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.491    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 591948    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 788       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3152      |\n",
      "|    total_timesteps | 595728    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.495    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 594972    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 790\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 792       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3166      |\n",
      "|    total_timesteps | 598752    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.487    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 597996    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 796       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3184      |\n",
      "|    total_timesteps | 601776    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.476    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 601020    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 800\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 800       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3201      |\n",
      "|    total_timesteps | 604800    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.474    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 604044    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 804       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3216      |\n",
      "|    total_timesteps | 607824    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 607068    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 808       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3232      |\n",
      "|    total_timesteps | 610848    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.47     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 610092    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 810\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 812       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3247      |\n",
      "|    total_timesteps | 613872    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 613116    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 816       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3262      |\n",
      "|    total_timesteps | 616896    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.469    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 616140    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 820\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 820       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3276      |\n",
      "|    total_timesteps | 619920    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 619164    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 824       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3292      |\n",
      "|    total_timesteps | 622944    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.484    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 622188    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 828       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3310      |\n",
      "|    total_timesteps | 625968    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 625212    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 830\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 832       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3327      |\n",
      "|    total_timesteps | 628992    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 628236    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 836       |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 3343      |\n",
      "|    total_timesteps | 632016    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.466    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 631260    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 840\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 840       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3360      |\n",
      "|    total_timesteps | 635040    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.468    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 634284    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 844       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3377      |\n",
      "|    total_timesteps | 638064    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.482    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 637308    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 848       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3396      |\n",
      "|    total_timesteps | 641088    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.486    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 640332    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 850\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 852       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3413      |\n",
      "|    total_timesteps | 644112    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.489    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 643356    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 856       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3431      |\n",
      "|    total_timesteps | 647136    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.495    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 646380    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 860\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 860       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3447      |\n",
      "|    total_timesteps | 650160    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 649404    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 864       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3462      |\n",
      "|    total_timesteps | 653184    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.497    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 652428    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 868       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3477      |\n",
      "|    total_timesteps | 656208    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.498    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 655452    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 870\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 872       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3492      |\n",
      "|    total_timesteps | 659232    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.489    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 658476    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 876       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3506      |\n",
      "|    total_timesteps | 662256    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.493    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 661500    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 880\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 880       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3521      |\n",
      "|    total_timesteps | 665280    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.485    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 664524    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 884       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3537      |\n",
      "|    total_timesteps | 668304    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.473    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 667548    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 888       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3554      |\n",
      "|    total_timesteps | 671328    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 670572    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 890\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 892       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3572      |\n",
      "|    total_timesteps | 674352    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.469    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 673596    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 896       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3589      |\n",
      "|    total_timesteps | 677376    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.463    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 676620    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 900\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 900       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3607      |\n",
      "|    total_timesteps | 680400    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.461    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 679644    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 904       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3623      |\n",
      "|    total_timesteps | 683424    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.473    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 682668    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 908       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3637      |\n",
      "|    total_timesteps | 686448    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.476    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 685692    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 910\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 912       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3652      |\n",
      "|    total_timesteps | 689472    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 688716    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 916       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3670      |\n",
      "|    total_timesteps | 692496    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 691740    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 920\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 920       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3686      |\n",
      "|    total_timesteps | 695520    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.463    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 694764    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 924       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3702      |\n",
      "|    total_timesteps | 698544    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.468    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 697788    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 928       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3717      |\n",
      "|    total_timesteps | 701568    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.464    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 700812    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 930\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 932       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3732      |\n",
      "|    total_timesteps | 704592    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.466    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 703836    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 936       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3746      |\n",
      "|    total_timesteps | 707616    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.471    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 706860    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 940\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 940       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3761      |\n",
      "|    total_timesteps | 710640    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.484    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 709884    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 944       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3777      |\n",
      "|    total_timesteps | 713664    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 712908    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 948       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3794      |\n",
      "|    total_timesteps | 716688    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.488    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 715932    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 950\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 952       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3811      |\n",
      "|    total_timesteps | 719712    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.495    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 718956    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 956       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3828      |\n",
      "|    total_timesteps | 722736    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.495    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 721980    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 960\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 960       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3846      |\n",
      "|    total_timesteps | 725760    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.487    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 725004    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 964       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3863      |\n",
      "|    total_timesteps | 728784    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.485    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 728028    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 968       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3877      |\n",
      "|    total_timesteps | 731808    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.495    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 731052    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 970\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 972       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3892      |\n",
      "|    total_timesteps | 734832    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.498    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 734076    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 976       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3909      |\n",
      "|    total_timesteps | 737856    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.494    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 737100    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 980\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 980       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3924      |\n",
      "|    total_timesteps | 740880    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.488    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 740124    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 984       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3940      |\n",
      "|    total_timesteps | 743904    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.501    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 743148    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 988       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3955      |\n",
      "|    total_timesteps | 746928    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.504    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 746172    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 990\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 992       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3971      |\n",
      "|    total_timesteps | 749952    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.503    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 749196    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 996       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 3985      |\n",
      "|    total_timesteps | 752976    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.497    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 752220    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1000\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1000      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4000      |\n",
      "|    total_timesteps | 756000    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.486    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 755244    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1004      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4016      |\n",
      "|    total_timesteps | 759024    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 758268    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1008      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4033      |\n",
      "|    total_timesteps | 762048    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 761292    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1010\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1012      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4050      |\n",
      "|    total_timesteps | 765072    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 764316    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1016      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4068      |\n",
      "|    total_timesteps | 768096    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 767340    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1020\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1020      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4086      |\n",
      "|    total_timesteps | 771120    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.469    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 770364    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1024      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4104      |\n",
      "|    total_timesteps | 774144    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.471    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 773388    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1028      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4121      |\n",
      "|    total_timesteps | 777168    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.464    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 776412    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1030\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1032      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4139      |\n",
      "|    total_timesteps | 780192    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.474    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 779436    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1036      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4154      |\n",
      "|    total_timesteps | 783216    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 782460    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1040\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1040      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4169      |\n",
      "|    total_timesteps | 786240    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.477    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 785484    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1044      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4184      |\n",
      "|    total_timesteps | 789264    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.47     |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 788508    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1048      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4200      |\n",
      "|    total_timesteps | 792288    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 791532    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1050\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1052      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4215      |\n",
      "|    total_timesteps | 795312    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.47     |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 794556    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1056      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4229      |\n",
      "|    total_timesteps | 798336    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.474    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 797580    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1060\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1060      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4246      |\n",
      "|    total_timesteps | 801360    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 800604    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1064      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4262      |\n",
      "|    total_timesteps | 804384    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.483    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 803628    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1068      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4280      |\n",
      "|    total_timesteps | 807408    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.489    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 806652    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1070\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1072      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4296      |\n",
      "|    total_timesteps | 810432    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.491    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 809676    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1076      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4313      |\n",
      "|    total_timesteps | 813456    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.483    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 812700    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1080\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1080      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4332      |\n",
      "|    total_timesteps | 816480    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.475    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 815724    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1084      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4347      |\n",
      "|    total_timesteps | 819504    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 818748    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1088      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4361      |\n",
      "|    total_timesteps | 822528    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.478    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 821772    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1090\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1092      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4377      |\n",
      "|    total_timesteps | 825552    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 824796    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1096      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4395      |\n",
      "|    total_timesteps | 828576    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.476    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 827820    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1100      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4411      |\n",
      "|    total_timesteps | 831600    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.476    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 830844    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1104      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4426      |\n",
      "|    total_timesteps | 834624    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.488    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 833868    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1108      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4441      |\n",
      "|    total_timesteps | 837648    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.494    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 836892    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1112      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4456      |\n",
      "|    total_timesteps | 840672    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.486    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 839916    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1116      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4471      |\n",
      "|    total_timesteps | 843696    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.491    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 842940    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1120      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4485      |\n",
      "|    total_timesteps | 846720    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.493    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 845964    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1124      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4501      |\n",
      "|    total_timesteps | 849744    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.495    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 848988    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1128      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4518      |\n",
      "|    total_timesteps | 852768    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.482    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 852012    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1132      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4536      |\n",
      "|    total_timesteps | 855792    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.483    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 855036    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1136      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4553      |\n",
      "|    total_timesteps | 858816    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.49     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 858060    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1140      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4570      |\n",
      "|    total_timesteps | 861840    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.485    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 861084    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1144      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4586      |\n",
      "|    total_timesteps | 864864    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 864108    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1148      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4601      |\n",
      "|    total_timesteps | 867888    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.482    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 867132    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1152      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4617      |\n",
      "|    total_timesteps | 870912    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.476    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 870156    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1156      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4633      |\n",
      "|    total_timesteps | 873936    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.483    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 873180    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1160      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4649      |\n",
      "|    total_timesteps | 876960    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.485    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 876204    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1164      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4665      |\n",
      "|    total_timesteps | 879984    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.482    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 879228    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1168      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4680      |\n",
      "|    total_timesteps | 883008    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.478    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 882252    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1172      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4695      |\n",
      "|    total_timesteps | 886032    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 885276    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1176      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4710      |\n",
      "|    total_timesteps | 889056    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.471    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 888300    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1180      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4724      |\n",
      "|    total_timesteps | 892080    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.473    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 891324    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1184      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4741      |\n",
      "|    total_timesteps | 895104    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.467    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 894348    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1188      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4757      |\n",
      "|    total_timesteps | 898128    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.473    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 897372    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1192      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4774      |\n",
      "|    total_timesteps | 901152    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.474    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 900396    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1196      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4790      |\n",
      "|    total_timesteps | 904176    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.455    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 903420    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1200      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4807      |\n",
      "|    total_timesteps | 907200    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.465    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 906444    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1204      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4823      |\n",
      "|    total_timesteps | 910224    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.468    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 909468    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1208      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4837      |\n",
      "|    total_timesteps | 913248    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.467    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 912492    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1212      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4852      |\n",
      "|    total_timesteps | 916272    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 915516    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1216      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4869      |\n",
      "|    total_timesteps | 919296    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.478    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 918540    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1220\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1220      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4884      |\n",
      "|    total_timesteps | 922320    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.468    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 921564    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1224      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4899      |\n",
      "|    total_timesteps | 925344    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.47     |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 924588    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1228      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4914      |\n",
      "|    total_timesteps | 928368    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.478    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 927612    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1230\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1232      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4929      |\n",
      "|    total_timesteps | 931392    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.473    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 930636    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1236      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 4944      |\n",
      "|    total_timesteps | 934416    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.484    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 933660    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1240\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1240      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 4958      |\n",
      "|    total_timesteps | 937440    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.484    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 936684    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1244      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 4974      |\n",
      "|    total_timesteps | 940464    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 939708    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1248      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 4990      |\n",
      "|    total_timesteps | 943488    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.482    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 942732    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1250\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1252      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 5007      |\n",
      "|    total_timesteps | 946512    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.487    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 945756    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1256      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 5025      |\n",
      "|    total_timesteps | 949536    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 948780    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1260\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1260      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 5042      |\n",
      "|    total_timesteps | 952560    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.472    |\n",
      "|    critic_loss     | 0.126     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 951804    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1264      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 5058      |\n",
      "|    total_timesteps | 955584    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.472    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 954828    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1268      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 5073      |\n",
      "|    total_timesteps | 958608    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 957852    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1270\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1272      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 5088      |\n",
      "|    total_timesteps | 961632    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.479    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 960876    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1276      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 5104      |\n",
      "|    total_timesteps | 964656    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.474    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 963900    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1280\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1280      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 5120      |\n",
      "|    total_timesteps | 967680    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.48     |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 966924    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1284      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 5136      |\n",
      "|    total_timesteps | 970704    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.487    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 969948    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1288      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 5151      |\n",
      "|    total_timesteps | 973728    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.488    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 972972    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1290\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1292      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 5166      |\n",
      "|    total_timesteps | 976752    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 975996    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1296      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 5181      |\n",
      "|    total_timesteps | 979776    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.474    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 979020    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1300\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1300      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 5196      |\n",
      "|    total_timesteps | 982800    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.474    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 982044    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1304      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 5212      |\n",
      "|    total_timesteps | 985824    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.468    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 985068    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1308      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 5229      |\n",
      "|    total_timesteps | 988848    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.464    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 988092    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1310\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1312      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 5246      |\n",
      "|    total_timesteps | 991872    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.471    |\n",
      "|    critic_loss     | 0.127     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 991116    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1316      |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 5263      |\n",
      "|    total_timesteps | 994896    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.476    |\n",
      "|    critic_loss     | 0.129     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 994140    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n",
      "day: 755, episode: 1320\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039545.55\n",
      "total_reward: 39545.55\n",
      "total_cost: 999.00\n",
      "total_trades: 755\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 1320      |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 5280      |\n",
      "|    total_timesteps | 997920    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.481    |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0025    |\n",
      "|    n_updates       | 997164    |\n",
      "|    reward          | 0.1039026 |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_name  = 'DDPG_'\n",
    "total_timesteps = 1000000\n",
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=total_timesteps)\n",
    "trained_ddpg.save(os.path.join(config.TRAINED_MODEL_DIR, model_name + str(total_timesteps) + \".pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of stable_baselines3.common.logger failed: Traceback (most recent call last):\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 365, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 319, in update_instances\n",
      "    refs = gc.get_referrers(old)\n",
      "KeyboardInterrupt\n",
      "]\n",
      "[autoreload of stable_baselines3.common.type_aliases failed: Traceback (most recent call last):\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 365, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 319, in update_instances\n",
      "    refs = gc.get_referrers(old)\n",
      "KeyboardInterrupt\n",
      "]\n",
      "[autoreload of stable_baselines3.common.base_class failed: Traceback (most recent call last):\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 365, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 319, in update_instances\n",
      "    refs = gc.get_referrers(old)\n",
      "KeyboardInterrupt\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "TENSORBOARD_LOG_DIR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_gDkU-j-fCmZ"
   },
   "source": [
    "### Model 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "y5D5PFUhMzSV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = config.PPO_PARAMS\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS, tensorboard_log= config.TENSORBOARD_LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ppo.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "Gt8eIQKYM4G3",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to MARKETS/ForexMarket/TENSORBOARD_LOG_DIR/ppo_1\n",
      "day: 521, episode: 120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999930.23\n",
      "total_reward: -69.77\n",
      "total_cost: 28.03\n",
      "total_trades: 477\n",
      "Sharpe: -1.430\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 125           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 16            |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0018495668 |\n",
      "--------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 109            |\n",
      "|    iterations           | 2              |\n",
      "|    time_elapsed         | 37             |\n",
      "|    total_timesteps      | 4096           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.00394472     |\n",
      "|    clip_fraction        | 0.03           |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.43          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.0204        |\n",
      "|    n_updates            | 10             |\n",
      "|    policy_gradient_loss | -0.000754      |\n",
      "|    reward               | -0.00047071525 |\n",
      "|    std                  | 1.02           |\n",
      "|    value_loss           | 0.00464        |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 111            |\n",
      "|    iterations           | 3              |\n",
      "|    time_elapsed         | 54             |\n",
      "|    total_timesteps      | 6144           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.002440176    |\n",
      "|    clip_fraction        | 0.0201         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.45          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.0126        |\n",
      "|    n_updates            | 20             |\n",
      "|    policy_gradient_loss | -0.000334      |\n",
      "|    reward               | 1.30455865e-05 |\n",
      "|    std                  | 1.04           |\n",
      "|    value_loss           | 0.00424        |\n",
      "--------------------------------------------\n",
      "day: 521, episode: 130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999924.49\n",
      "total_reward: -75.51\n",
      "total_cost: 29.17\n",
      "total_trades: 485\n",
      "Sharpe: -1.616\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 114           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 71            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0060861534  |\n",
      "|    clip_fraction        | 0.0339        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.47         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.00979       |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00154      |\n",
      "|    reward               | 0.00020111975 |\n",
      "|    std                  | 1.05          |\n",
      "|    value_loss           | 0.00282       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 117           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 87            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.005029171   |\n",
      "|    clip_fraction        | 0.0629        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.47         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.0247       |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00271      |\n",
      "|    reward               | -0.0028566222 |\n",
      "|    std                  | 1.06          |\n",
      "|    value_loss           | 0.00182       |\n",
      "-------------------------------------------\n",
      "day: 521, episode: 140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999831.76\n",
      "total_reward: -168.24\n",
      "total_cost: 32.68\n",
      "total_trades: 514\n",
      "Sharpe: -1.870\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 119            |\n",
      "|    iterations           | 6              |\n",
      "|    time_elapsed         | 103            |\n",
      "|    total_timesteps      | 12288          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0015087505   |\n",
      "|    clip_fraction        | 0.00361        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.49          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.0123        |\n",
      "|    n_updates            | 50             |\n",
      "|    policy_gradient_loss | -0.000296      |\n",
      "|    reward               | -5.6918084e-06 |\n",
      "|    std                  | 1.08           |\n",
      "|    value_loss           | 0.00113        |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 119            |\n",
      "|    iterations           | 7              |\n",
      "|    time_elapsed         | 120            |\n",
      "|    total_timesteps      | 14336          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0030484116   |\n",
      "|    clip_fraction        | 0.0104         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.5           |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.0165        |\n",
      "|    n_updates            | 60             |\n",
      "|    policy_gradient_loss | -0.000133      |\n",
      "|    reward               | -0.00031188942 |\n",
      "|    std                  | 1.09           |\n",
      "|    value_loss           | 0.000803       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 119           |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 136           |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.004512899   |\n",
      "|    clip_fraction        | 0.0732        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.51         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.00205      |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | -0.00269      |\n",
      "|    reward               | 0.00017221503 |\n",
      "|    std                  | 1.09          |\n",
      "|    value_loss           | 0.000569      |\n",
      "-------------------------------------------\n",
      "day: 521, episode: 150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999918.99\n",
      "total_reward: -81.01\n",
      "total_cost: 32.80\n",
      "total_trades: 511\n",
      "Sharpe: -0.939\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 119           |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 153           |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0027297186  |\n",
      "|    clip_fraction        | 0.00474       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.52         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.0198       |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -0.000151     |\n",
      "|    reward               | 0.00021074452 |\n",
      "|    std                  | 1.11          |\n",
      "|    value_loss           | 0.000347      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 124          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 164          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075865053 |\n",
      "|    clip_fraction        | 0.0496       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.53        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0199      |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    reward               | -0.002994742 |\n",
      "|    std                  | 1.13         |\n",
      "|    value_loss           | 0.000235     |\n",
      "------------------------------------------\n",
      "day: 521, episode: 160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999280.49\n",
      "total_reward: -719.51\n",
      "total_cost: 33.68\n",
      "total_trades: 515\n",
      "Sharpe: -1.093\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 128          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 175          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039439714 |\n",
      "|    clip_fraction        | 0.0237       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.54        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0387      |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    reward               | 6.970362e-06 |\n",
      "|    std                  | 1.13         |\n",
      "|    value_loss           | 0.000171     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 128          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 191          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004982753 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.55        |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0192      |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | 0.000155     |\n",
      "|    reward               | 9.264035e-05 |\n",
      "|    std                  | 1.14         |\n",
      "|    value_loss           | 0.000362     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 127           |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 208           |\n",
      "|    total_timesteps      | 26624         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0034466549  |\n",
      "|    clip_fraction        | 0.017         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.55         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.0283       |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | -0.00101      |\n",
      "|    reward               | 5.7179794e-05 |\n",
      "|    std                  | 1.15          |\n",
      "|    value_loss           | 8.63e-05      |\n",
      "-------------------------------------------\n",
      "day: 521, episode: 170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999096.44\n",
      "total_reward: -903.56\n",
      "total_cost: 34.32\n",
      "total_trades: 507\n",
      "Sharpe: -1.147\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 128          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 223          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043732603 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.55        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.000302     |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00127     |\n",
      "|    reward               | 0.011728906  |\n",
      "|    std                  | 1.15         |\n",
      "|    value_loss           | 8.57e-05     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 129            |\n",
      "|    iterations           | 15             |\n",
      "|    time_elapsed         | 237            |\n",
      "|    total_timesteps      | 30720          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0017186309   |\n",
      "|    clip_fraction        | 0.0138         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.56          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.0191        |\n",
      "|    n_updates            | 140            |\n",
      "|    policy_gradient_loss | -0.000946      |\n",
      "|    reward               | -0.00040880957 |\n",
      "|    std                  | 1.16           |\n",
      "|    value_loss           | 5.14e-05       |\n",
      "--------------------------------------------\n",
      "day: 521, episode: 180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 998634.26\n",
      "total_reward: -1365.74\n",
      "total_cost: 34.65\n",
      "total_trades: 519\n",
      "Sharpe: -1.143\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 129           |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 253           |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.004056423   |\n",
      "|    clip_fraction        | 0.0132        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.57         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.00962      |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -0.000824     |\n",
      "|    reward               | 0.00041280323 |\n",
      "|    std                  | 1.16          |\n",
      "|    value_loss           | 5.59e-05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 129           |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 268           |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.006900086   |\n",
      "|    clip_fraction        | 0.076         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.56         |\n",
      "|    explained_variance   | 0.382         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.0151       |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | -0.00523      |\n",
      "|    reward               | 0.00018699822 |\n",
      "|    std                  | 1.14          |\n",
      "|    value_loss           | 0.00306       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 130          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 281          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011767203 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.54        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0078      |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | 8.54e-07     |\n",
      "|    reward               | 0.0074774367 |\n",
      "|    std                  | 1.12         |\n",
      "|    value_loss           | 3.6e-05      |\n",
      "------------------------------------------\n",
      "day: 521, episode: 190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 998682.58\n",
      "total_reward: -1317.42\n",
      "total_cost: 34.82\n",
      "total_trades: 515\n",
      "Sharpe: -1.157\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 131          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 295          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049920124 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.53        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0194      |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    reward               | 0.0021066798 |\n",
      "|    std                  | 1.12         |\n",
      "|    value_loss           | 5.57e-05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 132           |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 309           |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0036663166  |\n",
      "|    clip_fraction        | 0.00688       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.53         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.0111        |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -0.000345     |\n",
      "|    reward               | -0.0017155814 |\n",
      "|    std                  | 1.11          |\n",
      "|    value_loss           | 5.53e-05      |\n",
      "-------------------------------------------\n",
      "day: 521, episode: 200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 998877.32\n",
      "total_reward: -1122.68\n",
      "total_cost: 33.74\n",
      "total_trades: 517\n",
      "Sharpe: -1.150\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 132            |\n",
      "|    iterations           | 21             |\n",
      "|    time_elapsed         | 324            |\n",
      "|    total_timesteps      | 43008          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0056640343   |\n",
      "|    clip_fraction        | 0.0377         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.52          |\n",
      "|    explained_variance   | -1.19e-07      |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 0.00815        |\n",
      "|    n_updates            | 200            |\n",
      "|    policy_gradient_loss | -0.00234       |\n",
      "|    reward               | -0.00011513752 |\n",
      "|    std                  | 1.1            |\n",
      "|    value_loss           | 9.72e-05       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 133           |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 337           |\n",
      "|    total_timesteps      | 45056         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0036093714  |\n",
      "|    clip_fraction        | 0.0291        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.51         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.0238       |\n",
      "|    n_updates            | 210           |\n",
      "|    policy_gradient_loss | -0.00185      |\n",
      "|    reward               | 0.00032092122 |\n",
      "|    std                  | 1.09          |\n",
      "|    value_loss           | 6.25e-05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 132           |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 354           |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.004442614   |\n",
      "|    clip_fraction        | 0.0303        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.51         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.000453     |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.0028       |\n",
      "|    reward               | -0.0013100529 |\n",
      "|    std                  | 1.09          |\n",
      "|    value_loss           | 4.2e-05       |\n",
      "-------------------------------------------\n",
      "day: 521, episode: 210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 998574.30\n",
      "total_reward: -1425.70\n",
      "total_cost: 34.62\n",
      "total_trades: 519\n",
      "Sharpe: -1.139\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 131            |\n",
      "|    iterations           | 24             |\n",
      "|    time_elapsed         | 374            |\n",
      "|    total_timesteps      | 49152          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0031746945   |\n",
      "|    clip_fraction        | 0.00918        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.51          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.0147        |\n",
      "|    n_updates            | 230            |\n",
      "|    policy_gradient_loss | -0.000383      |\n",
      "|    reward               | -0.00012352185 |\n",
      "|    std                  | 1.1            |\n",
      "|    value_loss           | 7.06e-05       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 130           |\n",
      "|    iterations           | 25            |\n",
      "|    time_elapsed         | 390           |\n",
      "|    total_timesteps      | 51200         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.002029471   |\n",
      "|    clip_fraction        | 0.0181        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.52         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.00494      |\n",
      "|    n_updates            | 240           |\n",
      "|    policy_gradient_loss | -0.00142      |\n",
      "|    reward               | 0.00020285514 |\n",
      "|    std                  | 1.11          |\n",
      "|    value_loss           | 9.74e-05      |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_name  = 'ppo_'\n",
    "model_version = '50000'\n",
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=50000)\n",
    "trained_ppo.save(os.path.join(config.TRAINED_MODEL_DIR, model_name + \".pth\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zpv4S0-fDBv"
   },
   "source": [
    "### Model 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "JSAHhV4Xc-bh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 100, \n",
    "              \"buffer_size\": 1000000, \n",
    "              \"learning_rate\": 0.001}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "OSRxNYAxdKpU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 199          |\n",
      "|    time_elapsed    | 15           |\n",
      "|    total_timesteps | 3024         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -422         |\n",
      "|    critic_loss     | 4.47e+03     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 2268         |\n",
      "|    reward          | -0.055712607 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 8            |\n",
      "|    fps             | 195          |\n",
      "|    time_elapsed    | 30           |\n",
      "|    total_timesteps | 6048         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -317         |\n",
      "|    critic_loss     | 1.52e+05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 5292         |\n",
      "|    reward          | -0.055712607 |\n",
      "-------------------------------------\n",
      "day: 755, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 998886.95\n",
      "total_reward: -1113.05\n",
      "total_cost: 284.47\n",
      "total_trades: 2265\n",
      "Sharpe: -0.065\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 12           |\n",
      "|    fps             | 194          |\n",
      "|    time_elapsed    | 46           |\n",
      "|    total_timesteps | 9072         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -374         |\n",
      "|    critic_loss     | 1.8e+03      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 8316         |\n",
      "|    reward          | -0.055712607 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 16           |\n",
      "|    fps             | 184          |\n",
      "|    time_elapsed    | 65           |\n",
      "|    total_timesteps | 12096        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -339         |\n",
      "|    critic_loss     | 5.38e+03     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 11340        |\n",
      "|    reward          | -0.055712607 |\n",
      "-------------------------------------\n",
      "day: 755, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 998886.95\n",
      "total_reward: -1113.05\n",
      "total_cost: 284.47\n",
      "total_trades: 2265\n",
      "Sharpe: -0.065\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 20           |\n",
      "|    fps             | 183          |\n",
      "|    time_elapsed    | 82           |\n",
      "|    total_timesteps | 15120        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -320         |\n",
      "|    critic_loss     | 1.55e+03     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 14364        |\n",
      "|    reward          | -0.055712607 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 24           |\n",
      "|    fps             | 183          |\n",
      "|    time_elapsed    | 99           |\n",
      "|    total_timesteps | 18144        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 23.3         |\n",
      "|    critic_loss     | 1.68e+04     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 17388        |\n",
      "|    reward          | -0.055712607 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 28           |\n",
      "|    fps             | 185          |\n",
      "|    time_elapsed    | 114          |\n",
      "|    total_timesteps | 21168        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.866        |\n",
      "|    critic_loss     | 0.193        |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 20412        |\n",
      "|    reward          | -0.055712607 |\n",
      "-------------------------------------\n",
      "day: 755, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 998886.95\n",
      "total_reward: -1113.05\n",
      "total_cost: 284.47\n",
      "total_trades: 2265\n",
      "Sharpe: -0.065\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 32           |\n",
      "|    fps             | 187          |\n",
      "|    time_elapsed    | 128          |\n",
      "|    total_timesteps | 24192        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 1.09         |\n",
      "|    critic_loss     | 0.0231       |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 23436        |\n",
      "|    reward          | -0.055712607 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 36           |\n",
      "|    fps             | 188          |\n",
      "|    time_elapsed    | 144          |\n",
      "|    total_timesteps | 27216        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 1.17         |\n",
      "|    critic_loss     | 0.0241       |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 26460        |\n",
      "|    reward          | -0.055712607 |\n",
      "-------------------------------------\n",
      "day: 755, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 998886.95\n",
      "total_reward: -1113.05\n",
      "total_cost: 284.47\n",
      "total_trades: 2265\n",
      "Sharpe: -0.065\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 40           |\n",
      "|    fps             | 187          |\n",
      "|    time_elapsed    | 161          |\n",
      "|    total_timesteps | 30240        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 1.16         |\n",
      "|    critic_loss     | 0.0676       |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 29484        |\n",
      "|    reward          | -0.055712607 |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_name ='td3_'\n",
    "trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=30000)\n",
    "trained_td3.save(os.path.join(config.TRAINED_MODEL_DIR, model_name + \".pth\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr49PotrfG01"
   },
   "source": [
    "### Model 5: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwOhVjqRkCdM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 1000000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 1000000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8RSdKCckJyH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 23        |\n",
      "|    time_elapsed    | 63        |\n",
      "|    total_timesteps | 1508      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.22e+03  |\n",
      "|    critic_loss     | 7.89e+03  |\n",
      "|    ent_coef        | 0.115     |\n",
      "|    ent_coef_loss   | 1.08e+03  |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 1407      |\n",
      "|    reward          | 4.9791036 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 19        |\n",
      "|    time_elapsed    | 156       |\n",
      "|    total_timesteps | 3016      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.66e+03  |\n",
      "|    critic_loss     | 8.25e+03  |\n",
      "|    ent_coef        | 0.134     |\n",
      "|    ent_coef_loss   | 1.01e+03  |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 2915      |\n",
      "|    reward          | 4.9791036 |\n",
      "----------------------------------\n",
      "day: 376, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 964607.58\n",
      "total_reward: -35392.42\n",
      "total_cost: 1002.62\n",
      "total_trades: 4139\n",
      "Sharpe: 1.166\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 21        |\n",
      "|    time_elapsed    | 212       |\n",
      "|    total_timesteps | 4524      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 2e+03     |\n",
      "|    critic_loss     | 6.04e+03  |\n",
      "|    ent_coef        | 0.155     |\n",
      "|    ent_coef_loss   | 939       |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 4423      |\n",
      "|    reward          | 4.9791036 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 22        |\n",
      "|    time_elapsed    | 273       |\n",
      "|    total_timesteps | 6032      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 2.55e+03  |\n",
      "|    critic_loss     | 9.16e+03  |\n",
      "|    ent_coef        | 0.181     |\n",
      "|    ent_coef_loss   | 863       |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 5931      |\n",
      "|    reward          | 4.9791036 |\n",
      "----------------------------------\n",
      "day: 376, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 964607.58\n",
      "total_reward: -35392.42\n",
      "total_cost: 1002.62\n",
      "total_trades: 4139\n",
      "Sharpe: 1.166\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 22        |\n",
      "|    time_elapsed    | 336       |\n",
      "|    total_timesteps | 7540      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 3.08e+03  |\n",
      "|    critic_loss     | 8.01e+03  |\n",
      "|    ent_coef        | 0.21      |\n",
      "|    ent_coef_loss   | 787       |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 7439      |\n",
      "|    reward          | 4.9791036 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 22        |\n",
      "|    time_elapsed    | 397       |\n",
      "|    total_timesteps | 9048      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 3.8e+03   |\n",
      "|    critic_loss     | 1.12e+04  |\n",
      "|    ent_coef        | 0.244     |\n",
      "|    ent_coef_loss   | 709       |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 8947      |\n",
      "|    reward          | 4.9791036 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 28        |\n",
      "|    fps             | 23        |\n",
      "|    time_elapsed    | 453       |\n",
      "|    total_timesteps | 10556     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.48e+03  |\n",
      "|    critic_loss     | 6.41e+03  |\n",
      "|    ent_coef        | 0.284     |\n",
      "|    ent_coef_loss   | 635       |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 10455     |\n",
      "|    reward          | 4.9791036 |\n",
      "----------------------------------\n",
      "day: 376, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 964607.58\n",
      "total_reward: -35392.42\n",
      "total_cost: 1002.62\n",
      "total_trades: 4139\n",
      "Sharpe: 1.166\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 32        |\n",
      "|    fps             | 23        |\n",
      "|    time_elapsed    | 516       |\n",
      "|    total_timesteps | 12064     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 5.47e+03  |\n",
      "|    critic_loss     | 9.98e+03  |\n",
      "|    ent_coef        | 0.331     |\n",
      "|    ent_coef_loss   | 559       |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 11963     |\n",
      "|    reward          | 4.9791036 |\n",
      "----------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/f/financial_projects/Deep Reinforcement Learning Approaches on Stock Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb Cell 89\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bu18/mnt/f/financial_projects/Deep%20Reinforcement%20Learning%20Approaches%20on%20Stock%20Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb#Y154sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msac_\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bu18/mnt/f/financial_projects/Deep%20Reinforcement%20Learning%20Approaches%20on%20Stock%20Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb#Y154sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m trained_sac \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mtrain_model(model\u001b[39m=\u001b[39;49mmodel_sac, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bu18/mnt/f/financial_projects/Deep%20Reinforcement%20Learning%20Approaches%20on%20Stock%20Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb#Y154sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m                              tb_log_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msac\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bu18/mnt/f/financial_projects/Deep%20Reinforcement%20Learning%20Approaches%20on%20Stock%20Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb#Y154sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m                              total_timesteps\u001b[39m=\u001b[39;49m\u001b[39m60000\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bu18/mnt/f/financial_projects/Deep%20Reinforcement%20Learning%20Approaches%20on%20Stock%20Prediction/FinRL/FinRL_StockTrading_NeurIPS_2018.ipynb#Y154sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m trained_sac\u001b[39m.\u001b[39msave(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(TRAINED_MODEL_DIR, model_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.pth\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[0;32m/mnt/f/financial_projects/Deep Reinforcement Learning Approaches on Stock Prediction/FinRL/finrl/agents/stablebaselines3/models.py:102\u001b[0m, in \u001b[0;36mDRLAgent.train_model\u001b[0;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_model\u001b[39m(\u001b[39mself\u001b[39m, model, tb_log_name, total_timesteps\u001b[39m=\u001b[39m\u001b[39m5000\u001b[39m):\n\u001b[0;32m--> 102\u001b[0m     model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    103\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    104\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    105\u001b[0m         callback\u001b[39m=\u001b[39;49mTensorboardCallback(),\n\u001b[1;32m    106\u001b[0m     )\n\u001b[1;32m    107\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/FinRl/lib/python3.8/site-packages/stable_baselines3/sac/sac.py:298\u001b[0m, in \u001b[0;36mSAC.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    286\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    287\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    295\u001b[0m     reset_num_timesteps: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    296\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OffPolicyAlgorithm:\n\u001b[0;32m--> 298\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    299\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    300\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    301\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    302\u001b[0m         eval_env\u001b[39m=\u001b[39;49meval_env,\n\u001b[1;32m    303\u001b[0m         eval_freq\u001b[39m=\u001b[39;49meval_freq,\n\u001b[1;32m    304\u001b[0m         n_eval_episodes\u001b[39m=\u001b[39;49mn_eval_episodes,\n\u001b[1;32m    305\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    306\u001b[0m         eval_log_path\u001b[39m=\u001b[39;49meval_log_path,\n\u001b[1;32m    307\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    308\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/FinRl/lib/python3.8/site-packages/stable_baselines3/common/off_policy_algorithm.py:363\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[39m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[1;32m    362\u001b[0m         \u001b[39mif\u001b[39;00m gradient_steps \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 363\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size, gradient_steps\u001b[39m=\u001b[39;49mgradient_steps)\n\u001b[1;32m    365\u001b[0m callback\u001b[39m.\u001b[39mon_training_end()\n\u001b[1;32m    367\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/FinRl/lib/python3.8/site-packages/stable_baselines3/sac/sac.py:239\u001b[0m, in \u001b[0;36mSAC.train\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    237\u001b[0m next_actions, next_log_prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactor\u001b[39m.\u001b[39maction_log_prob(replay_data\u001b[39m.\u001b[39mnext_observations)\n\u001b[1;32m    238\u001b[0m \u001b[39m# Compute the next Q values: min over all critics targets\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m next_q_values \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mcat(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcritic_target(replay_data\u001b[39m.\u001b[39;49mnext_observations, next_actions), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    240\u001b[0m next_q_values, _ \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mmin(next_q_values, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    241\u001b[0m \u001b[39m# add entropy term\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/FinRl/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/FinRl/lib/python3.8/site-packages/stable_baselines3/common/policies.py:885\u001b[0m, in \u001b[0;36mContinuousCritic.forward\u001b[0;34m(self, obs, actions)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshare_features_extractor):\n\u001b[1;32m    884\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_features(obs)\n\u001b[0;32m--> 885\u001b[0m qvalue_input \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39;49mcat([features, actions], dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    886\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(q_net(qvalue_input) \u001b[39mfor\u001b[39;00m q_net \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_networks)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_name = 'sac_'\n",
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=60000)\n",
    "trained_sac.save(os.path.join(config.TRAINED_MODEL_DIR, model_name + \".pth\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6: recurrentppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 13  |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 9   |\n",
      "|    total_timesteps | 128 |\n",
      "----------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 13         |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 19         |\n",
      "|    total_timesteps      | 256        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15408333 |\n",
      "|    clip_fraction        | 0.392      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.863     |\n",
      "|    explained_variance   | -0.28      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.465      |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | 0.431      |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 0.00468    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 21         |\n",
      "|    total_timesteps      | 384        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09988053 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.04      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.414      |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | 0.35       |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 0.0059     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 22         |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 22         |\n",
      "|    total_timesteps      | 512        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15821509 |\n",
      "|    clip_fraction        | 0.384      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.883     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.473      |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | 0.416      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.00376    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 23         |\n",
      "|    total_timesteps      | 640        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08317316 |\n",
      "|    clip_fraction        | 0.292      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.395      |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | 0.379      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.00516    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 28         |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 26         |\n",
      "|    total_timesteps      | 768        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16150594 |\n",
      "|    clip_fraction        | 0.505      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.705     |\n",
      "|    explained_variance   | -0.0297    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.297      |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | 0.288      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.00753    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 31          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 896         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.069801815 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.365       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | 0.392       |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.00087     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 34         |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 29         |\n",
      "|    total_timesteps      | 1024       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15124899 |\n",
      "|    clip_fraction        | 0.38       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.882     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.468      |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | 0.433      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.00103    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 37         |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 30         |\n",
      "|    total_timesteps      | 1152       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06769338 |\n",
      "|    clip_fraction        | 0.37       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.896     |\n",
      "|    explained_variance   | -0.142     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.364      |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | 0.442      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.000693   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 36         |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 35         |\n",
      "|    total_timesteps      | 1280       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15645479 |\n",
      "|    clip_fraction        | 0.479      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.742     |\n",
      "|    explained_variance   | -0.103     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.284      |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | 0.272      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.00162    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 38           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 1408         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052852547 |\n",
      "|    clip_fraction        | 0.21         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0467       |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | 0.292        |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000221     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 40         |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 38         |\n",
      "|    total_timesteps      | 1536       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03370288 |\n",
      "|    clip_fraction        | 0.353      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.923     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.168      |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | 0.362      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.000173   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 1664         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061935047 |\n",
      "|    clip_fraction        | 0.317        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.973       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0291       |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | 0.315        |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000182     |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 31        |\n",
      "|    iterations           | 14        |\n",
      "|    time_elapsed         | 57        |\n",
      "|    total_timesteps      | 1792      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1431268 |\n",
      "|    clip_fraction        | 0.377     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.893    |\n",
      "|    explained_variance   | -0.318    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.253     |\n",
      "|    n_updates            | 130       |\n",
      "|    policy_gradient_loss | 0.22      |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 0.000525  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 32         |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 59         |\n",
      "|    total_timesteps      | 1920       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12339346 |\n",
      "|    clip_fraction        | 0.36       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.929     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.436      |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | 0.414      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 6.06e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 33         |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 60         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07184786 |\n",
      "|    clip_fraction        | 0.296      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.296      |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | 0.328      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 5.43e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 35         |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 61         |\n",
      "|    total_timesteps      | 2176       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16030458 |\n",
      "|    clip_fraction        | 0.374      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.897     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.439      |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | 0.37       |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 6.56e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 34         |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 66         |\n",
      "|    total_timesteps      | 2304       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14065298 |\n",
      "|    clip_fraction        | 0.399      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.863     |\n",
      "|    explained_variance   | -0.681     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.234      |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | 0.221      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.000253   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 36         |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 67         |\n",
      "|    total_timesteps      | 2432       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09432593 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.412      |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | 0.391      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 2.85e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 37          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 2560        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048354544 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.285       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | 0.366       |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.88e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 38         |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 70         |\n",
      "|    total_timesteps      | 2688       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13321045 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.03      |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.462      |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | 0.366      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 1.63e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 38         |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 73         |\n",
      "|    total_timesteps      | 2816       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14739487 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.03      |\n",
      "|    explained_variance   | -1.64      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.206      |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | 0.146      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.000175   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 39         |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 74         |\n",
      "|    total_timesteps      | 2944       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11653935 |\n",
      "|    clip_fraction        | 0.358      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.927     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.429      |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | 0.425      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 2e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 40         |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 76         |\n",
      "|    total_timesteps      | 3072       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10517091 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.07      |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.422      |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | 0.33       |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 1.51e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 3200        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.104902156 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.411       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | 0.323       |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.16e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 3328        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.101244435 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.971      |\n",
      "|    explained_variance   | -5.57       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0988      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | 0.102       |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.94e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 3456        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027844852 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.155       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | 0.325       |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 6.52e-06    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 42        |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 84        |\n",
      "|    total_timesteps      | 3584      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1597437 |\n",
      "|    clip_fraction        | 0.349     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.93     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.299     |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | 0.233     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 1.1e-05   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 43        |\n",
      "|    iterations           | 29        |\n",
      "|    time_elapsed         | 85        |\n",
      "|    total_timesteps      | 3712      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1089355 |\n",
      "|    clip_fraction        | 0.333     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.95     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.178     |\n",
      "|    n_updates            | 280       |\n",
      "|    policy_gradient_loss | 0.171     |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.63e-05  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 43         |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 89         |\n",
      "|    total_timesteps      | 3840       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12448902 |\n",
      "|    clip_fraction        | 0.365      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.902     |\n",
      "|    explained_variance   | -6.81      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0763     |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | 0.0725     |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 8.51e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 3968        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.111158736 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00632    |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00396    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 4.39e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036548078 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.931      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.044       |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | 0.118       |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.6e-06     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 44         |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 94         |\n",
      "|    total_timesteps      | 4224       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08662726 |\n",
      "|    clip_fraction        | 0.348      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.93      |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0191     |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | 0.0272     |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 8.72e-07   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 44         |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 97         |\n",
      "|    total_timesteps      | 4352       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03746298 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | -82.5      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0216    |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0475    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 6.75e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 45          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 4480        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014671897 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.957      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.112      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.362      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 7.61e-07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 45          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 4608        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021620678 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0283     |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0739     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.75e-07    |\n",
      "-----------------------------------------\n",
      "day: 521, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999967.69\n",
      "total_reward: -32.31\n",
      "total_cost: 26.22\n",
      "total_trades: 441\n",
      "Sharpe: -0.968\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 46         |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 102        |\n",
      "|    total_timesteps      | 4736       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12244283 |\n",
      "|    clip_fraction        | 0.332      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.957     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.089     |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.08      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 7.1e-08    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 45         |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 106        |\n",
      "|    total_timesteps      | 4864       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16883782 |\n",
      "|    clip_fraction        | 0.395      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.86      |\n",
      "|    explained_variance   | -776       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0513    |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0415    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 5.49e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 4992        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013858112 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0178     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | 0.055       |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3.77e-07    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 46        |\n",
      "|    iterations           | 40        |\n",
      "|    time_elapsed         | 109       |\n",
      "|    total_timesteps      | 5120      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1256581 |\n",
      "|    clip_fraction        | 0.389     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.01     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.337     |\n",
      "|    n_updates            | 390       |\n",
      "|    policy_gradient_loss | 0.284     |\n",
      "|    std                  | 0.999     |\n",
      "|    value_loss           | 6.67e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 47         |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 110        |\n",
      "|    total_timesteps      | 5248       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14783949 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.389      |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | 0.26       |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 1.45e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 46         |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 115        |\n",
      "|    total_timesteps      | 5376       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10867713 |\n",
      "|    clip_fraction        | 0.408      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.839     |\n",
      "|    explained_variance   | -6.56e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0227    |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0275    |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 5.14e-05   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 47        |\n",
      "|    iterations           | 43        |\n",
      "|    time_elapsed         | 116       |\n",
      "|    total_timesteps      | 5504      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0760449 |\n",
      "|    clip_fraction        | 0.384     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.909    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.307     |\n",
      "|    n_updates            | 420       |\n",
      "|    policy_gradient_loss | 0.419     |\n",
      "|    std                  | 0.993     |\n",
      "|    value_loss           | 6.96e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 47         |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 118        |\n",
      "|    total_timesteps      | 5632       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15575205 |\n",
      "|    clip_fraction        | 0.307      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.985     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.466      |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | 0.332      |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 2.55e-08   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 48        |\n",
      "|    iterations           | 45        |\n",
      "|    time_elapsed         | 119       |\n",
      "|    total_timesteps      | 5760      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1564574 |\n",
      "|    clip_fraction        | 0.311     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.973    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.455     |\n",
      "|    n_updates            | 440       |\n",
      "|    policy_gradient_loss | 0.36      |\n",
      "|    std                  | 0.992     |\n",
      "|    value_loss           | 1.88e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 47         |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 123        |\n",
      "|    total_timesteps      | 5888       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20510347 |\n",
      "|    clip_fraction        | 0.489      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.72      |\n",
      "|    explained_variance   | -7.82e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0333    |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0301    |\n",
      "|    std                  | 0.991      |\n",
      "|    value_loss           | 4.23e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 47          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 6016        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.097795665 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.892      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.381       |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | 0.434       |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 2.62e-08    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 48         |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 126        |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14543793 |\n",
      "|    clip_fraction        | 0.211      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.11      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.455      |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | 0.287      |\n",
      "|    std                  | 0.989      |\n",
      "|    value_loss           | 1.5e-08    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 48         |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 128        |\n",
      "|    total_timesteps      | 6272       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13879074 |\n",
      "|    clip_fraction        | 0.291      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.434      |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | 0.331      |\n",
      "|    std                  | 0.987      |\n",
      "|    value_loss           | 2.32e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 48         |\n",
      "|    iterations           | 50         |\n",
      "|    time_elapsed         | 133        |\n",
      "|    total_timesteps      | 6400       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16466427 |\n",
      "|    clip_fraction        | 0.539      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.648     |\n",
      "|    explained_variance   | -7.34e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0291    |\n",
      "|    n_updates            | 490        |\n",
      "|    policy_gradient_loss | -0.0304    |\n",
      "|    std                  | 0.986      |\n",
      "|    value_loss           | 3.67e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 48         |\n",
      "|    iterations           | 51         |\n",
      "|    time_elapsed         | 134        |\n",
      "|    total_timesteps      | 6528       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15399475 |\n",
      "|    clip_fraction        | 0.29       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.996     |\n",
      "|    explained_variance   | 1.21e-05   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.462      |\n",
      "|    n_updates            | 500        |\n",
      "|    policy_gradient_loss | 0.362      |\n",
      "|    std                  | 0.985      |\n",
      "|    value_loss           | 1.86e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 48         |\n",
      "|    iterations           | 52         |\n",
      "|    time_elapsed         | 136        |\n",
      "|    total_timesteps      | 6656       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07069981 |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.03      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.341      |\n",
      "|    n_updates            | 510        |\n",
      "|    policy_gradient_loss | 0.389      |\n",
      "|    std                  | 0.988      |\n",
      "|    value_loss           | 9.33e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 49         |\n",
      "|    iterations           | 53         |\n",
      "|    time_elapsed         | 137        |\n",
      "|    total_timesteps      | 6784       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11164945 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.998     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.387      |\n",
      "|    n_updates            | 520        |\n",
      "|    policy_gradient_loss | 0.337      |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 4.28e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 49         |\n",
      "|    iterations           | 54         |\n",
      "|    time_elapsed         | 139        |\n",
      "|    total_timesteps      | 6912       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15012172 |\n",
      "|    clip_fraction        | 0.399      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.873     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.425      |\n",
      "|    n_updates            | 530        |\n",
      "|    policy_gradient_loss | 0.405      |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 3.65e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 48         |\n",
      "|    iterations           | 55         |\n",
      "|    time_elapsed         | 144        |\n",
      "|    total_timesteps      | 7040       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22074872 |\n",
      "|    clip_fraction        | 0.541      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.648     |\n",
      "|    explained_variance   | -1.21e+04  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0409    |\n",
      "|    n_updates            | 540        |\n",
      "|    policy_gradient_loss | -0.0358    |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 3.52e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 49         |\n",
      "|    iterations           | 56         |\n",
      "|    time_elapsed         | 145        |\n",
      "|    total_timesteps      | 7168       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15641776 |\n",
      "|    clip_fraction        | 0.336      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.936     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.466      |\n",
      "|    n_updates            | 550        |\n",
      "|    policy_gradient_loss | 0.419      |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 1.61e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 49         |\n",
      "|    iterations           | 57         |\n",
      "|    time_elapsed         | 147        |\n",
      "|    total_timesteps      | 7296       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17036983 |\n",
      "|    clip_fraction        | 0.347      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.919     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.461      |\n",
      "|    n_updates            | 560        |\n",
      "|    policy_gradient_loss | 0.406      |\n",
      "|    std                  | 0.988      |\n",
      "|    value_loss           | 6.55e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 49         |\n",
      "|    iterations           | 58         |\n",
      "|    time_elapsed         | 148        |\n",
      "|    total_timesteps      | 7424       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10111868 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.362      |\n",
      "|    n_updates            | 570        |\n",
      "|    policy_gradient_loss | 0.337      |\n",
      "|    std                  | 0.985      |\n",
      "|    value_loss           | 2.01e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 49         |\n",
      "|    iterations           | 59         |\n",
      "|    time_elapsed         | 153        |\n",
      "|    total_timesteps      | 7552       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14264031 |\n",
      "|    clip_fraction        | 0.501      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.7       |\n",
      "|    explained_variance   | -7.47e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0247    |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | -0.0322    |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 3.66e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 7680        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.102023624 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.947      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.336       |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | 0.403       |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 6.82e-08    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 50         |\n",
      "|    iterations           | 61         |\n",
      "|    time_elapsed         | 156        |\n",
      "|    total_timesteps      | 7808       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15964685 |\n",
      "|    clip_fraction        | 0.429      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.801     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.463      |\n",
      "|    n_updates            | 600        |\n",
      "|    policy_gradient_loss | 0.46       |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 2.35e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 50         |\n",
      "|    iterations           | 62         |\n",
      "|    time_elapsed         | 157        |\n",
      "|    total_timesteps      | 7936       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10198855 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.393      |\n",
      "|    n_updates            | 610        |\n",
      "|    policy_gradient_loss | 0.402      |\n",
      "|    std                  | 0.985      |\n",
      "|    value_loss           | 7.45e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 49         |\n",
      "|    iterations           | 63         |\n",
      "|    time_elapsed         | 162        |\n",
      "|    total_timesteps      | 8064       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19069375 |\n",
      "|    clip_fraction        | 0.463      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.753     |\n",
      "|    explained_variance   | -4.2e+03   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0314    |\n",
      "|    n_updates            | 620        |\n",
      "|    policy_gradient_loss | -0.0285    |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 3.76e-05   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 50        |\n",
      "|    iterations           | 64        |\n",
      "|    time_elapsed         | 163       |\n",
      "|    total_timesteps      | 8192      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1685556 |\n",
      "|    clip_fraction        | 0.295     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.988    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.469     |\n",
      "|    n_updates            | 630       |\n",
      "|    policy_gradient_loss | 0.393     |\n",
      "|    std                  | 0.982     |\n",
      "|    value_loss           | 2.97e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 50         |\n",
      "|    iterations           | 65         |\n",
      "|    time_elapsed         | 164        |\n",
      "|    total_timesteps      | 8320       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14001903 |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.426      |\n",
      "|    n_updates            | 640        |\n",
      "|    policy_gradient_loss | 0.354      |\n",
      "|    std                  | 0.981      |\n",
      "|    value_loss           | 1.59e-08   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 50        |\n",
      "|    iterations           | 66        |\n",
      "|    time_elapsed         | 166       |\n",
      "|    total_timesteps      | 8448      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1624584 |\n",
      "|    clip_fraction        | 0.334     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.944    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.451     |\n",
      "|    n_updates            | 650       |\n",
      "|    policy_gradient_loss | 0.407     |\n",
      "|    std                  | 0.98      |\n",
      "|    value_loss           | 4.91e-09  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 50         |\n",
      "|    iterations           | 67         |\n",
      "|    time_elapsed         | 170        |\n",
      "|    total_timesteps      | 8576       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23852569 |\n",
      "|    clip_fraction        | 0.537      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.728     |\n",
      "|    explained_variance   | -3.16e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.039     |\n",
      "|    n_updates            | 660        |\n",
      "|    policy_gradient_loss | -0.0347    |\n",
      "|    std                  | 0.981      |\n",
      "|    value_loss           | 3.48e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 8704        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.068229266 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.974      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | 0.363       |\n",
      "|    std                  | 0.982       |\n",
      "|    value_loss           | 1.97e-08    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 50         |\n",
      "|    iterations           | 69         |\n",
      "|    time_elapsed         | 173        |\n",
      "|    total_timesteps      | 8832       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10282493 |\n",
      "|    clip_fraction        | 0.254      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.249      |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | 0.352      |\n",
      "|    std                  | 0.983      |\n",
      "|    value_loss           | 1.83e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 70         |\n",
      "|    time_elapsed         | 174        |\n",
      "|    total_timesteps      | 8960       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18163605 |\n",
      "|    clip_fraction        | 0.324      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.952     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.469      |\n",
      "|    n_updates            | 690        |\n",
      "|    policy_gradient_loss | 0.405      |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 9.65e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 50         |\n",
      "|    iterations           | 71         |\n",
      "|    time_elapsed         | 178        |\n",
      "|    total_timesteps      | 9088       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21353415 |\n",
      "|    clip_fraction        | 0.413      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.845     |\n",
      "|    explained_variance   | -5.31e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0437    |\n",
      "|    n_updates            | 700        |\n",
      "|    policy_gradient_loss | -0.0317    |\n",
      "|    std                  | 0.985      |\n",
      "|    value_loss           | 3.86e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 72         |\n",
      "|    time_elapsed         | 180        |\n",
      "|    total_timesteps      | 9216       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10872651 |\n",
      "|    clip_fraction        | 0.374      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.02      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.364      |\n",
      "|    n_updates            | 710        |\n",
      "|    policy_gradient_loss | 0.372      |\n",
      "|    std                  | 0.986      |\n",
      "|    value_loss           | 2.05e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 73         |\n",
      "|    time_elapsed         | 181        |\n",
      "|    total_timesteps      | 9344       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15029989 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.428      |\n",
      "|    n_updates            | 720        |\n",
      "|    policy_gradient_loss | 0.338      |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 2.53e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 74         |\n",
      "|    time_elapsed         | 183        |\n",
      "|    total_timesteps      | 9472       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12373399 |\n",
      "|    clip_fraction        | 0.407      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.891     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.342      |\n",
      "|    n_updates            | 730        |\n",
      "|    policy_gradient_loss | 0.391      |\n",
      "|    std                  | 0.981      |\n",
      "|    value_loss           | 2.47e-09   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 187         |\n",
      "|    total_timesteps      | 9600        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.094799474 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -8.42e+03   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0222     |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    std                  | 0.981       |\n",
      "|    value_loss           | 4.66e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 76         |\n",
      "|    time_elapsed         | 188        |\n",
      "|    total_timesteps      | 9728       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14130296 |\n",
      "|    clip_fraction        | 0.352      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.907     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.443      |\n",
      "|    n_updates            | 750        |\n",
      "|    policy_gradient_loss | 0.407      |\n",
      "|    std                  | 0.98       |\n",
      "|    value_loss           | 4.39e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 77         |\n",
      "|    time_elapsed         | 190        |\n",
      "|    total_timesteps      | 9856       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15193553 |\n",
      "|    clip_fraction        | 0.271      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.43       |\n",
      "|    n_updates            | 760        |\n",
      "|    policy_gradient_loss | 0.341      |\n",
      "|    std                  | 0.98       |\n",
      "|    value_loss           | 1.02e-08   |\n",
      "----------------------------------------\n",
      "day: 521, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999998.49\n",
      "total_reward: -1.51\n",
      "total_cost: 2.28\n",
      "total_trades: 56\n",
      "Sharpe: -0.754\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 78         |\n",
      "|    time_elapsed         | 191        |\n",
      "|    total_timesteps      | 9984       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12814093 |\n",
      "|    clip_fraction        | 0.291      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.992     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.398      |\n",
      "|    n_updates            | 770        |\n",
      "|    policy_gradient_loss | 0.394      |\n",
      "|    std                  | 0.979      |\n",
      "|    value_loss           | 4.95e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 79         |\n",
      "|    time_elapsed         | 195        |\n",
      "|    total_timesteps      | 10112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04398776 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.957     |\n",
      "|    explained_variance   | -2.74e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.016     |\n",
      "|    n_updates            | 780        |\n",
      "|    policy_gradient_loss | -0.024     |\n",
      "|    std                  | 0.979      |\n",
      "|    value_loss           | 3.92e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 80         |\n",
      "|    time_elapsed         | 197        |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17542498 |\n",
      "|    clip_fraction        | 0.447      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.859     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.431      |\n",
      "|    n_updates            | 790        |\n",
      "|    policy_gradient_loss | 0.422      |\n",
      "|    std                  | 0.979      |\n",
      "|    value_loss           | 1.86e-08   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 52        |\n",
      "|    iterations           | 81        |\n",
      "|    time_elapsed         | 198       |\n",
      "|    total_timesteps      | 10368     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1721585 |\n",
      "|    clip_fraction        | 0.32      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.951    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.464     |\n",
      "|    n_updates            | 800       |\n",
      "|    policy_gradient_loss | 0.425     |\n",
      "|    std                  | 0.98      |\n",
      "|    value_loss           | 1.84e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 82         |\n",
      "|    time_elapsed         | 200        |\n",
      "|    total_timesteps      | 10496      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18671098 |\n",
      "|    clip_fraction        | 0.334      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.976     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.463      |\n",
      "|    n_updates            | 810        |\n",
      "|    policy_gradient_loss | 0.379      |\n",
      "|    std                  | 0.982      |\n",
      "|    value_loss           | 4.41e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 83         |\n",
      "|    time_elapsed         | 203        |\n",
      "|    total_timesteps      | 10624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17494391 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | -4.63e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0178    |\n",
      "|    n_updates            | 820        |\n",
      "|    policy_gradient_loss | -0.0202    |\n",
      "|    std                  | 0.983      |\n",
      "|    value_loss           | 3.95e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 10752       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.096080355 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.943      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.324       |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | 0.4         |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 5.58e-08    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 10880       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.119037315 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.397       |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | 0.351       |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 2.81e-08    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 86         |\n",
      "|    time_elapsed         | 208        |\n",
      "|    total_timesteps      | 11008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12534127 |\n",
      "|    clip_fraction        | 0.319      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.965     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.403      |\n",
      "|    n_updates            | 850        |\n",
      "|    policy_gradient_loss | 0.393      |\n",
      "|    std                  | 0.983      |\n",
      "|    value_loss           | 4.8e-09    |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 52        |\n",
      "|    iterations           | 87        |\n",
      "|    time_elapsed         | 212       |\n",
      "|    total_timesteps      | 11136     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1570932 |\n",
      "|    clip_fraction        | 0.34      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.925    |\n",
      "|    explained_variance   | -3.2e+03  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0248   |\n",
      "|    n_updates            | 860       |\n",
      "|    policy_gradient_loss | -0.0205   |\n",
      "|    std                  | 0.983     |\n",
      "|    value_loss           | 3.33e-05  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 88         |\n",
      "|    time_elapsed         | 213        |\n",
      "|    total_timesteps      | 11264      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07039478 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.291      |\n",
      "|    n_updates            | 870        |\n",
      "|    policy_gradient_loss | 0.316      |\n",
      "|    std                  | 0.981      |\n",
      "|    value_loss           | 3.41e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 89         |\n",
      "|    time_elapsed         | 215        |\n",
      "|    total_timesteps      | 11392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09345385 |\n",
      "|    clip_fraction        | 0.293      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.322      |\n",
      "|    n_updates            | 880        |\n",
      "|    policy_gradient_loss | 0.356      |\n",
      "|    std                  | 0.98       |\n",
      "|    value_loss           | 1.35e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 90         |\n",
      "|    time_elapsed         | 216        |\n",
      "|    total_timesteps      | 11520      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12922306 |\n",
      "|    clip_fraction        | 0.419      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.874     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.395      |\n",
      "|    n_updates            | 890        |\n",
      "|    policy_gradient_loss | 0.426      |\n",
      "|    std                  | 0.978      |\n",
      "|    value_loss           | 1.15e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 91         |\n",
      "|    time_elapsed         | 220        |\n",
      "|    total_timesteps      | 11648      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15035681 |\n",
      "|    clip_fraction        | 0.383      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.876     |\n",
      "|    explained_variance   | -1.96e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0317    |\n",
      "|    n_updates            | 900        |\n",
      "|    policy_gradient_loss | -0.0246    |\n",
      "|    std                  | 0.978      |\n",
      "|    value_loss           | 2.95e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 92         |\n",
      "|    time_elapsed         | 221        |\n",
      "|    total_timesteps      | 11776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12035959 |\n",
      "|    clip_fraction        | 0.365      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.886     |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.409      |\n",
      "|    n_updates            | 910        |\n",
      "|    policy_gradient_loss | 0.421      |\n",
      "|    std                  | 0.977      |\n",
      "|    value_loss           | 1.84e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 93         |\n",
      "|    time_elapsed         | 223        |\n",
      "|    total_timesteps      | 11904      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12756334 |\n",
      "|    clip_fraction        | 0.378      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.868     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.429      |\n",
      "|    n_updates            | 920        |\n",
      "|    policy_gradient_loss | 0.445      |\n",
      "|    std                  | 0.977      |\n",
      "|    value_loss           | 9.38e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 94         |\n",
      "|    time_elapsed         | 224        |\n",
      "|    total_timesteps      | 12032      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17120348 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.998     |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.457      |\n",
      "|    n_updates            | 930        |\n",
      "|    policy_gradient_loss | 0.353      |\n",
      "|    std                  | 0.977      |\n",
      "|    value_loss           | 4.54e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 95         |\n",
      "|    time_elapsed         | 229        |\n",
      "|    total_timesteps      | 12160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20388219 |\n",
      "|    clip_fraction        | 0.502      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.695     |\n",
      "|    explained_variance   | -2.46e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0315    |\n",
      "|    n_updates            | 940        |\n",
      "|    policy_gradient_loss | -0.0265    |\n",
      "|    std                  | 0.978      |\n",
      "|    value_loss           | 2.24e-05   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 53        |\n",
      "|    iterations           | 96        |\n",
      "|    time_elapsed         | 230       |\n",
      "|    total_timesteps      | 12288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1192852 |\n",
      "|    clip_fraction        | 0.274     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.02     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.42      |\n",
      "|    n_updates            | 950       |\n",
      "|    policy_gradient_loss | 0.376     |\n",
      "|    std                  | 0.981     |\n",
      "|    value_loss           | 1.42e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 97         |\n",
      "|    time_elapsed         | 231        |\n",
      "|    total_timesteps      | 12416      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16774896 |\n",
      "|    clip_fraction        | 0.353      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.907     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.472      |\n",
      "|    n_updates            | 960        |\n",
      "|    policy_gradient_loss | 0.435      |\n",
      "|    std                  | 0.983      |\n",
      "|    value_loss           | 9.67e-09   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 12544       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021669138 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0439      |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | 0.352       |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 7.97e-09    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 99         |\n",
      "|    time_elapsed         | 237        |\n",
      "|    total_timesteps      | 12672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18971162 |\n",
      "|    clip_fraction        | 0.487      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.719     |\n",
      "|    explained_variance   | -1.57e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0231    |\n",
      "|    n_updates            | 980        |\n",
      "|    policy_gradient_loss | -0.0229    |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 2.18e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 100        |\n",
      "|    time_elapsed         | 239        |\n",
      "|    total_timesteps      | 12800      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14029193 |\n",
      "|    clip_fraction        | 0.332      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.937     |\n",
      "|    explained_variance   | 1.79e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.428      |\n",
      "|    n_updates            | 990        |\n",
      "|    policy_gradient_loss | 0.411      |\n",
      "|    std                  | 0.983      |\n",
      "|    value_loss           | 1.96e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 101        |\n",
      "|    time_elapsed         | 241        |\n",
      "|    total_timesteps      | 12928      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15854296 |\n",
      "|    clip_fraction        | 0.344      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.919     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.448      |\n",
      "|    n_updates            | 1000       |\n",
      "|    policy_gradient_loss | 0.425      |\n",
      "|    std                  | 0.98       |\n",
      "|    value_loss           | 8.23e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 102        |\n",
      "|    time_elapsed         | 243        |\n",
      "|    total_timesteps      | 13056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12381333 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.969     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.314      |\n",
      "|    n_updates            | 1010       |\n",
      "|    policy_gradient_loss | 0.384      |\n",
      "|    std                  | 0.977      |\n",
      "|    value_loss           | 1.29e-08   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 52        |\n",
      "|    iterations           | 103       |\n",
      "|    time_elapsed         | 248       |\n",
      "|    total_timesteps      | 13184     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2352863 |\n",
      "|    clip_fraction        | 0.532     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.653    |\n",
      "|    explained_variance   | -2.01e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0259   |\n",
      "|    n_updates            | 1020      |\n",
      "|    policy_gradient_loss | -0.0243   |\n",
      "|    std                  | 0.974     |\n",
      "|    value_loss           | 1.87e-05  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 251         |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.082250886 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.0001      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | 0.317       |\n",
      "|    std                  | 0.973       |\n",
      "|    value_loss           | 1.89e-08    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 53        |\n",
      "|    iterations           | 105       |\n",
      "|    time_elapsed         | 252       |\n",
      "|    total_timesteps      | 13440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1577104 |\n",
      "|    clip_fraction        | 0.388     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.858    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.411     |\n",
      "|    n_updates            | 1040      |\n",
      "|    policy_gradient_loss | 0.446     |\n",
      "|    std                  | 0.971     |\n",
      "|    value_loss           | 1.32e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 106        |\n",
      "|    time_elapsed         | 254        |\n",
      "|    total_timesteps      | 13568      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15075754 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.358      |\n",
      "|    n_updates            | 1050       |\n",
      "|    policy_gradient_loss | 0.367      |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 6.72e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 107        |\n",
      "|    time_elapsed         | 255        |\n",
      "|    total_timesteps      | 13696      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18083079 |\n",
      "|    clip_fraction        | 0.343      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.924     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.361      |\n",
      "|    n_updates            | 1060       |\n",
      "|    policy_gradient_loss | 0.414      |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 8.82e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 108        |\n",
      "|    time_elapsed         | 261        |\n",
      "|    total_timesteps      | 13824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26905802 |\n",
      "|    clip_fraction        | 0.503      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.703     |\n",
      "|    explained_variance   | -1.85e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0285    |\n",
      "|    n_updates            | 1070       |\n",
      "|    policy_gradient_loss | -0.0252    |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 1.89e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 109        |\n",
      "|    time_elapsed         | 262        |\n",
      "|    total_timesteps      | 13952      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18697943 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.402      |\n",
      "|    n_updates            | 1080       |\n",
      "|    policy_gradient_loss | 0.36       |\n",
      "|    std                  | 0.967      |\n",
      "|    value_loss           | 4.24e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 110        |\n",
      "|    time_elapsed         | 264        |\n",
      "|    total_timesteps      | 14080      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17542388 |\n",
      "|    clip_fraction        | 0.254      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.03      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.207      |\n",
      "|    n_updates            | 1090       |\n",
      "|    policy_gradient_loss | 0.34       |\n",
      "|    std                  | 0.965      |\n",
      "|    value_loss           | 2.03e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 111        |\n",
      "|    time_elapsed         | 268        |\n",
      "|    total_timesteps      | 14208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24068199 |\n",
      "|    clip_fraction        | 0.406      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.9       |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.291      |\n",
      "|    n_updates            | 1100       |\n",
      "|    policy_gradient_loss | 0.399      |\n",
      "|    std                  | 0.966      |\n",
      "|    value_loss           | 1.07e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 112        |\n",
      "|    time_elapsed         | 273        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33830276 |\n",
      "|    clip_fraction        | 0.49       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.707     |\n",
      "|    explained_variance   | -557       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0189    |\n",
      "|    n_updates            | 1110       |\n",
      "|    policy_gradient_loss | -0.0192    |\n",
      "|    std                  | 0.967      |\n",
      "|    value_loss           | 1.78e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 113        |\n",
      "|    time_elapsed         | 274        |\n",
      "|    total_timesteps      | 14464      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24228178 |\n",
      "|    clip_fraction        | 0.293      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.988     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.313      |\n",
      "|    n_updates            | 1120       |\n",
      "|    policy_gradient_loss | 0.381      |\n",
      "|    std                  | 0.967      |\n",
      "|    value_loss           | 6.82e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 114        |\n",
      "|    time_elapsed         | 276        |\n",
      "|    total_timesteps      | 14592      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25708795 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.968     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.404      |\n",
      "|    n_updates            | 1130       |\n",
      "|    policy_gradient_loss | 0.391      |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 5.38e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 115        |\n",
      "|    time_elapsed         | 277        |\n",
      "|    total_timesteps      | 14720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26889545 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.02      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.459      |\n",
      "|    n_updates            | 1140       |\n",
      "|    policy_gradient_loss | 0.352      |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 1.3e-08    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 116        |\n",
      "|    time_elapsed         | 282        |\n",
      "|    total_timesteps      | 14848      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35094166 |\n",
      "|    clip_fraction        | 0.489      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.712     |\n",
      "|    explained_variance   | -602       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.028     |\n",
      "|    n_updates            | 1150       |\n",
      "|    policy_gradient_loss | -0.0219    |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 1.67e-05   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 52        |\n",
      "|    iterations           | 117       |\n",
      "|    time_elapsed         | 283       |\n",
      "|    total_timesteps      | 14976     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2417387 |\n",
      "|    clip_fraction        | 0.275     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.04     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.471     |\n",
      "|    n_updates            | 1160      |\n",
      "|    policy_gradient_loss | 0.319     |\n",
      "|    std                  | 0.97      |\n",
      "|    value_loss           | 1.94e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 118        |\n",
      "|    time_elapsed         | 284        |\n",
      "|    total_timesteps      | 15104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22571036 |\n",
      "|    clip_fraction        | 0.311      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.956     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.461      |\n",
      "|    n_updates            | 1170       |\n",
      "|    policy_gradient_loss | 0.404      |\n",
      "|    std                  | 0.967      |\n",
      "|    value_loss           | 2.97e-08   |\n",
      "----------------------------------------\n",
      "day: 521, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999999.94\n",
      "total_reward: -0.06\n",
      "total_cost: 0.19\n",
      "total_trades: 2\n",
      "Sharpe: -0.413\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 119        |\n",
      "|    time_elapsed         | 286        |\n",
      "|    total_timesteps      | 15232      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20417967 |\n",
      "|    clip_fraction        | 0.342      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.911     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.342      |\n",
      "|    n_updates            | 1180       |\n",
      "|    policy_gradient_loss | 0.417      |\n",
      "|    std                  | 0.967      |\n",
      "|    value_loss           | 2.05e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 120        |\n",
      "|    time_elapsed         | 291        |\n",
      "|    total_timesteps      | 15360      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30024454 |\n",
      "|    clip_fraction        | 0.431      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.795     |\n",
      "|    explained_variance   | -356       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0275    |\n",
      "|    n_updates            | 1190       |\n",
      "|    policy_gradient_loss | -0.0183    |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 1.75e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 121        |\n",
      "|    time_elapsed         | 293        |\n",
      "|    total_timesteps      | 15488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17893094 |\n",
      "|    clip_fraction        | 0.308      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.978     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.408      |\n",
      "|    n_updates            | 1200       |\n",
      "|    policy_gradient_loss | 0.388      |\n",
      "|    std                  | 0.969      |\n",
      "|    value_loss           | 1.48e-08   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 52        |\n",
      "|    iterations           | 122       |\n",
      "|    time_elapsed         | 294       |\n",
      "|    total_timesteps      | 15616     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1971894 |\n",
      "|    clip_fraction        | 0.317     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.948    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.454     |\n",
      "|    n_updates            | 1210      |\n",
      "|    policy_gradient_loss | 0.4       |\n",
      "|    std                  | 0.97      |\n",
      "|    value_loss           | 2.15e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 123        |\n",
      "|    time_elapsed         | 296        |\n",
      "|    total_timesteps      | 15744      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22432803 |\n",
      "|    clip_fraction        | 0.405      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.828     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.468      |\n",
      "|    n_updates            | 1220       |\n",
      "|    policy_gradient_loss | 0.443      |\n",
      "|    std                  | 0.973      |\n",
      "|    value_loss           | 1.56e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 124        |\n",
      "|    time_elapsed         | 300        |\n",
      "|    total_timesteps      | 15872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30040848 |\n",
      "|    clip_fraction        | 0.392      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.846     |\n",
      "|    explained_variance   | -404       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0153    |\n",
      "|    n_updates            | 1230       |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    std                  | 0.974      |\n",
      "|    value_loss           | 1.77e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 125        |\n",
      "|    time_elapsed         | 302        |\n",
      "|    total_timesteps      | 16000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19886218 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.954     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.468      |\n",
      "|    n_updates            | 1240       |\n",
      "|    policy_gradient_loss | 0.393      |\n",
      "|    std                  | 0.971      |\n",
      "|    value_loss           | 1.71e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 126        |\n",
      "|    time_elapsed         | 303        |\n",
      "|    total_timesteps      | 16128      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16589074 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.11      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.345      |\n",
      "|    n_updates            | 1250       |\n",
      "|    policy_gradient_loss | 0.292      |\n",
      "|    std                  | 0.969      |\n",
      "|    value_loss           | 2.71e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 127        |\n",
      "|    time_elapsed         | 305        |\n",
      "|    total_timesteps      | 16256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16224924 |\n",
      "|    clip_fraction        | 0.341      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.914     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.342      |\n",
      "|    n_updates            | 1260       |\n",
      "|    policy_gradient_loss | 0.401      |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 4.99e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 128        |\n",
      "|    time_elapsed         | 309        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29886964 |\n",
      "|    clip_fraction        | 0.35       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.904     |\n",
      "|    explained_variance   | -1.27e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0259    |\n",
      "|    n_updates            | 1270       |\n",
      "|    policy_gradient_loss | -0.0202    |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 1.72e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 129        |\n",
      "|    time_elapsed         | 310        |\n",
      "|    total_timesteps      | 16512      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18994446 |\n",
      "|    clip_fraction        | 0.353      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.942     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.385      |\n",
      "|    n_updates            | 1280       |\n",
      "|    policy_gradient_loss | 0.395      |\n",
      "|    std                  | 0.967      |\n",
      "|    value_loss           | 2.3e-08    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 130        |\n",
      "|    time_elapsed         | 311        |\n",
      "|    total_timesteps      | 16640      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20036094 |\n",
      "|    clip_fraction        | 0.319      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.944     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.417      |\n",
      "|    n_updates            | 1290       |\n",
      "|    policy_gradient_loss | 0.401      |\n",
      "|    std                  | 0.966      |\n",
      "|    value_loss           | 4.31e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 131        |\n",
      "|    time_elapsed         | 313        |\n",
      "|    total_timesteps      | 16768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19303219 |\n",
      "|    clip_fraction        | 0.322      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.95      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.414      |\n",
      "|    n_updates            | 1300       |\n",
      "|    policy_gradient_loss | 0.386      |\n",
      "|    std                  | 0.966      |\n",
      "|    value_loss           | 6.88e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 132        |\n",
      "|    time_elapsed         | 316        |\n",
      "|    total_timesteps      | 16896      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28136742 |\n",
      "|    clip_fraction        | 0.333      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.923     |\n",
      "|    explained_variance   | -2e+03     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0203    |\n",
      "|    n_updates            | 1310       |\n",
      "|    policy_gradient_loss | -0.0203    |\n",
      "|    std                  | 0.965      |\n",
      "|    value_loss           | 1.58e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 133        |\n",
      "|    time_elapsed         | 317        |\n",
      "|    total_timesteps      | 17024      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15398653 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.986     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.366      |\n",
      "|    n_updates            | 1320       |\n",
      "|    policy_gradient_loss | 0.401      |\n",
      "|    std                  | 0.964      |\n",
      "|    value_loss           | 3.78e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 134        |\n",
      "|    time_elapsed         | 319        |\n",
      "|    total_timesteps      | 17152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06212515 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.07      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.101      |\n",
      "|    n_updates            | 1330       |\n",
      "|    policy_gradient_loss | 0.294      |\n",
      "|    std                  | 0.965      |\n",
      "|    value_loss           | 3.46e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 135        |\n",
      "|    time_elapsed         | 320        |\n",
      "|    total_timesteps      | 17280      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13536899 |\n",
      "|    clip_fraction        | 0.213      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.09      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.298      |\n",
      "|    n_updates            | 1340       |\n",
      "|    policy_gradient_loss | 0.317      |\n",
      "|    std                  | 0.966      |\n",
      "|    value_loss           | 3.93e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 136        |\n",
      "|    time_elapsed         | 323        |\n",
      "|    total_timesteps      | 17408      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21497847 |\n",
      "|    clip_fraction        | 0.344      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.907     |\n",
      "|    explained_variance   | -4.49e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0278    |\n",
      "|    n_updates            | 1350       |\n",
      "|    policy_gradient_loss | -0.0233    |\n",
      "|    std                  | 0.965      |\n",
      "|    value_loss           | 1.4e-05    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 137        |\n",
      "|    time_elapsed         | 325        |\n",
      "|    total_timesteps      | 17536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16601892 |\n",
      "|    clip_fraction        | 0.355      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.892     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.419      |\n",
      "|    n_updates            | 1360       |\n",
      "|    policy_gradient_loss | 0.428      |\n",
      "|    std                  | 0.965      |\n",
      "|    value_loss           | 2.28e-09   |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 138           |\n",
      "|    time_elapsed         | 326           |\n",
      "|    total_timesteps      | 17664         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6778318e-05 |\n",
      "|    clip_fraction        | 0.309         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.955        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.000509     |\n",
      "|    n_updates            | 1370          |\n",
      "|    policy_gradient_loss | 0.343         |\n",
      "|    std                  | 0.962         |\n",
      "|    value_loss           | 1.51e-09      |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 139        |\n",
      "|    time_elapsed         | 327        |\n",
      "|    total_timesteps      | 17792      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18648487 |\n",
      "|    clip_fraction        | 0.309      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.953     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.457      |\n",
      "|    n_updates            | 1380       |\n",
      "|    policy_gradient_loss | 0.396      |\n",
      "|    std                  | 0.963      |\n",
      "|    value_loss           | 4.94e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 140        |\n",
      "|    time_elapsed         | 330        |\n",
      "|    total_timesteps      | 17920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19754298 |\n",
      "|    clip_fraction        | 0.321      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.938     |\n",
      "|    explained_variance   | -3.34e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0107    |\n",
      "|    n_updates            | 1390       |\n",
      "|    policy_gradient_loss | -0.0204    |\n",
      "|    std                  | 0.963      |\n",
      "|    value_loss           | 1.3e-05    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 141        |\n",
      "|    time_elapsed         | 332        |\n",
      "|    total_timesteps      | 18048      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15839167 |\n",
      "|    clip_fraction        | 0.332      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.976     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.275      |\n",
      "|    n_updates            | 1400       |\n",
      "|    policy_gradient_loss | 0.376      |\n",
      "|    std                  | 0.963      |\n",
      "|    value_loss           | 4.52e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 142        |\n",
      "|    time_elapsed         | 333        |\n",
      "|    total_timesteps      | 18176      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17342357 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.03      |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.342      |\n",
      "|    n_updates            | 1410       |\n",
      "|    policy_gradient_loss | 0.357      |\n",
      "|    std                  | 0.965      |\n",
      "|    value_loss           | 1.8e-09    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 143        |\n",
      "|    time_elapsed         | 335        |\n",
      "|    total_timesteps      | 18304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20552282 |\n",
      "|    clip_fraction        | 0.335      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.923     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.429      |\n",
      "|    n_updates            | 1420       |\n",
      "|    policy_gradient_loss | 0.401      |\n",
      "|    std                  | 0.966      |\n",
      "|    value_loss           | 2.03e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 144        |\n",
      "|    time_elapsed         | 339        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26930004 |\n",
      "|    clip_fraction        | 0.457      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.797     |\n",
      "|    explained_variance   | -2.04e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0388    |\n",
      "|    n_updates            | 1430       |\n",
      "|    policy_gradient_loss | -0.0302    |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 9.85e-06   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 54        |\n",
      "|    iterations           | 145       |\n",
      "|    time_elapsed         | 340       |\n",
      "|    total_timesteps      | 18560     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2087599 |\n",
      "|    clip_fraction        | 0.272     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.08     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.277     |\n",
      "|    n_updates            | 1440      |\n",
      "|    policy_gradient_loss | 0.341     |\n",
      "|    std                  | 0.969     |\n",
      "|    value_loss           | 5.69e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 54        |\n",
      "|    iterations           | 146       |\n",
      "|    time_elapsed         | 342       |\n",
      "|    total_timesteps      | 18688     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2526217 |\n",
      "|    clip_fraction        | 0.272     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.01     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.31      |\n",
      "|    n_updates            | 1450      |\n",
      "|    policy_gradient_loss | 0.361     |\n",
      "|    std                  | 0.969     |\n",
      "|    value_loss           | 8.5e-09   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 147        |\n",
      "|    time_elapsed         | 343        |\n",
      "|    total_timesteps      | 18816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28696993 |\n",
      "|    clip_fraction        | 0.303      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.995     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.267      |\n",
      "|    n_updates            | 1460       |\n",
      "|    policy_gradient_loss | 0.369      |\n",
      "|    std                  | 0.969      |\n",
      "|    value_loss           | 2.11e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 148        |\n",
      "|    time_elapsed         | 347        |\n",
      "|    total_timesteps      | 18944      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37045002 |\n",
      "|    clip_fraction        | 0.5        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.694     |\n",
      "|    explained_variance   | -5.07e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0392    |\n",
      "|    n_updates            | 1470       |\n",
      "|    policy_gradient_loss | -0.0303    |\n",
      "|    std                  | 0.972      |\n",
      "|    value_loss           | 8.02e-06   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 149        |\n",
      "|    time_elapsed         | 349        |\n",
      "|    total_timesteps      | 19072      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21263412 |\n",
      "|    clip_fraction        | 0.375      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.886     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.347      |\n",
      "|    n_updates            | 1480       |\n",
      "|    policy_gradient_loss | 0.43       |\n",
      "|    std                  | 0.975      |\n",
      "|    value_loss           | 6.51e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 150        |\n",
      "|    time_elapsed         | 350        |\n",
      "|    total_timesteps      | 19200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24287042 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.98      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.397      |\n",
      "|    n_updates            | 1490       |\n",
      "|    policy_gradient_loss | 0.358      |\n",
      "|    std                  | 0.978      |\n",
      "|    value_loss           | 9.75e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 151        |\n",
      "|    time_elapsed         | 351        |\n",
      "|    total_timesteps      | 19328      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15489252 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.07      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.134      |\n",
      "|    n_updates            | 1500       |\n",
      "|    policy_gradient_loss | 0.323      |\n",
      "|    std                  | 0.978      |\n",
      "|    value_loss           | 1.05e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 152        |\n",
      "|    time_elapsed         | 355        |\n",
      "|    total_timesteps      | 19456      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33721283 |\n",
      "|    clip_fraction        | 0.454      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.763     |\n",
      "|    explained_variance   | -1.72e+04  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0375    |\n",
      "|    n_updates            | 1510       |\n",
      "|    policy_gradient_loss | -0.0338    |\n",
      "|    std                  | 0.98       |\n",
      "|    value_loss           | 8.44e-06   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 153        |\n",
      "|    time_elapsed         | 357        |\n",
      "|    total_timesteps      | 19584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20676519 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.08      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.163      |\n",
      "|    n_updates            | 1520       |\n",
      "|    policy_gradient_loss | 0.307      |\n",
      "|    std                  | 0.982      |\n",
      "|    value_loss           | 5.27e-09   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 358         |\n",
      "|    total_timesteps      | 19712       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.061283648 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0508      |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | 0.325       |\n",
      "|    std                  | 0.985       |\n",
      "|    value_loss           | 9.88e-09    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 155        |\n",
      "|    time_elapsed         | 359        |\n",
      "|    total_timesteps      | 19840      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27293795 |\n",
      "|    clip_fraction        | 0.259      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.465      |\n",
      "|    n_updates            | 1540       |\n",
      "|    policy_gradient_loss | 0.348      |\n",
      "|    std                  | 0.988      |\n",
      "|    value_loss           | 2.29e-08   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 54        |\n",
      "|    iterations           | 156       |\n",
      "|    time_elapsed         | 364       |\n",
      "|    total_timesteps      | 19968     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3291706 |\n",
      "|    clip_fraction        | 0.496     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.709    |\n",
      "|    explained_variance   | -1.59e+04 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0452   |\n",
      "|    n_updates            | 1550      |\n",
      "|    policy_gradient_loss | -0.0368   |\n",
      "|    std                  | 0.99      |\n",
      "|    value_loss           | 7.41e-06  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 157        |\n",
      "|    time_elapsed         | 365        |\n",
      "|    total_timesteps      | 20096      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22223936 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | 0.000278   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.425      |\n",
      "|    n_updates            | 1560       |\n",
      "|    policy_gradient_loss | 0.371      |\n",
      "|    std                  | 0.989      |\n",
      "|    value_loss           | 2.76e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 158       |\n",
      "|    time_elapsed         | 366       |\n",
      "|    total_timesteps      | 20224     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2952987 |\n",
      "|    clip_fraction        | 0.31      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.98     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.44      |\n",
      "|    n_updates            | 1570      |\n",
      "|    policy_gradient_loss | 0.387     |\n",
      "|    std                  | 0.989     |\n",
      "|    value_loss           | 9.83e-10  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 159        |\n",
      "|    time_elapsed         | 368        |\n",
      "|    total_timesteps      | 20352      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34380734 |\n",
      "|    clip_fraction        | 0.378      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.942     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.43       |\n",
      "|    n_updates            | 1580       |\n",
      "|    policy_gradient_loss | 0.397      |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 8.33e-10   |\n",
      "----------------------------------------\n",
      "day: 521, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999999.88\n",
      "total_reward: -0.12\n",
      "total_cost: 0.11\n",
      "total_trades: 6\n",
      "Sharpe: -1.325\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 160        |\n",
      "|    time_elapsed         | 369        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34046417 |\n",
      "|    clip_fraction        | 0.305      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.98      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.467      |\n",
      "|    n_updates            | 1590       |\n",
      "|    policy_gradient_loss | 0.391      |\n",
      "|    std                  | 0.991      |\n",
      "|    value_loss           | 4.38e-10   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 161       |\n",
      "|    time_elapsed         | 374       |\n",
      "|    total_timesteps      | 20608     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4440988 |\n",
      "|    clip_fraction        | 0.533     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.66     |\n",
      "|    explained_variance   | -7.35e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.034    |\n",
      "|    n_updates            | 1600      |\n",
      "|    policy_gradient_loss | -0.033    |\n",
      "|    std                  | 0.991     |\n",
      "|    value_loss           | 6.54e-06  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 162        |\n",
      "|    time_elapsed         | 375        |\n",
      "|    total_timesteps      | 20736      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27434355 |\n",
      "|    clip_fraction        | 0.365      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.919     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.429      |\n",
      "|    n_updates            | 1610       |\n",
      "|    policy_gradient_loss | 0.419      |\n",
      "|    std                  | 0.991      |\n",
      "|    value_loss           | 1.18e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 163        |\n",
      "|    time_elapsed         | 376        |\n",
      "|    total_timesteps      | 20864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22851957 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.167      |\n",
      "|    n_updates            | 1620       |\n",
      "|    policy_gradient_loss | 0.373      |\n",
      "|    std                  | 0.991      |\n",
      "|    value_loss           | 8.98e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 164       |\n",
      "|    time_elapsed         | 377       |\n",
      "|    total_timesteps      | 20992     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3191377 |\n",
      "|    clip_fraction        | 0.224     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.11     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.39      |\n",
      "|    n_updates            | 1630      |\n",
      "|    policy_gradient_loss | 0.329     |\n",
      "|    std                  | 0.992     |\n",
      "|    value_loss           | 1.16e-08  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 165       |\n",
      "|    time_elapsed         | 382       |\n",
      "|    total_timesteps      | 21120     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3930893 |\n",
      "|    clip_fraction        | 0.538     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.697    |\n",
      "|    explained_variance   | -2.74e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0425   |\n",
      "|    n_updates            | 1640      |\n",
      "|    policy_gradient_loss | -0.0344   |\n",
      "|    std                  | 0.992     |\n",
      "|    value_loss           | 6.36e-06  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 166        |\n",
      "|    time_elapsed         | 383        |\n",
      "|    total_timesteps      | 21248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32344392 |\n",
      "|    clip_fraction        | 0.387      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.865     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.272      |\n",
      "|    n_updates            | 1650       |\n",
      "|    policy_gradient_loss | 0.434      |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 3.2e-08    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 167        |\n",
      "|    time_elapsed         | 385        |\n",
      "|    total_timesteps      | 21376      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33000076 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.14      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.473     |\n",
      "|    n_updates            | 1660       |\n",
      "|    policy_gradient_loss | -0.304     |\n",
      "|    std                  | 0.994      |\n",
      "|    value_loss           | 1.77e-07   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 168       |\n",
      "|    time_elapsed         | 386       |\n",
      "|    total_timesteps      | 21504     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3363211 |\n",
      "|    clip_fraction        | 0.271     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.03     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.467    |\n",
      "|    n_updates            | 1670      |\n",
      "|    policy_gradient_loss | -0.366    |\n",
      "|    std                  | 0.995     |\n",
      "|    value_loss           | 6.49e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 169        |\n",
      "|    time_elapsed         | 389        |\n",
      "|    total_timesteps      | 21632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41651854 |\n",
      "|    clip_fraction        | 0.369      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.892     |\n",
      "|    explained_variance   | -2.2e+03   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0281    |\n",
      "|    n_updates            | 1680       |\n",
      "|    policy_gradient_loss | -0.0217    |\n",
      "|    std                  | 0.994      |\n",
      "|    value_loss           | 7.45e-06   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 170       |\n",
      "|    time_elapsed         | 391       |\n",
      "|    total_timesteps      | 21760     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3096369 |\n",
      "|    clip_fraction        | 0.352     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.915    |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.332     |\n",
      "|    n_updates            | 1690      |\n",
      "|    policy_gradient_loss | 0.412     |\n",
      "|    std                  | 0.992     |\n",
      "|    value_loss           | 1.11e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 171        |\n",
      "|    time_elapsed         | 392        |\n",
      "|    total_timesteps      | 21888      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32972544 |\n",
      "|    clip_fraction        | 0.359      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.904     |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.322      |\n",
      "|    n_updates            | 1700       |\n",
      "|    policy_gradient_loss | 0.432      |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 9.38e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 172       |\n",
      "|    time_elapsed         | 393       |\n",
      "|    total_timesteps      | 22016     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3317862 |\n",
      "|    clip_fraction        | 0.279     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.02     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.472     |\n",
      "|    n_updates            | 1710      |\n",
      "|    policy_gradient_loss | 0.349     |\n",
      "|    std                  | 0.994     |\n",
      "|    value_loss           | 1.09e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 173        |\n",
      "|    time_elapsed         | 397        |\n",
      "|    total_timesteps      | 22144      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48327363 |\n",
      "|    clip_fraction        | 0.46       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.763     |\n",
      "|    explained_variance   | -2.41e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.03      |\n",
      "|    n_updates            | 1720       |\n",
      "|    policy_gradient_loss | -0.0266    |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 5.6e-06    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 174        |\n",
      "|    time_elapsed         | 398        |\n",
      "|    total_timesteps      | 22272      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29790857 |\n",
      "|    clip_fraction        | 0.337      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.937     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.452      |\n",
      "|    n_updates            | 1730       |\n",
      "|    policy_gradient_loss | 0.411      |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 3.21e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 175        |\n",
      "|    time_elapsed         | 399        |\n",
      "|    total_timesteps      | 22400      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30037323 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.472      |\n",
      "|    n_updates            | 1740       |\n",
      "|    policy_gradient_loss | 0.368      |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 3.87e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 176        |\n",
      "|    time_elapsed         | 401        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30490935 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.973     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.467      |\n",
      "|    n_updates            | 1750       |\n",
      "|    policy_gradient_loss | 0.398      |\n",
      "|    std                  | 0.996      |\n",
      "|    value_loss           | 4.67e-10   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 177       |\n",
      "|    time_elapsed         | 405       |\n",
      "|    total_timesteps      | 22656     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3697189 |\n",
      "|    clip_fraction        | 0.387     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.867    |\n",
      "|    explained_variance   | -3.92e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0286   |\n",
      "|    n_updates            | 1760      |\n",
      "|    policy_gradient_loss | -0.0247   |\n",
      "|    std                  | 0.995     |\n",
      "|    value_loss           | 5.68e-06  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 178        |\n",
      "|    time_elapsed         | 406        |\n",
      "|    total_timesteps      | 22784      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31924066 |\n",
      "|    clip_fraction        | 0.33       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.963     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.468      |\n",
      "|    n_updates            | 1770       |\n",
      "|    policy_gradient_loss | 0.382      |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 4.63e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 179        |\n",
      "|    time_elapsed         | 407        |\n",
      "|    total_timesteps      | 22912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33983183 |\n",
      "|    clip_fraction        | 0.264      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.04      |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.387      |\n",
      "|    n_updates            | 1780       |\n",
      "|    policy_gradient_loss | 0.366      |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 3.71e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 180        |\n",
      "|    time_elapsed         | 408        |\n",
      "|    total_timesteps      | 23040      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36629054 |\n",
      "|    clip_fraction        | 0.346      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.936     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.448      |\n",
      "|    n_updates            | 1790       |\n",
      "|    policy_gradient_loss | 0.416      |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 1.73e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 181        |\n",
      "|    time_elapsed         | 411        |\n",
      "|    total_timesteps      | 23168      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.55090266 |\n",
      "|    clip_fraction        | 0.308      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.02      |\n",
      "|    explained_variance   | -1.58e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0209    |\n",
      "|    n_updates            | 1800       |\n",
      "|    policy_gradient_loss | -0.0194    |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 5.86e-06   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 56        |\n",
      "|    iterations           | 182       |\n",
      "|    time_elapsed         | 412       |\n",
      "|    total_timesteps      | 23296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3965247 |\n",
      "|    clip_fraction        | 0.31      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.976    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.361     |\n",
      "|    n_updates            | 1810      |\n",
      "|    policy_gradient_loss | 0.381     |\n",
      "|    std                  | 0.995     |\n",
      "|    value_loss           | 3.22e-08  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 56        |\n",
      "|    iterations           | 183       |\n",
      "|    time_elapsed         | 414       |\n",
      "|    total_timesteps      | 23424     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4192481 |\n",
      "|    clip_fraction        | 0.387     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.868    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.403     |\n",
      "|    n_updates            | 1820      |\n",
      "|    policy_gradient_loss | 0.443     |\n",
      "|    std                  | 0.996     |\n",
      "|    value_loss           | 1.38e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 184        |\n",
      "|    time_elapsed         | 415        |\n",
      "|    total_timesteps      | 23552      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48043942 |\n",
      "|    clip_fraction        | 0.282      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.03      |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.391      |\n",
      "|    n_updates            | 1830       |\n",
      "|    policy_gradient_loss | 0.356      |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 4.35e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 185        |\n",
      "|    time_elapsed         | 418        |\n",
      "|    total_timesteps      | 23680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.91052306 |\n",
      "|    clip_fraction        | 0.353      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.947     |\n",
      "|    explained_variance   | -7.24e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0327    |\n",
      "|    n_updates            | 1840       |\n",
      "|    policy_gradient_loss | -0.0282    |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 4.66e-06   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 56        |\n",
      "|    iterations           | 186       |\n",
      "|    time_elapsed         | 420       |\n",
      "|    total_timesteps      | 23808     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5430809 |\n",
      "|    clip_fraction        | 0.423     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.941    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.326     |\n",
      "|    n_updates            | 1850      |\n",
      "|    policy_gradient_loss | 0.392     |\n",
      "|    std                  | 0.999     |\n",
      "|    value_loss           | 3.04e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 56        |\n",
      "|    iterations           | 187       |\n",
      "|    time_elapsed         | 421       |\n",
      "|    total_timesteps      | 23936     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5553236 |\n",
      "|    clip_fraction        | 0.371     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.925    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.445     |\n",
      "|    n_updates            | 1860      |\n",
      "|    policy_gradient_loss | 0.42      |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.65e-09  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 188        |\n",
      "|    time_elapsed         | 422        |\n",
      "|    total_timesteps      | 24064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.63395566 |\n",
      "|    clip_fraction        | 0.346      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.979     |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.402      |\n",
      "|    n_updates            | 1870       |\n",
      "|    policy_gradient_loss | 0.403      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 7.38e-10   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 56        |\n",
      "|    iterations           | 189       |\n",
      "|    time_elapsed         | 425       |\n",
      "|    total_timesteps      | 24192     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9617386 |\n",
      "|    clip_fraction        | 0.337     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.966    |\n",
      "|    explained_variance   | -2.18e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0314   |\n",
      "|    n_updates            | 1880      |\n",
      "|    policy_gradient_loss | -0.0227   |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.1e-06   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 56        |\n",
      "|    iterations           | 190       |\n",
      "|    time_elapsed         | 427       |\n",
      "|    total_timesteps      | 24320     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6401445 |\n",
      "|    clip_fraction        | 0.302     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.03     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.31      |\n",
      "|    n_updates            | 1890      |\n",
      "|    policy_gradient_loss | 0.354     |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.88e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 191       |\n",
      "|    time_elapsed         | 428       |\n",
      "|    total_timesteps      | 24448     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7846434 |\n",
      "|    clip_fraction        | 0.25      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.07     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.236     |\n",
      "|    n_updates            | 1900      |\n",
      "|    policy_gradient_loss | 0.35      |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 2.4e-09   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 192        |\n",
      "|    time_elapsed         | 430        |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.68351024 |\n",
      "|    clip_fraction        | 0.299      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.999     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.442      |\n",
      "|    n_updates            | 1910       |\n",
      "|    policy_gradient_loss | 0.373      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 1.85e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 56        |\n",
      "|    iterations           | 193       |\n",
      "|    time_elapsed         | 433       |\n",
      "|    total_timesteps      | 24704     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1140721 |\n",
      "|    clip_fraction        | 0.294     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.01     |\n",
      "|    explained_variance   | -1.18e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0215   |\n",
      "|    n_updates            | 1920      |\n",
      "|    policy_gradient_loss | -0.0154   |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 3.7e-06   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 57       |\n",
      "|    iterations           | 194      |\n",
      "|    time_elapsed         | 435      |\n",
      "|    total_timesteps      | 24832    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.656644 |\n",
      "|    clip_fraction        | 0.311    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.09    |\n",
      "|    explained_variance   | 0        |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.368    |\n",
      "|    n_updates            | 1930     |\n",
      "|    policy_gradient_loss | 0.325    |\n",
      "|    std                  | 1.01     |\n",
      "|    value_loss           | 3.94e-09 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 57       |\n",
      "|    iterations           | 195      |\n",
      "|    time_elapsed         | 436      |\n",
      "|    total_timesteps      | 24960    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.814818 |\n",
      "|    clip_fraction        | 0.374    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.892   |\n",
      "|    explained_variance   | 5.96e-08 |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.193    |\n",
      "|    n_updates            | 1940     |\n",
      "|    policy_gradient_loss | 0.43     |\n",
      "|    std                  | 1.01     |\n",
      "|    value_loss           | 1.53e-09 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 196       |\n",
      "|    time_elapsed         | 438       |\n",
      "|    total_timesteps      | 25088     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6535764 |\n",
      "|    clip_fraction        | 0.359     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.917    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.465     |\n",
      "|    n_updates            | 1950      |\n",
      "|    policy_gradient_loss | 0.412     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 1.64e-10  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 56        |\n",
      "|    iterations           | 197       |\n",
      "|    time_elapsed         | 442       |\n",
      "|    total_timesteps      | 25216     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6299552 |\n",
      "|    clip_fraction        | 0.468     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.762    |\n",
      "|    explained_variance   | -5.39e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0323   |\n",
      "|    n_updates            | 1960      |\n",
      "|    policy_gradient_loss | -0.0291   |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 2.52e-06  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 198        |\n",
      "|    time_elapsed         | 444        |\n",
      "|    total_timesteps      | 25344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.64850056 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.981     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.216      |\n",
      "|    n_updates            | 1970       |\n",
      "|    policy_gradient_loss | 0.379      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 1.7e-08    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 199        |\n",
      "|    time_elapsed         | 445        |\n",
      "|    total_timesteps      | 25472      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.57667196 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.467      |\n",
      "|    n_updates            | 1980       |\n",
      "|    policy_gradient_loss | 0.344      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 2.75e-08   |\n",
      "----------------------------------------\n",
      "day: 521, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 200       |\n",
      "|    time_elapsed         | 447       |\n",
      "|    total_timesteps      | 25600     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7694656 |\n",
      "|    clip_fraction        | 0.249     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.07     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.214     |\n",
      "|    n_updates            | 1990      |\n",
      "|    policy_gradient_loss | 0.344     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 5.97e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 201       |\n",
      "|    time_elapsed         | 450       |\n",
      "|    total_timesteps      | 25728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7682879 |\n",
      "|    clip_fraction        | 0.438     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.801    |\n",
      "|    explained_variance   | -2.02e+04 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0396   |\n",
      "|    n_updates            | 2000      |\n",
      "|    policy_gradient_loss | -0.0331   |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 2.33e-06  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 202        |\n",
      "|    time_elapsed         | 452        |\n",
      "|    total_timesteps      | 25856      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49501824 |\n",
      "|    clip_fraction        | 0.37       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.946     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.421      |\n",
      "|    n_updates            | 2010       |\n",
      "|    policy_gradient_loss | 0.413      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 2.76e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 203        |\n",
      "|    time_elapsed         | 453        |\n",
      "|    total_timesteps      | 25984      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.58862543 |\n",
      "|    clip_fraction        | 0.41       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.901     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.386      |\n",
      "|    n_updates            | 2020       |\n",
      "|    policy_gradient_loss | 0.425      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 2.57e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 204        |\n",
      "|    time_elapsed         | 454        |\n",
      "|    total_timesteps      | 26112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.56267834 |\n",
      "|    clip_fraction        | 0.329      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.344      |\n",
      "|    n_updates            | 2030       |\n",
      "|    policy_gradient_loss | 0.401      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 4.08e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 205       |\n",
      "|    time_elapsed         | 458       |\n",
      "|    total_timesteps      | 26240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6168001 |\n",
      "|    clip_fraction        | 0.474     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.75     |\n",
      "|    explained_variance   | -2.85e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0278   |\n",
      "|    n_updates            | 2040      |\n",
      "|    policy_gradient_loss | -0.0244   |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 1.92e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 206       |\n",
      "|    time_elapsed         | 460       |\n",
      "|    total_timesteps      | 26368     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5407766 |\n",
      "|    clip_fraction        | 0.287     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.04     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.236     |\n",
      "|    n_updates            | 2050      |\n",
      "|    policy_gradient_loss | 0.353     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 1.28e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 207        |\n",
      "|    time_elapsed         | 461        |\n",
      "|    total_timesteps      | 26496      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.56975913 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.02      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.398      |\n",
      "|    n_updates            | 2060       |\n",
      "|    policy_gradient_loss | 0.388      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 1.15e-08   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 208       |\n",
      "|    time_elapsed         | 463       |\n",
      "|    total_timesteps      | 26624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5504507 |\n",
      "|    clip_fraction        | 0.267     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.05     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.465     |\n",
      "|    n_updates            | 2070      |\n",
      "|    policy_gradient_loss | 0.354     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 2.35e-09  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 209        |\n",
      "|    time_elapsed         | 466        |\n",
      "|    total_timesteps      | 26752      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.70430344 |\n",
      "|    clip_fraction        | 0.523      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.681     |\n",
      "|    explained_variance   | -589       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0141    |\n",
      "|    n_updates            | 2080       |\n",
      "|    policy_gradient_loss | -0.0156    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 1.5e-06    |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 210       |\n",
      "|    time_elapsed         | 468       |\n",
      "|    total_timesteps      | 26880     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4853171 |\n",
      "|    clip_fraction        | 0.2       |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.14     |\n",
      "|    explained_variance   | -2.15     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.146     |\n",
      "|    n_updates            | 2090      |\n",
      "|    policy_gradient_loss | 0.25      |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.23e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 211       |\n",
      "|    time_elapsed         | 469       |\n",
      "|    total_timesteps      | 27008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4926725 |\n",
      "|    clip_fraction        | 0.296     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1        |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.465     |\n",
      "|    n_updates            | 2100      |\n",
      "|    policy_gradient_loss | 0.379     |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.06e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 212       |\n",
      "|    time_elapsed         | 471       |\n",
      "|    total_timesteps      | 27136     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5488579 |\n",
      "|    clip_fraction        | 0.307     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.985    |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.468     |\n",
      "|    n_updates            | 2110      |\n",
      "|    policy_gradient_loss | 0.387     |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.45e-10  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 213        |\n",
      "|    time_elapsed         | 472        |\n",
      "|    total_timesteps      | 27264      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.56772786 |\n",
      "|    clip_fraction        | 0.313      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.976     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.466      |\n",
      "|    n_updates            | 2120       |\n",
      "|    policy_gradient_loss | 0.364      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 7.44e-10   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 214       |\n",
      "|    time_elapsed         | 476       |\n",
      "|    total_timesteps      | 27392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8684042 |\n",
      "|    clip_fraction        | 0.517     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.698    |\n",
      "|    explained_variance   | -1.05e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0361   |\n",
      "|    n_updates            | 2130      |\n",
      "|    policy_gradient_loss | -0.0289   |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.4e-06   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 215        |\n",
      "|    time_elapsed         | 477        |\n",
      "|    total_timesteps      | 27520      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.65590906 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.387      |\n",
      "|    n_updates            | 2140       |\n",
      "|    policy_gradient_loss | 0.343      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 2.05e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 216        |\n",
      "|    time_elapsed         | 479        |\n",
      "|    total_timesteps      | 27648      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.66171515 |\n",
      "|    clip_fraction        | 0.288      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.399      |\n",
      "|    n_updates            | 2150       |\n",
      "|    policy_gradient_loss | 0.375      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 9.84e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 217        |\n",
      "|    time_elapsed         | 480        |\n",
      "|    total_timesteps      | 27776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.57501084 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.162      |\n",
      "|    n_updates            | 2160       |\n",
      "|    policy_gradient_loss | 0.381      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 1.15e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 218       |\n",
      "|    time_elapsed         | 484       |\n",
      "|    total_timesteps      | 27904     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9506071 |\n",
      "|    clip_fraction        | 0.433     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.808    |\n",
      "|    explained_variance   | -566      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0244   |\n",
      "|    n_updates            | 2170      |\n",
      "|    policy_gradient_loss | -0.0192   |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.49e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 219       |\n",
      "|    time_elapsed         | 485       |\n",
      "|    total_timesteps      | 28032     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5832337 |\n",
      "|    clip_fraction        | 0.324     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.965    |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.468     |\n",
      "|    n_updates            | 2180      |\n",
      "|    policy_gradient_loss | 0.396     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 2.44e-09  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 220        |\n",
      "|    time_elapsed         | 487        |\n",
      "|    total_timesteps      | 28160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.68161386 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.972     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.386      |\n",
      "|    n_updates            | 2190       |\n",
      "|    policy_gradient_loss | 0.376      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 1.92e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 221        |\n",
      "|    time_elapsed         | 488        |\n",
      "|    total_timesteps      | 28288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.63812745 |\n",
      "|    clip_fraction        | 0.253      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.07      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.454      |\n",
      "|    n_updates            | 2200       |\n",
      "|    policy_gradient_loss | 0.329      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 1.94e-09   |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 57       |\n",
      "|    iterations           | 222      |\n",
      "|    time_elapsed         | 492      |\n",
      "|    total_timesteps      | 28416    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.280103 |\n",
      "|    clip_fraction        | 0.427    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.821   |\n",
      "|    explained_variance   | -955     |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | -0.0119  |\n",
      "|    n_updates            | 2210     |\n",
      "|    policy_gradient_loss | -0.0191  |\n",
      "|    std                  | 1.01     |\n",
      "|    value_loss           | 1.38e-06 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 223       |\n",
      "|    time_elapsed         | 493       |\n",
      "|    total_timesteps      | 28544     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5620362 |\n",
      "|    clip_fraction        | 0.251     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.07     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.469     |\n",
      "|    n_updates            | 2220      |\n",
      "|    policy_gradient_loss | 0.335     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 2.19e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 224        |\n",
      "|    time_elapsed         | 494        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.54357713 |\n",
      "|    clip_fraction        | 0.279      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.04      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.134      |\n",
      "|    n_updates            | 2230       |\n",
      "|    policy_gradient_loss | 0.37       |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 2.11e-08   |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 58       |\n",
      "|    iterations           | 225      |\n",
      "|    time_elapsed         | 496      |\n",
      "|    total_timesteps      | 28800    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.594316 |\n",
      "|    clip_fraction        | 0.365    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.986   |\n",
      "|    explained_variance   | 0        |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.138    |\n",
      "|    n_updates            | 2240     |\n",
      "|    policy_gradient_loss | 0.388    |\n",
      "|    std                  | 1.01     |\n",
      "|    value_loss           | 4.35e-08 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 226       |\n",
      "|    time_elapsed         | 499       |\n",
      "|    total_timesteps      | 28928     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6150743 |\n",
      "|    clip_fraction        | 0.371     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.9      |\n",
      "|    explained_variance   | -604      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.00682  |\n",
      "|    n_updates            | 2250      |\n",
      "|    policy_gradient_loss | -0.014    |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 1.32e-06  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 227        |\n",
      "|    time_elapsed         | 501        |\n",
      "|    total_timesteps      | 29056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.73910993 |\n",
      "|    clip_fraction        | 0.222      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.11      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.4        |\n",
      "|    n_updates            | 2260       |\n",
      "|    policy_gradient_loss | 0.331      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 9.32e-08   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 503         |\n",
      "|    total_timesteps      | 29184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004949847 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00644    |\n",
      "|    n_updates            | 2270        |\n",
      "|    policy_gradient_loss | -0.337      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.97e-07    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 229       |\n",
      "|    time_elapsed         | 504       |\n",
      "|    total_timesteps      | 29312     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8634894 |\n",
      "|    clip_fraction        | 0.36      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1        |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.468    |\n",
      "|    n_updates            | 2280      |\n",
      "|    policy_gradient_loss | -0.384    |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 1.48e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 230       |\n",
      "|    time_elapsed         | 508       |\n",
      "|    total_timesteps      | 29440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6564485 |\n",
      "|    clip_fraction        | 0.398     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.867    |\n",
      "|    explained_variance   | -95.6     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00105   |\n",
      "|    n_updates            | 2290      |\n",
      "|    policy_gradient_loss | 0.00614   |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 1.07e-06  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 231        |\n",
      "|    time_elapsed         | 509        |\n",
      "|    total_timesteps      | 29568      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.77273536 |\n",
      "|    clip_fraction        | 0.303      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.464      |\n",
      "|    n_updates            | 2300       |\n",
      "|    policy_gradient_loss | 0.386      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 3.99e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 232        |\n",
      "|    time_elapsed         | 511        |\n",
      "|    total_timesteps      | 29696      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.88814914 |\n",
      "|    clip_fraction        | 0.335      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.954     |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.458      |\n",
      "|    n_updates            | 2310       |\n",
      "|    policy_gradient_loss | 0.413      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 1.23e-08   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 233       |\n",
      "|    time_elapsed         | 512       |\n",
      "|    total_timesteps      | 29824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0878313 |\n",
      "|    clip_fraction        | 0.284     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.02     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.414     |\n",
      "|    n_updates            | 2320      |\n",
      "|    policy_gradient_loss | 0.395     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 6.34e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 234       |\n",
      "|    time_elapsed         | 516       |\n",
      "|    total_timesteps      | 29952     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.4569392 |\n",
      "|    clip_fraction        | 0.309     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.988    |\n",
      "|    explained_variance   | -164      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.00119  |\n",
      "|    n_updates            | 2330      |\n",
      "|    policy_gradient_loss | -0.00046  |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 1.01e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 235       |\n",
      "|    time_elapsed         | 518       |\n",
      "|    total_timesteps      | 30080     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8981521 |\n",
      "|    clip_fraction        | 0.266     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.05     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.434     |\n",
      "|    n_updates            | 2340      |\n",
      "|    policy_gradient_loss | 0.357     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 9.56e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 236       |\n",
      "|    time_elapsed         | 519       |\n",
      "|    total_timesteps      | 30208     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5346899 |\n",
      "|    clip_fraction        | 0.327     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.962    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0973    |\n",
      "|    n_updates            | 2350      |\n",
      "|    policy_gradient_loss | 0.393     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 7.75e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 237       |\n",
      "|    time_elapsed         | 521       |\n",
      "|    total_timesteps      | 30336     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9154713 |\n",
      "|    clip_fraction        | 0.354     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.924    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.468     |\n",
      "|    n_updates            | 2360      |\n",
      "|    policy_gradient_loss | 0.407     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 2.35e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 238       |\n",
      "|    time_elapsed         | 524       |\n",
      "|    total_timesteps      | 30464     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1819727 |\n",
      "|    clip_fraction        | 0.368     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.927    |\n",
      "|    explained_variance   | -249      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0126   |\n",
      "|    n_updates            | 2370      |\n",
      "|    policy_gradient_loss | -0.00827  |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 7.72e-07  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 239        |\n",
      "|    time_elapsed         | 526        |\n",
      "|    total_timesteps      | 30592      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.77687526 |\n",
      "|    clip_fraction        | 0.39       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.874     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.452      |\n",
      "|    n_updates            | 2380       |\n",
      "|    policy_gradient_loss | 0.449      |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 9.23e-10   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 240       |\n",
      "|    time_elapsed         | 527       |\n",
      "|    total_timesteps      | 30720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0123351 |\n",
      "|    clip_fraction        | 0.305     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.997    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.419     |\n",
      "|    n_updates            | 2390      |\n",
      "|    policy_gradient_loss | 0.397     |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 2.71e-09  |\n",
      "---------------------------------------\n",
      "day: 521, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 241       |\n",
      "|    time_elapsed         | 528       |\n",
      "|    total_timesteps      | 30848     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1402074 |\n",
      "|    clip_fraction        | 0.213     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.12     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.374     |\n",
      "|    n_updates            | 2400      |\n",
      "|    policy_gradient_loss | 0.31      |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 3.67e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 242       |\n",
      "|    time_elapsed         | 531       |\n",
      "|    total_timesteps      | 30976     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6469746 |\n",
      "|    clip_fraction        | 0.328     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.959    |\n",
      "|    explained_variance   | -509      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0117   |\n",
      "|    n_updates            | 2410      |\n",
      "|    policy_gradient_loss | -0.0107   |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 6.77e-07  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 243        |\n",
      "|    time_elapsed         | 532        |\n",
      "|    total_timesteps      | 31104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.91061103 |\n",
      "|    clip_fraction        | 0.334      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.949     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.441      |\n",
      "|    n_updates            | 2420       |\n",
      "|    policy_gradient_loss | 0.415      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 1.7e-08    |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 244       |\n",
      "|    time_elapsed         | 534       |\n",
      "|    total_timesteps      | 31232     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8676807 |\n",
      "|    clip_fraction        | 0.274     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.03     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.465     |\n",
      "|    n_updates            | 2430      |\n",
      "|    policy_gradient_loss | 0.365     |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.49e-10  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 245       |\n",
      "|    time_elapsed         | 535       |\n",
      "|    total_timesteps      | 31360     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9991127 |\n",
      "|    clip_fraction        | 0.371     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.895    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.455     |\n",
      "|    n_updates            | 2440      |\n",
      "|    policy_gradient_loss | 0.418     |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.92e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 246       |\n",
      "|    time_elapsed         | 538       |\n",
      "|    total_timesteps      | 31488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0603043 |\n",
      "|    clip_fraction        | 0.418     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.831    |\n",
      "|    explained_variance   | -2.44e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0284   |\n",
      "|    n_updates            | 2450      |\n",
      "|    policy_gradient_loss | -0.0232   |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.67e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 247       |\n",
      "|    time_elapsed         | 539       |\n",
      "|    total_timesteps      | 31616     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0459125 |\n",
      "|    clip_fraction        | 0.299     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.997    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.265     |\n",
      "|    n_updates            | 2460      |\n",
      "|    policy_gradient_loss | 0.391     |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.72e-10  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 248       |\n",
      "|    time_elapsed         | 541       |\n",
      "|    total_timesteps      | 31744     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1235235 |\n",
      "|    clip_fraction        | 0.286     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.02     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.254     |\n",
      "|    n_updates            | 2470      |\n",
      "|    policy_gradient_loss | 0.306     |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.73e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 249       |\n",
      "|    time_elapsed         | 542       |\n",
      "|    total_timesteps      | 31872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1091018 |\n",
      "|    clip_fraction        | 0.364     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.904    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.342    |\n",
      "|    n_updates            | 2480      |\n",
      "|    policy_gradient_loss | -0.422    |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.7e-08   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 250       |\n",
      "|    time_elapsed         | 546       |\n",
      "|    total_timesteps      | 32000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2834392 |\n",
      "|    clip_fraction        | 0.482     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.772    |\n",
      "|    explained_variance   | -168      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0772   |\n",
      "|    n_updates            | 2490      |\n",
      "|    policy_gradient_loss | -0.0678   |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.04e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 251       |\n",
      "|    time_elapsed         | 547       |\n",
      "|    total_timesteps      | 32128     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9004365 |\n",
      "|    clip_fraction        | 0.284     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.02     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.342     |\n",
      "|    n_updates            | 2500      |\n",
      "|    policy_gradient_loss | 0.387     |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.01e-07  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 58       |\n",
      "|    iterations           | 252      |\n",
      "|    time_elapsed         | 548      |\n",
      "|    total_timesteps      | 32256    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.893423 |\n",
      "|    clip_fraction        | 0.257    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.06    |\n",
      "|    explained_variance   | 0        |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.404    |\n",
      "|    n_updates            | 2510     |\n",
      "|    policy_gradient_loss | 0.33     |\n",
      "|    std                  | 1        |\n",
      "|    value_loss           | 1.92e-07 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 253       |\n",
      "|    time_elapsed         | 549       |\n",
      "|    total_timesteps      | 32384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0149485 |\n",
      "|    clip_fraction        | 0.232     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.09     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.237     |\n",
      "|    n_updates            | 2520      |\n",
      "|    policy_gradient_loss | 0.352     |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.54e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 254        |\n",
      "|    time_elapsed         | 554        |\n",
      "|    total_timesteps      | 32512      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.78166324 |\n",
      "|    clip_fraction        | 0.421      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.822     |\n",
      "|    explained_variance   | -18.3      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0402     |\n",
      "|    n_updates            | 2530       |\n",
      "|    policy_gradient_loss | 0.0636     |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 3.9e-07    |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 255       |\n",
      "|    time_elapsed         | 555       |\n",
      "|    total_timesteps      | 32640     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5592546 |\n",
      "|    clip_fraction        | 0.365     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.901    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.471     |\n",
      "|    n_updates            | 2540      |\n",
      "|    policy_gradient_loss | 0.411     |\n",
      "|    std                  | 0.999     |\n",
      "|    value_loss           | 4.34e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 256       |\n",
      "|    time_elapsed         | 557       |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8624814 |\n",
      "|    clip_fraction        | 0.312     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.977    |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.372     |\n",
      "|    n_updates            | 2550      |\n",
      "|    policy_gradient_loss | 0.391     |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.19e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 257       |\n",
      "|    time_elapsed         | 558       |\n",
      "|    total_timesteps      | 32896     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9521411 |\n",
      "|    clip_fraction        | 0.32      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.966    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.392    |\n",
      "|    n_updates            | 2560      |\n",
      "|    policy_gradient_loss | -0.414    |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.39e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 258       |\n",
      "|    time_elapsed         | 563       |\n",
      "|    total_timesteps      | 33024     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9869117 |\n",
      "|    clip_fraction        | 0.55      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.679    |\n",
      "|    explained_variance   | -18.5     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.155    |\n",
      "|    n_updates            | 2570      |\n",
      "|    policy_gradient_loss | -0.139    |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.16e-07  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 259        |\n",
      "|    time_elapsed         | 564        |\n",
      "|    total_timesteps      | 33152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48740366 |\n",
      "|    clip_fraction        | 0.197      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.14      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.097     |\n",
      "|    n_updates            | 2580       |\n",
      "|    policy_gradient_loss | -0.297     |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 1.64e-08   |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 58       |\n",
      "|    iterations           | 260      |\n",
      "|    time_elapsed         | 566      |\n",
      "|    total_timesteps      | 33280    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.014129 |\n",
      "|    clip_fraction        | 0.236    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.11    |\n",
      "|    explained_variance   | 0        |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | -0.3     |\n",
      "|    n_updates            | 2590     |\n",
      "|    policy_gradient_loss | -0.322   |\n",
      "|    std                  | 1        |\n",
      "|    value_loss           | 5.71e-08 |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 261        |\n",
      "|    time_elapsed         | 568        |\n",
      "|    total_timesteps      | 33408      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.98827136 |\n",
      "|    clip_fraction        | 0.25       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.36      |\n",
      "|    n_updates            | 2600       |\n",
      "|    policy_gradient_loss | -0.34      |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 4.63e-08   |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 58            |\n",
      "|    iterations           | 262           |\n",
      "|    time_elapsed         | 569           |\n",
      "|    total_timesteps      | 33536         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3653341e-06 |\n",
      "|    clip_fraction        | 0.173         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.17         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.000196     |\n",
      "|    n_updates            | 2610          |\n",
      "|    policy_gradient_loss | -0.174        |\n",
      "|    std                  | 0.996         |\n",
      "|    value_loss           | 1.17e-08      |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 263       |\n",
      "|    time_elapsed         | 573       |\n",
      "|    total_timesteps      | 33664     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8999911 |\n",
      "|    clip_fraction        | 0.323     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.956    |\n",
      "|    explained_variance   | -1.63e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0323   |\n",
      "|    n_updates            | 2620      |\n",
      "|    policy_gradient_loss | -0.0501   |\n",
      "|    std                  | 0.993     |\n",
      "|    value_loss           | 2.98e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 264       |\n",
      "|    time_elapsed         | 574       |\n",
      "|    total_timesteps      | 33792     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9828031 |\n",
      "|    clip_fraction        | 0.298     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.991    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.248    |\n",
      "|    n_updates            | 2630      |\n",
      "|    policy_gradient_loss | -0.39     |\n",
      "|    std                  | 0.992     |\n",
      "|    value_loss           | 2.16e-08  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 265       |\n",
      "|    time_elapsed         | 576       |\n",
      "|    total_timesteps      | 33920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8447335 |\n",
      "|    clip_fraction        | 0.366     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.894    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.458    |\n",
      "|    n_updates            | 2640      |\n",
      "|    policy_gradient_loss | -0.433    |\n",
      "|    std                  | 0.993     |\n",
      "|    value_loss           | 1.44e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 266       |\n",
      "|    time_elapsed         | 577       |\n",
      "|    total_timesteps      | 34048     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7984865 |\n",
      "|    clip_fraction        | 0.354     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.912    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.471    |\n",
      "|    n_updates            | 2650      |\n",
      "|    policy_gradient_loss | -0.425    |\n",
      "|    std                  | 0.993     |\n",
      "|    value_loss           | 5.71e-09  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 267        |\n",
      "|    time_elapsed         | 581        |\n",
      "|    total_timesteps      | 34176      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.98793155 |\n",
      "|    clip_fraction        | 0.504      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.737     |\n",
      "|    explained_variance   | -175       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0723    |\n",
      "|    n_updates            | 2660       |\n",
      "|    policy_gradient_loss | -0.062     |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 1.87e-07   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 268       |\n",
      "|    time_elapsed         | 582       |\n",
      "|    total_timesteps      | 34304     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6716171 |\n",
      "|    clip_fraction        | 0.307     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.981    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.467    |\n",
      "|    n_updates            | 2670      |\n",
      "|    policy_gradient_loss | -0.377    |\n",
      "|    std                  | 0.99      |\n",
      "|    value_loss           | 2.26e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 269       |\n",
      "|    time_elapsed         | 583       |\n",
      "|    total_timesteps      | 34432     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8340311 |\n",
      "|    clip_fraction        | 0.246     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.06     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.392     |\n",
      "|    n_updates            | 2680      |\n",
      "|    policy_gradient_loss | 0.362     |\n",
      "|    std                  | 0.987     |\n",
      "|    value_loss           | 1.44e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 270       |\n",
      "|    time_elapsed         | 584       |\n",
      "|    total_timesteps      | 34560     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7375957 |\n",
      "|    clip_fraction        | 0.28      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.01     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.467    |\n",
      "|    n_updates            | 2690      |\n",
      "|    policy_gradient_loss | -0.389    |\n",
      "|    std                  | 0.987     |\n",
      "|    value_loss           | 1.45e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 271       |\n",
      "|    time_elapsed         | 589       |\n",
      "|    total_timesteps      | 34688     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1073766 |\n",
      "|    clip_fraction        | 0.446     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.778    |\n",
      "|    explained_variance   | -2.87     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.21     |\n",
      "|    n_updates            | 2700      |\n",
      "|    policy_gradient_loss | -0.188    |\n",
      "|    std                  | 0.988     |\n",
      "|    value_loss           | 2.17e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 272       |\n",
      "|    time_elapsed         | 590       |\n",
      "|    total_timesteps      | 34816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7992867 |\n",
      "|    clip_fraction        | 0.318     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.96     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.254    |\n",
      "|    n_updates            | 2710      |\n",
      "|    policy_gradient_loss | -0.405    |\n",
      "|    std                  | 0.989     |\n",
      "|    value_loss           | 3.57e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 273       |\n",
      "|    time_elapsed         | 591       |\n",
      "|    total_timesteps      | 34944     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9013673 |\n",
      "|    clip_fraction        | 0.309     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.972    |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.234     |\n",
      "|    n_updates            | 2720      |\n",
      "|    policy_gradient_loss | 0.4       |\n",
      "|    std                  | 0.989     |\n",
      "|    value_loss           | 7.93e-05  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 274        |\n",
      "|    time_elapsed         | 592        |\n",
      "|    total_timesteps      | 35072      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.79139763 |\n",
      "|    clip_fraction        | 0.296      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.991     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.456      |\n",
      "|    n_updates            | 2730       |\n",
      "|    policy_gradient_loss | 0.39       |\n",
      "|    std                  | 0.989      |\n",
      "|    value_loss           | 1.07e-05   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 275       |\n",
      "|    time_elapsed         | 596       |\n",
      "|    total_timesteps      | 35200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2677237 |\n",
      "|    clip_fraction        | 0.459     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.772    |\n",
      "|    explained_variance   | -186      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0667   |\n",
      "|    n_updates            | 2740      |\n",
      "|    policy_gradient_loss | -0.0619   |\n",
      "|    std                  | 0.989     |\n",
      "|    value_loss           | 1.71e-07  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 276        |\n",
      "|    time_elapsed         | 597        |\n",
      "|    total_timesteps      | 35328      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.75358725 |\n",
      "|    clip_fraction        | 0.351      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.979     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.457     |\n",
      "|    n_updates            | 2750       |\n",
      "|    policy_gradient_loss | -0.404     |\n",
      "|    std                  | 0.989      |\n",
      "|    value_loss           | 1.31e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 277        |\n",
      "|    time_elapsed         | 599        |\n",
      "|    total_timesteps      | 35456      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.84472764 |\n",
      "|    clip_fraction        | 0.323      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.952     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.45      |\n",
      "|    n_updates            | 2760       |\n",
      "|    policy_gradient_loss | -0.388     |\n",
      "|    std                  | 0.987      |\n",
      "|    value_loss           | 6.62e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 278       |\n",
      "|    time_elapsed         | 600       |\n",
      "|    total_timesteps      | 35584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8588643 |\n",
      "|    clip_fraction        | 0.303     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.979    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.458     |\n",
      "|    n_updates            | 2770      |\n",
      "|    policy_gradient_loss | 0.384     |\n",
      "|    std                  | 0.986     |\n",
      "|    value_loss           | 2.74e-08  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 279       |\n",
      "|    time_elapsed         | 603       |\n",
      "|    total_timesteps      | 35712     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.5977148 |\n",
      "|    clip_fraction        | 0.368     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.887    |\n",
      "|    explained_variance   | -202      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.00154  |\n",
      "|    n_updates            | 2780      |\n",
      "|    policy_gradient_loss | -0.00172  |\n",
      "|    std                  | 0.984     |\n",
      "|    value_loss           | 4.91e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 280       |\n",
      "|    time_elapsed         | 604       |\n",
      "|    total_timesteps      | 35840     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8294645 |\n",
      "|    clip_fraction        | 0.297     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.986    |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.444     |\n",
      "|    n_updates            | 2790      |\n",
      "|    policy_gradient_loss | 0.382     |\n",
      "|    std                  | 0.983     |\n",
      "|    value_loss           | 1.66e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 281       |\n",
      "|    time_elapsed         | 606       |\n",
      "|    total_timesteps      | 35968     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7767693 |\n",
      "|    clip_fraction        | 0.301     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.981    |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.458     |\n",
      "|    n_updates            | 2800      |\n",
      "|    policy_gradient_loss | 0.404     |\n",
      "|    std                  | 0.985     |\n",
      "|    value_loss           | 1.13e-05  |\n",
      "---------------------------------------\n",
      "day: 521, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 282        |\n",
      "|    time_elapsed         | 608        |\n",
      "|    total_timesteps      | 36096      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.86415035 |\n",
      "|    clip_fraction        | 0.343      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.986     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.411     |\n",
      "|    n_updates            | 2810       |\n",
      "|    policy_gradient_loss | -0.374     |\n",
      "|    std                  | 0.986      |\n",
      "|    value_loss           | 1.49e-06   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 283       |\n",
      "|    time_elapsed         | 611       |\n",
      "|    total_timesteps      | 36224     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3341056 |\n",
      "|    clip_fraction        | 0.319     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.956    |\n",
      "|    explained_variance   | -9.89     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0935    |\n",
      "|    n_updates            | 2820      |\n",
      "|    policy_gradient_loss | 0.0706    |\n",
      "|    std                  | 0.984     |\n",
      "|    value_loss           | 3.9e-06   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 284        |\n",
      "|    time_elapsed         | 613        |\n",
      "|    total_timesteps      | 36352      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.79057086 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.366      |\n",
      "|    n_updates            | 2830       |\n",
      "|    policy_gradient_loss | 0.394      |\n",
      "|    std                  | 0.98       |\n",
      "|    value_loss           | 3.22e-06   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 285       |\n",
      "|    time_elapsed         | 615       |\n",
      "|    total_timesteps      | 36480     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7834477 |\n",
      "|    clip_fraction        | 0.293     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.992    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.411     |\n",
      "|    n_updates            | 2840      |\n",
      "|    policy_gradient_loss | 0.374     |\n",
      "|    std                  | 0.978     |\n",
      "|    value_loss           | 1.19e-07  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 286        |\n",
      "|    time_elapsed         | 616        |\n",
      "|    total_timesteps      | 36608      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.76702404 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.401      |\n",
      "|    n_updates            | 2850       |\n",
      "|    policy_gradient_loss | 0.341      |\n",
      "|    std                  | 0.979      |\n",
      "|    value_loss           | 8.11e-07   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 287       |\n",
      "|    time_elapsed         | 620       |\n",
      "|    total_timesteps      | 36736     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9560287 |\n",
      "|    clip_fraction        | 0.328     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.94     |\n",
      "|    explained_variance   | -0.837    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.19      |\n",
      "|    n_updates            | 2860      |\n",
      "|    policy_gradient_loss | 0.207     |\n",
      "|    std                  | 0.979     |\n",
      "|    value_loss           | 4.69e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 288       |\n",
      "|    time_elapsed         | 621       |\n",
      "|    total_timesteps      | 36864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6626382 |\n",
      "|    clip_fraction        | 0.299     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.98     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.373     |\n",
      "|    n_updates            | 2870      |\n",
      "|    policy_gradient_loss | 0.367     |\n",
      "|    std                  | 0.98      |\n",
      "|    value_loss           | 7.98e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 289       |\n",
      "|    time_elapsed         | 623       |\n",
      "|    total_timesteps      | 36992     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7661464 |\n",
      "|    clip_fraction        | 0.235     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.07     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.358    |\n",
      "|    n_updates            | 2880      |\n",
      "|    policy_gradient_loss | -0.309    |\n",
      "|    std                  | 0.983     |\n",
      "|    value_loss           | 2.69e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 290       |\n",
      "|    time_elapsed         | 624       |\n",
      "|    total_timesteps      | 37120     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8670008 |\n",
      "|    clip_fraction        | 0.309     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.977    |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.287    |\n",
      "|    n_updates            | 2890      |\n",
      "|    policy_gradient_loss | -0.394    |\n",
      "|    std                  | 0.986     |\n",
      "|    value_loss           | 1.65e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 291       |\n",
      "|    time_elapsed         | 627       |\n",
      "|    total_timesteps      | 37248     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6517926 |\n",
      "|    clip_fraction        | 0.337     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.932    |\n",
      "|    explained_variance   | -12.5     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.135    |\n",
      "|    n_updates            | 2900      |\n",
      "|    policy_gradient_loss | -0.116    |\n",
      "|    std                  | 0.988     |\n",
      "|    value_loss           | 5.97e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 292       |\n",
      "|    time_elapsed         | 629       |\n",
      "|    total_timesteps      | 37376     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5230057 |\n",
      "|    clip_fraction        | 0.389     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.913    |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.468    |\n",
      "|    n_updates            | 2910      |\n",
      "|    policy_gradient_loss | -0.427    |\n",
      "|    std                  | 0.989     |\n",
      "|    value_loss           | 7.46e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 293       |\n",
      "|    time_elapsed         | 630       |\n",
      "|    total_timesteps      | 37504     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6188519 |\n",
      "|    clip_fraction        | 0.346     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.923    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.464     |\n",
      "|    n_updates            | 2920      |\n",
      "|    policy_gradient_loss | 0.39      |\n",
      "|    std                  | 0.99      |\n",
      "|    value_loss           | 1.3e-07   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 294        |\n",
      "|    time_elapsed         | 631        |\n",
      "|    total_timesteps      | 37632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.70009154 |\n",
      "|    clip_fraction        | 0.365      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.9       |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.461      |\n",
      "|    n_updates            | 2930       |\n",
      "|    policy_gradient_loss | 0.419      |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 3.57e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 295       |\n",
      "|    time_elapsed         | 635       |\n",
      "|    total_timesteps      | 37760     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7285355 |\n",
      "|    clip_fraction        | 0.366     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.895    |\n",
      "|    explained_variance   | -9.37     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.101     |\n",
      "|    n_updates            | 2940      |\n",
      "|    policy_gradient_loss | 0.086     |\n",
      "|    std                  | 0.992     |\n",
      "|    value_loss           | 1.3e-07   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 296       |\n",
      "|    time_elapsed         | 636       |\n",
      "|    total_timesteps      | 37888     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7245778 |\n",
      "|    clip_fraction        | 0.223     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.1      |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.19      |\n",
      "|    n_updates            | 2950      |\n",
      "|    policy_gradient_loss | 0.319     |\n",
      "|    std                  | 0.99      |\n",
      "|    value_loss           | 2.64e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 297        |\n",
      "|    time_elapsed         | 637        |\n",
      "|    total_timesteps      | 38016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.67103565 |\n",
      "|    clip_fraction        | 0.324      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.952     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.446      |\n",
      "|    n_updates            | 2960       |\n",
      "|    policy_gradient_loss | 0.383      |\n",
      "|    std                  | 0.989      |\n",
      "|    value_loss           | 9.44e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 298        |\n",
      "|    time_elapsed         | 639        |\n",
      "|    total_timesteps      | 38144      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.78844935 |\n",
      "|    clip_fraction        | 0.346      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.92      |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.271      |\n",
      "|    n_updates            | 2970       |\n",
      "|    policy_gradient_loss | 0.405      |\n",
      "|    std                  | 0.989      |\n",
      "|    value_loss           | 1.28e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 299       |\n",
      "|    time_elapsed         | 642       |\n",
      "|    total_timesteps      | 38272     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9642831 |\n",
      "|    clip_fraction        | 0.305     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.979    |\n",
      "|    explained_variance   | -960      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0151   |\n",
      "|    n_updates            | 2980      |\n",
      "|    policy_gradient_loss | -0.0111   |\n",
      "|    std                  | 0.988     |\n",
      "|    value_loss           | 1.03e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 300       |\n",
      "|    time_elapsed         | 643       |\n",
      "|    total_timesteps      | 38400     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5571115 |\n",
      "|    clip_fraction        | 0.307     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.986    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.453     |\n",
      "|    n_updates            | 2990      |\n",
      "|    policy_gradient_loss | 0.392     |\n",
      "|    std                  | 0.988     |\n",
      "|    value_loss           | 2.22e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 301       |\n",
      "|    time_elapsed         | 645       |\n",
      "|    total_timesteps      | 38528     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5569621 |\n",
      "|    clip_fraction        | 0.31      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.972    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.472    |\n",
      "|    n_updates            | 3000      |\n",
      "|    policy_gradient_loss | -0.387    |\n",
      "|    std                  | 0.991     |\n",
      "|    value_loss           | 1e-06     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 302       |\n",
      "|    time_elapsed         | 646       |\n",
      "|    total_timesteps      | 38656     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6971529 |\n",
      "|    clip_fraction        | 0.327     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.949    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.271    |\n",
      "|    n_updates            | 3010      |\n",
      "|    policy_gradient_loss | -0.406    |\n",
      "|    std                  | 0.993     |\n",
      "|    value_loss           | 1.13e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 303       |\n",
      "|    time_elapsed         | 650       |\n",
      "|    total_timesteps      | 38784     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8133869 |\n",
      "|    clip_fraction        | 0.448     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.811    |\n",
      "|    explained_variance   | -0.26     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.287     |\n",
      "|    n_updates            | 3020      |\n",
      "|    policy_gradient_loss | 0.276     |\n",
      "|    std                  | 0.995     |\n",
      "|    value_loss           | 1.5e-05   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 304        |\n",
      "|    time_elapsed         | 651        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.57127625 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.07      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.214     |\n",
      "|    n_updates            | 3030       |\n",
      "|    policy_gradient_loss | -0.341     |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 3.01e-05   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 305       |\n",
      "|    time_elapsed         | 652       |\n",
      "|    total_timesteps      | 39040     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5250963 |\n",
      "|    clip_fraction        | 0.281     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.02     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.447    |\n",
      "|    n_updates            | 3040      |\n",
      "|    policy_gradient_loss | -0.375    |\n",
      "|    std                  | 0.995     |\n",
      "|    value_loss           | 1.94e-06  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 306        |\n",
      "|    time_elapsed         | 653        |\n",
      "|    total_timesteps      | 39168      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.53247356 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.462     |\n",
      "|    n_updates            | 3050       |\n",
      "|    policy_gradient_loss | -0.36      |\n",
      "|    std                  | 0.993      |\n",
      "|    value_loss           | 0.000297   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 307       |\n",
      "|    time_elapsed         | 657       |\n",
      "|    total_timesteps      | 39296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7863692 |\n",
      "|    clip_fraction        | 0.462     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.764    |\n",
      "|    explained_variance   | -0.143    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.269     |\n",
      "|    n_updates            | 3060      |\n",
      "|    policy_gradient_loss | 0.302     |\n",
      "|    std                  | 0.993     |\n",
      "|    value_loss           | 8.81e-05  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 308        |\n",
      "|    time_elapsed         | 659        |\n",
      "|    total_timesteps      | 39424      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36700124 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.13      |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.138      |\n",
      "|    n_updates            | 3070       |\n",
      "|    policy_gradient_loss | 0.276      |\n",
      "|    std                  | 0.993      |\n",
      "|    value_loss           | 0.000188   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 309        |\n",
      "|    time_elapsed         | 660        |\n",
      "|    total_timesteps      | 39552      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48637268 |\n",
      "|    clip_fraction        | 0.336      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.95      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.305     |\n",
      "|    n_updates            | 3080       |\n",
      "|    policy_gradient_loss | -0.421     |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 0.000274   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 310        |\n",
      "|    time_elapsed         | 661        |\n",
      "|    total_timesteps      | 39680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46343875 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.986     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.47       |\n",
      "|    n_updates            | 3090       |\n",
      "|    policy_gradient_loss | 0.399      |\n",
      "|    std                  | 0.991      |\n",
      "|    value_loss           | 5.69e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 311        |\n",
      "|    time_elapsed         | 665        |\n",
      "|    total_timesteps      | 39808      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.59232515 |\n",
      "|    clip_fraction        | 0.51       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.691     |\n",
      "|    explained_variance   | -0.148     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.322      |\n",
      "|    n_updates            | 3100       |\n",
      "|    policy_gradient_loss | 0.327      |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 6.44e-06   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 312       |\n",
      "|    time_elapsed         | 667       |\n",
      "|    total_timesteps      | 39936     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3746464 |\n",
      "|    clip_fraction        | 0.206     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.12     |\n",
      "|    explained_variance   | 8.29e-06  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.36      |\n",
      "|    n_updates            | 3110      |\n",
      "|    policy_gradient_loss | 0.297     |\n",
      "|    std                  | 0.993     |\n",
      "|    value_loss           | 3.87e-06  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 313        |\n",
      "|    time_elapsed         | 668        |\n",
      "|    total_timesteps      | 40064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42999992 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.472     |\n",
      "|    n_updates            | 3120       |\n",
      "|    policy_gradient_loss | -0.335     |\n",
      "|    std                  | 0.991      |\n",
      "|    value_loss           | 3.22e-06   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 314        |\n",
      "|    time_elapsed         | 670        |\n",
      "|    total_timesteps      | 40192      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44093585 |\n",
      "|    clip_fraction        | 0.33       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.944     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.471      |\n",
      "|    n_updates            | 3130       |\n",
      "|    policy_gradient_loss | 0.415      |\n",
      "|    std                  | 0.991      |\n",
      "|    value_loss           | 1.33e-08   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 315       |\n",
      "|    time_elapsed         | 671       |\n",
      "|    total_timesteps      | 40320     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4637959 |\n",
      "|    clip_fraction        | 0.358     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.919    |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.406     |\n",
      "|    n_updates            | 3140      |\n",
      "|    policy_gradient_loss | 0.43      |\n",
      "|    std                  | 0.992     |\n",
      "|    value_loss           | 9.62e-09  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 316       |\n",
      "|    time_elapsed         | 675       |\n",
      "|    total_timesteps      | 40448     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6250188 |\n",
      "|    clip_fraction        | 0.473     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.75     |\n",
      "|    explained_variance   | -8.19     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.116     |\n",
      "|    n_updates            | 3150      |\n",
      "|    policy_gradient_loss | 0.13      |\n",
      "|    std                  | 0.992     |\n",
      "|    value_loss           | 6.65e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 317        |\n",
      "|    time_elapsed         | 676        |\n",
      "|    total_timesteps      | 40576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36779764 |\n",
      "|    clip_fraction        | 0.294      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.191      |\n",
      "|    n_updates            | 3160       |\n",
      "|    policy_gradient_loss | 0.377      |\n",
      "|    std                  | 0.993      |\n",
      "|    value_loss           | 3.26e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 318        |\n",
      "|    time_elapsed         | 677        |\n",
      "|    total_timesteps      | 40704      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38128653 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.986     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.461      |\n",
      "|    n_updates            | 3170       |\n",
      "|    policy_gradient_loss | 0.409      |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 1.06e-08   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 319       |\n",
      "|    time_elapsed         | 679       |\n",
      "|    total_timesteps      | 40832     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3887271 |\n",
      "|    clip_fraction        | 0.319     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.961    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.468     |\n",
      "|    n_updates            | 3180      |\n",
      "|    policy_gradient_loss | 0.384     |\n",
      "|    std                  | 0.991     |\n",
      "|    value_loss           | 3.13e-09  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 320        |\n",
      "|    time_elapsed         | 683        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44237542 |\n",
      "|    clip_fraction        | 0.519      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.678     |\n",
      "|    explained_variance   | -5.83      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.123      |\n",
      "|    n_updates            | 3190       |\n",
      "|    policy_gradient_loss | 0.114      |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 6.39e-08   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 321       |\n",
      "|    time_elapsed         | 684       |\n",
      "|    total_timesteps      | 41088     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3415067 |\n",
      "|    clip_fraction        | 0.239     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.07     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.47      |\n",
      "|    n_updates            | 3200      |\n",
      "|    policy_gradient_loss | 0.31      |\n",
      "|    std                  | 0.988     |\n",
      "|    value_loss           | 5.72e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 322        |\n",
      "|    time_elapsed         | 685        |\n",
      "|    total_timesteps      | 41216      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36804196 |\n",
      "|    clip_fraction        | 0.382      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.87      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.468      |\n",
      "|    n_updates            | 3210       |\n",
      "|    policy_gradient_loss | 0.432      |\n",
      "|    std                  | 0.989      |\n",
      "|    value_loss           | 1.06e-08   |\n",
      "----------------------------------------\n",
      "day: 521, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 323        |\n",
      "|    time_elapsed         | 687        |\n",
      "|    total_timesteps      | 41344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34694964 |\n",
      "|    clip_fraction        | 0.272      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.08      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.462      |\n",
      "|    n_updates            | 3220       |\n",
      "|    policy_gradient_loss | 0.31       |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 6.21e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 324        |\n",
      "|    time_elapsed         | 691        |\n",
      "|    total_timesteps      | 41472      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46356636 |\n",
      "|    clip_fraction        | 0.513      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.687     |\n",
      "|    explained_variance   | -30.1      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0449     |\n",
      "|    n_updates            | 3230       |\n",
      "|    policy_gradient_loss | 0.0424     |\n",
      "|    std                  | 0.991      |\n",
      "|    value_loss           | 3.98e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 325        |\n",
      "|    time_elapsed         | 692        |\n",
      "|    total_timesteps      | 41600      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29352596 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.04      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.408      |\n",
      "|    n_updates            | 3240       |\n",
      "|    policy_gradient_loss | 0.363      |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 3.16e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 326        |\n",
      "|    time_elapsed         | 694        |\n",
      "|    total_timesteps      | 41728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31810632 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.466      |\n",
      "|    n_updates            | 3250       |\n",
      "|    policy_gradient_loss | 0.358      |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 5.97e-10   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 327        |\n",
      "|    time_elapsed         | 695        |\n",
      "|    total_timesteps      | 41856      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33499432 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.988     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.451      |\n",
      "|    n_updates            | 3260       |\n",
      "|    policy_gradient_loss | 0.377      |\n",
      "|    std                  | 0.988      |\n",
      "|    value_loss           | 4.02e-10   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 328        |\n",
      "|    time_elapsed         | 699        |\n",
      "|    total_timesteps      | 41984      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43466693 |\n",
      "|    clip_fraction        | 0.463      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.764     |\n",
      "|    explained_variance   | -35.8      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0299     |\n",
      "|    n_updates            | 3270       |\n",
      "|    policy_gradient_loss | 0.0362     |\n",
      "|    std                  | 0.987      |\n",
      "|    value_loss           | 3.96e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 329        |\n",
      "|    time_elapsed         | 700        |\n",
      "|    total_timesteps      | 42112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28613365 |\n",
      "|    clip_fraction        | 0.314      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.964     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.464      |\n",
      "|    n_updates            | 3280       |\n",
      "|    policy_gradient_loss | 0.405      |\n",
      "|    std                  | 0.987      |\n",
      "|    value_loss           | 1.37e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 330       |\n",
      "|    time_elapsed         | 702       |\n",
      "|    total_timesteps      | 42240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3541858 |\n",
      "|    clip_fraction        | 0.386     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.963    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.437     |\n",
      "|    n_updates            | 3290      |\n",
      "|    policy_gradient_loss | 0.382     |\n",
      "|    std                  | 0.987     |\n",
      "|    value_loss           | 1.68e-09  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 331        |\n",
      "|    time_elapsed         | 703        |\n",
      "|    total_timesteps      | 42368      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37356204 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.217      |\n",
      "|    n_updates            | 3300       |\n",
      "|    policy_gradient_loss | 0.383      |\n",
      "|    std                  | 0.987      |\n",
      "|    value_loss           | 1.29e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 332       |\n",
      "|    time_elapsed         | 707       |\n",
      "|    total_timesteps      | 42496     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5889615 |\n",
      "|    clip_fraction        | 0.416     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.832    |\n",
      "|    explained_variance   | -59       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0216    |\n",
      "|    n_updates            | 3310      |\n",
      "|    policy_gradient_loss | 0.0211    |\n",
      "|    std                  | 0.987     |\n",
      "|    value_loss           | 3.9e-08   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 333        |\n",
      "|    time_elapsed         | 709        |\n",
      "|    total_timesteps      | 42624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37449718 |\n",
      "|    clip_fraction        | 0.379      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.879     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.472      |\n",
      "|    n_updates            | 3320       |\n",
      "|    policy_gradient_loss | 0.424      |\n",
      "|    std                  | 0.986      |\n",
      "|    value_loss           | 7.33e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 334       |\n",
      "|    time_elapsed         | 710       |\n",
      "|    total_timesteps      | 42752     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2756722 |\n",
      "|    clip_fraction        | 0.284     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.01     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.136     |\n",
      "|    n_updates            | 3330      |\n",
      "|    policy_gradient_loss | 0.371     |\n",
      "|    std                  | 0.986     |\n",
      "|    value_loss           | 2.84e-10  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 335        |\n",
      "|    time_elapsed         | 713        |\n",
      "|    total_timesteps      | 42880      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41884482 |\n",
      "|    clip_fraction        | 0.343      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.923     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.331      |\n",
      "|    n_updates            | 3340       |\n",
      "|    policy_gradient_loss | 0.424      |\n",
      "|    std                  | 0.987      |\n",
      "|    value_loss           | 2.09e-10   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 336       |\n",
      "|    time_elapsed         | 716       |\n",
      "|    total_timesteps      | 43008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6608801 |\n",
      "|    clip_fraction        | 0.302     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.983    |\n",
      "|    explained_variance   | -44.9     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0304    |\n",
      "|    n_updates            | 3350      |\n",
      "|    policy_gradient_loss | 0.0249    |\n",
      "|    std                  | 0.989     |\n",
      "|    value_loss           | 3.79e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 337        |\n",
      "|    time_elapsed         | 717        |\n",
      "|    total_timesteps      | 43136      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40796074 |\n",
      "|    clip_fraction        | 0.364      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.958     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.186      |\n",
      "|    n_updates            | 3360       |\n",
      "|    policy_gradient_loss | 0.392      |\n",
      "|    std                  | 0.989      |\n",
      "|    value_loss           | 3.68e-10   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 338        |\n",
      "|    time_elapsed         | 718        |\n",
      "|    total_timesteps      | 43264      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10453337 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.09      |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0561     |\n",
      "|    n_updates            | 3370       |\n",
      "|    policy_gradient_loss | 0.33       |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 1.63e-10   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 339       |\n",
      "|    time_elapsed         | 720       |\n",
      "|    total_timesteps      | 43392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4479579 |\n",
      "|    clip_fraction        | 0.286     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.01     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.329     |\n",
      "|    n_updates            | 3380      |\n",
      "|    policy_gradient_loss | 0.382     |\n",
      "|    std                  | 0.991     |\n",
      "|    value_loss           | 7.37e-10  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 340        |\n",
      "|    time_elapsed         | 723        |\n",
      "|    total_timesteps      | 43520      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.55022967 |\n",
      "|    clip_fraction        | 0.333      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.942     |\n",
      "|    explained_variance   | -56.4      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0155     |\n",
      "|    n_updates            | 3390       |\n",
      "|    policy_gradient_loss | 0.0234     |\n",
      "|    std                  | 0.994      |\n",
      "|    value_loss           | 3.23e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 341        |\n",
      "|    time_elapsed         | 725        |\n",
      "|    total_timesteps      | 43648      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36238724 |\n",
      "|    clip_fraction        | 0.344      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.927     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.449      |\n",
      "|    n_updates            | 3400       |\n",
      "|    policy_gradient_loss | 0.426      |\n",
      "|    std                  | 0.996      |\n",
      "|    value_loss           | 3.41e-10   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 342        |\n",
      "|    time_elapsed         | 726        |\n",
      "|    total_timesteps      | 43776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39094788 |\n",
      "|    clip_fraction        | 0.303      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.327      |\n",
      "|    n_updates            | 3410       |\n",
      "|    policy_gradient_loss | 0.333      |\n",
      "|    std                  | 0.996      |\n",
      "|    value_loss           | 1.53e-10   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 343        |\n",
      "|    time_elapsed         | 728        |\n",
      "|    total_timesteps      | 43904      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36831903 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.1       |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.193      |\n",
      "|    n_updates            | 3420       |\n",
      "|    policy_gradient_loss | 0.302      |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 2.26e-10   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 344        |\n",
      "|    time_elapsed         | 732        |\n",
      "|    total_timesteps      | 44032      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.52191496 |\n",
      "|    clip_fraction        | 0.375      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.909     |\n",
      "|    explained_variance   | -256       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0135    |\n",
      "|    n_updates            | 3430       |\n",
      "|    policy_gradient_loss | -0.00547   |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 2.87e-08   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 345          |\n",
      "|    time_elapsed         | 733          |\n",
      "|    total_timesteps      | 44160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057487655 |\n",
      "|    clip_fraction        | 0.268        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0109      |\n",
      "|    n_updates            | 3440         |\n",
      "|    policy_gradient_loss | 0.327        |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 8.99e-10     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 346        |\n",
      "|    time_elapsed         | 735        |\n",
      "|    total_timesteps      | 44288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29592016 |\n",
      "|    clip_fraction        | 0.324      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.991     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.387     |\n",
      "|    n_updates            | 3450       |\n",
      "|    policy_gradient_loss | -0.387     |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 2.48e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 347        |\n",
      "|    time_elapsed         | 737        |\n",
      "|    total_timesteps      | 44416      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31509545 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.08      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.238     |\n",
      "|    n_updates            | 3460       |\n",
      "|    policy_gradient_loss | -0.207     |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 4.08e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 348       |\n",
      "|    time_elapsed         | 740       |\n",
      "|    total_timesteps      | 44544     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5063339 |\n",
      "|    clip_fraction        | 0.407     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.86     |\n",
      "|    explained_variance   | -2.33e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0149   |\n",
      "|    n_updates            | 3470      |\n",
      "|    policy_gradient_loss | -0.0155   |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.44e-08  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 349       |\n",
      "|    time_elapsed         | 742       |\n",
      "|    total_timesteps      | 44672     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3094102 |\n",
      "|    clip_fraction        | 0.322     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.979    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.435     |\n",
      "|    n_updates            | 3480      |\n",
      "|    policy_gradient_loss | 0.372     |\n",
      "|    std                  | 0.998     |\n",
      "|    value_loss           | 1.52e-10  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 350       |\n",
      "|    time_elapsed         | 744       |\n",
      "|    total_timesteps      | 44800     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3847473 |\n",
      "|    clip_fraction        | 0.352     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.925    |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.327    |\n",
      "|    n_updates            | 3490      |\n",
      "|    policy_gradient_loss | -0.382    |\n",
      "|    std                  | 0.998     |\n",
      "|    value_loss           | 4.93e-11  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 351       |\n",
      "|    time_elapsed         | 745       |\n",
      "|    total_timesteps      | 44928     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3839739 |\n",
      "|    clip_fraction        | 0.302     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.989    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.443     |\n",
      "|    n_updates            | 3500      |\n",
      "|    policy_gradient_loss | 0.35      |\n",
      "|    std                  | 0.998     |\n",
      "|    value_loss           | 2.39e-12  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 352        |\n",
      "|    time_elapsed         | 749        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43068358 |\n",
      "|    clip_fraction        | 0.361      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.906     |\n",
      "|    explained_variance   | -8.37e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0246    |\n",
      "|    n_updates            | 3510       |\n",
      "|    policy_gradient_loss | -0.0174    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 2.14e-08   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 750         |\n",
      "|    total_timesteps      | 45184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008172968 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.994      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0185     |\n",
      "|    n_updates            | 3520        |\n",
      "|    policy_gradient_loss | 0.36        |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 1.72e-12    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 354        |\n",
      "|    time_elapsed         | 752        |\n",
      "|    total_timesteps      | 45312      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43027332 |\n",
      "|    clip_fraction        | 0.34       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.964     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.451      |\n",
      "|    n_updates            | 3530       |\n",
      "|    policy_gradient_loss | 0.387      |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 3.36e-12   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 355        |\n",
      "|    time_elapsed         | 753        |\n",
      "|    total_timesteps      | 45440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44055927 |\n",
      "|    clip_fraction        | 0.322      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.962     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.389      |\n",
      "|    n_updates            | 3540       |\n",
      "|    policy_gradient_loss | 0.394      |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 6.25e-12   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 356       |\n",
      "|    time_elapsed         | 758       |\n",
      "|    total_timesteps      | 45568     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5091808 |\n",
      "|    clip_fraction        | 0.514     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.73     |\n",
      "|    explained_variance   | -4.24e+03 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0248   |\n",
      "|    n_updates            | 3550      |\n",
      "|    policy_gradient_loss | -0.0213   |\n",
      "|    std                  | 0.998     |\n",
      "|    value_loss           | 1.47e-08  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 357        |\n",
      "|    time_elapsed         | 759        |\n",
      "|    total_timesteps      | 45696      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29524586 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.324      |\n",
      "|    n_updates            | 3560       |\n",
      "|    policy_gradient_loss | 0.338      |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 3.56e-10   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 358       |\n",
      "|    time_elapsed         | 760       |\n",
      "|    total_timesteps      | 45824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3202817 |\n",
      "|    clip_fraction        | 0.308     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.981    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.426    |\n",
      "|    n_updates            | 3570      |\n",
      "|    policy_gradient_loss | -0.406    |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.56e-09  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 359        |\n",
      "|    time_elapsed         | 762        |\n",
      "|    total_timesteps      | 45952      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33245072 |\n",
      "|    clip_fraction        | 0.361      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.907     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.457     |\n",
      "|    n_updates            | 3580       |\n",
      "|    policy_gradient_loss | -0.432     |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 5.49e-10   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 360       |\n",
      "|    time_elapsed         | 766       |\n",
      "|    total_timesteps      | 46080     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4090179 |\n",
      "|    clip_fraction        | 0.516     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.712    |\n",
      "|    explained_variance   | -114      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.076    |\n",
      "|    n_updates            | 3590      |\n",
      "|    policy_gradient_loss | -0.0675   |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.27e-08  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 361       |\n",
      "|    time_elapsed         | 768       |\n",
      "|    total_timesteps      | 46208     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2280317 |\n",
      "|    clip_fraction        | 0.314     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.984    |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.34     |\n",
      "|    n_updates            | 3600      |\n",
      "|    policy_gradient_loss | -0.386    |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.91e-10  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 362       |\n",
      "|    time_elapsed         | 769       |\n",
      "|    total_timesteps      | 46336     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3010364 |\n",
      "|    clip_fraction        | 0.365     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.903    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.421     |\n",
      "|    n_updates            | 3610      |\n",
      "|    policy_gradient_loss | 0.42      |\n",
      "|    std                  | 0.997     |\n",
      "|    value_loss           | 1.62e-09  |\n",
      "---------------------------------------\n",
      "day: 521, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999999.76\n",
      "total_reward: -0.24\n",
      "total_cost: 0.05\n",
      "total_trades: 2\n",
      "Sharpe: -0.779\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 363        |\n",
      "|    time_elapsed         | 770        |\n",
      "|    total_timesteps      | 46464      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35099933 |\n",
      "|    clip_fraction        | 0.388      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.935     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.287      |\n",
      "|    n_updates            | 3620       |\n",
      "|    policy_gradient_loss | 0.248      |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 1.93e-10   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 364        |\n",
      "|    time_elapsed         | 774        |\n",
      "|    total_timesteps      | 46592      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40184197 |\n",
      "|    clip_fraction        | 0.543      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.648     |\n",
      "|    explained_variance   | -1.94e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0136    |\n",
      "|    n_updates            | 3630       |\n",
      "|    policy_gradient_loss | -0.013     |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 1.03e-08   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 365        |\n",
      "|    time_elapsed         | 776        |\n",
      "|    total_timesteps      | 46720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30689198 |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.989     |\n",
      "|    explained_variance   | -0.00413   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.4        |\n",
      "|    n_updates            | 3640       |\n",
      "|    policy_gradient_loss | 0.381      |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 2.52e-11   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 366         |\n",
      "|    time_elapsed         | 777         |\n",
      "|    total_timesteps      | 46848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.082984515 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.976      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0552      |\n",
      "|    n_updates            | 3650        |\n",
      "|    policy_gradient_loss | 0.36        |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 1.32e-10    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 367        |\n",
      "|    time_elapsed         | 779        |\n",
      "|    total_timesteps      | 46976      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33995974 |\n",
      "|    clip_fraction        | 0.36       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.905     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.46      |\n",
      "|    n_updates            | 3660       |\n",
      "|    policy_gradient_loss | -0.415     |\n",
      "|    std                  | 0.994      |\n",
      "|    value_loss           | 1.05e-10   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 368        |\n",
      "|    time_elapsed         | 780        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34414485 |\n",
      "|    clip_fraction        | 0.303      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.987     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.438     |\n",
      "|    n_updates            | 3670       |\n",
      "|    policy_gradient_loss | -0.347     |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 8.69e-11   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 369        |\n",
      "|    time_elapsed         | 785        |\n",
      "|    total_timesteps      | 47232      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40141895 |\n",
      "|    clip_fraction        | 0.587      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.583     |\n",
      "|    explained_variance   | -2.57e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.026     |\n",
      "|    n_updates            | 3680       |\n",
      "|    policy_gradient_loss | -0.0252    |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 8.21e-09   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 370       |\n",
      "|    time_elapsed         | 786       |\n",
      "|    total_timesteps      | 47360     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3049496 |\n",
      "|    clip_fraction        | 0.316     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.964    |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.412     |\n",
      "|    n_updates            | 3690      |\n",
      "|    policy_gradient_loss | 0.351     |\n",
      "|    std                  | 0.988     |\n",
      "|    value_loss           | 5.8e-12   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 371        |\n",
      "|    time_elapsed         | 787        |\n",
      "|    total_timesteps      | 47488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33416706 |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.982     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.408      |\n",
      "|    n_updates            | 3700       |\n",
      "|    policy_gradient_loss | 0.375      |\n",
      "|    std                  | 0.987      |\n",
      "|    value_loss           | 3.67e-12   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 372       |\n",
      "|    time_elapsed         | 789       |\n",
      "|    total_timesteps      | 47616     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3834796 |\n",
      "|    clip_fraction        | 0.338     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.02     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.457    |\n",
      "|    n_updates            | 3710      |\n",
      "|    policy_gradient_loss | -0.338    |\n",
      "|    std                  | 0.986     |\n",
      "|    value_loss           | 4.32e-11  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 373        |\n",
      "|    time_elapsed         | 793        |\n",
      "|    total_timesteps      | 47744      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.58429575 |\n",
      "|    clip_fraction        | 0.449      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.779     |\n",
      "|    explained_variance   | -2.71e+03  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0165    |\n",
      "|    n_updates            | 3720       |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 9.87e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 374        |\n",
      "|    time_elapsed         | 794        |\n",
      "|    total_timesteps      | 47872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37673903 |\n",
      "|    clip_fraction        | 0.356      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.912     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.375      |\n",
      "|    n_updates            | 3730       |\n",
      "|    policy_gradient_loss | 0.399      |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 3.51e-11   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 375        |\n",
      "|    time_elapsed         | 795        |\n",
      "|    total_timesteps      | 48000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42263043 |\n",
      "|    clip_fraction        | 0.314      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.961     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.357     |\n",
      "|    n_updates            | 3740       |\n",
      "|    policy_gradient_loss | -0.383     |\n",
      "|    std                  | 0.983      |\n",
      "|    value_loss           | 2.21e-10   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 376        |\n",
      "|    time_elapsed         | 796        |\n",
      "|    total_timesteps      | 48128      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42761675 |\n",
      "|    clip_fraction        | 0.276      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.368     |\n",
      "|    n_updates            | 3750       |\n",
      "|    policy_gradient_loss | -0.35      |\n",
      "|    std                  | 0.982      |\n",
      "|    value_loss           | 3.11e-10   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 377       |\n",
      "|    time_elapsed         | 800       |\n",
      "|    total_timesteps      | 48256     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6639662 |\n",
      "|    clip_fraction        | 0.37      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.883    |\n",
      "|    explained_variance   | -445      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0257   |\n",
      "|    n_updates            | 3760      |\n",
      "|    policy_gradient_loss | -0.0273   |\n",
      "|    std                  | 0.983     |\n",
      "|    value_loss           | 9.83e-09  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 378        |\n",
      "|    time_elapsed         | 801        |\n",
      "|    total_timesteps      | 48384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38205528 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.997     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.422     |\n",
      "|    n_updates            | 3770       |\n",
      "|    policy_gradient_loss | -0.358     |\n",
      "|    std                  | 0.985      |\n",
      "|    value_loss           | 7.01e-10   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 379        |\n",
      "|    time_elapsed         | 802        |\n",
      "|    total_timesteps      | 48512      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41196725 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.401      |\n",
      "|    n_updates            | 3780       |\n",
      "|    policy_gradient_loss | 0.366      |\n",
      "|    std                  | 0.982      |\n",
      "|    value_loss           | 2.36e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 380        |\n",
      "|    time_elapsed         | 803        |\n",
      "|    total_timesteps      | 48640      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39356244 |\n",
      "|    clip_fraction        | 0.332      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.938     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.467     |\n",
      "|    n_updates            | 3790       |\n",
      "|    policy_gradient_loss | -0.397     |\n",
      "|    std                  | 0.978      |\n",
      "|    value_loss           | 1.03e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 381        |\n",
      "|    time_elapsed         | 807        |\n",
      "|    total_timesteps      | 48768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.60330963 |\n",
      "|    clip_fraction        | 0.456      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.759     |\n",
      "|    explained_variance   | -385       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0303    |\n",
      "|    n_updates            | 3800       |\n",
      "|    policy_gradient_loss | -0.032     |\n",
      "|    std                  | 0.977      |\n",
      "|    value_loss           | 7.98e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 382        |\n",
      "|    time_elapsed         | 808        |\n",
      "|    total_timesteps      | 48896      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36943823 |\n",
      "|    clip_fraction        | 0.359      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.894     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.471     |\n",
      "|    n_updates            | 3810       |\n",
      "|    policy_gradient_loss | -0.415     |\n",
      "|    std                  | 0.976      |\n",
      "|    value_loss           | 6.91e-11   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 383        |\n",
      "|    time_elapsed         | 810        |\n",
      "|    total_timesteps      | 49024      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37278152 |\n",
      "|    clip_fraction        | 0.314      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.968     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.467     |\n",
      "|    n_updates            | 3820       |\n",
      "|    policy_gradient_loss | -0.399     |\n",
      "|    std                  | 0.976      |\n",
      "|    value_loss           | 3.48e-11   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 384        |\n",
      "|    time_elapsed         | 811        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35919914 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.412     |\n",
      "|    n_updates            | 3830       |\n",
      "|    policy_gradient_loss | -0.352     |\n",
      "|    std                  | 0.973      |\n",
      "|    value_loss           | 1.67e-11   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 385        |\n",
      "|    time_elapsed         | 815        |\n",
      "|    total_timesteps      | 49280      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42600113 |\n",
      "|    clip_fraction        | 0.353      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.973     |\n",
      "|    explained_variance   | -246       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0521    |\n",
      "|    n_updates            | 3840       |\n",
      "|    policy_gradient_loss | -0.0363    |\n",
      "|    std                  | 0.97       |\n",
      "|    value_loss           | 8.78e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 386        |\n",
      "|    time_elapsed         | 816        |\n",
      "|    total_timesteps      | 49408      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28649458 |\n",
      "|    clip_fraction        | 0.337      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.923     |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.444     |\n",
      "|    n_updates            | 3850       |\n",
      "|    policy_gradient_loss | -0.403     |\n",
      "|    std                  | 0.969      |\n",
      "|    value_loss           | 6.9e-12    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 387        |\n",
      "|    time_elapsed         | 817        |\n",
      "|    total_timesteps      | 49536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27231425 |\n",
      "|    clip_fraction        | 0.326      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.935     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.373     |\n",
      "|    n_updates            | 3860       |\n",
      "|    policy_gradient_loss | -0.405     |\n",
      "|    std                  | 0.967      |\n",
      "|    value_loss           | 2.86e-11   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 388       |\n",
      "|    time_elapsed         | 819       |\n",
      "|    total_timesteps      | 49664     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2895539 |\n",
      "|    clip_fraction        | 0.315     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.948    |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.452     |\n",
      "|    n_updates            | 3870      |\n",
      "|    policy_gradient_loss | 0.382     |\n",
      "|    std                  | 0.966     |\n",
      "|    value_loss           | 2.12e-11  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 389        |\n",
      "|    time_elapsed         | 822        |\n",
      "|    total_timesteps      | 49792      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.50697726 |\n",
      "|    clip_fraction        | 0.357      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.916     |\n",
      "|    explained_variance   | -260       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0113    |\n",
      "|    n_updates            | 3880       |\n",
      "|    policy_gradient_loss | -0.00561   |\n",
      "|    std                  | 0.966      |\n",
      "|    value_loss           | 7.49e-09   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 390        |\n",
      "|    time_elapsed         | 823        |\n",
      "|    total_timesteps      | 49920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26360092 |\n",
      "|    clip_fraction        | 0.311      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.955     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.238      |\n",
      "|    n_updates            | 3890       |\n",
      "|    policy_gradient_loss | 0.377      |\n",
      "|    std                  | 0.969      |\n",
      "|    value_loss           | 7e-13      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 391        |\n",
      "|    time_elapsed         | 824        |\n",
      "|    total_timesteps      | 50048      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28797945 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.09      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.335     |\n",
      "|    n_updates            | 3900       |\n",
      "|    policy_gradient_loss | -0.218     |\n",
      "|    std                  | 0.971      |\n",
      "|    value_loss           | 2.62e-09   |\n",
      "----------------------------------------\n",
      "day: 521, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "day: 521, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "model = RecurrentPPO(\"MlpLstmPolicy\", env=env_train, verbose=1)\n",
    "model.learn(50000)\n",
    "model_version = '50000_iter_'\n",
    "model_name = 'recurrent_ppo'\n",
    "\n",
    "env = model.get_env()\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=20, warn=False)\n",
    "print(mean_reward)\n",
    "\n",
    "model.save(os.path.join(config.TRAINED_MODEL_DIR, model_version + model_name  + \".pth\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "f2wZgkQXh1jE"
   },
   "source": [
    "# Trading\n",
    "Assume that we have $1,000,000 initial capital at 2020-07-01. We use the DDPG model to trade Dow jones 30 stocks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "bEv5KGC8h1jE"
   },
   "source": [
    "### Set turbulence threshold\n",
    "Set the turbulence threshold to be greater than the maximum of insample turbulence data, if current turbulence index is greater than the threshold, then we assume that the current market is volatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "efwBi84ch1jE"
   },
   "outputs": [],
   "source": [
    "data_risk_indicator = processed_full[(processed_full.date<trade_end_date) & (processed_full.date> train_end_date)]\n",
    "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "VHZMBpSqh1jG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    250.000000\n",
       "mean      25.639720\n",
       "std        4.216336\n",
       "min       16.600000\n",
       "25%       22.230000\n",
       "50%       25.505000\n",
       "75%       28.930001\n",
       "max       36.450001\n",
       "Name: vix, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "BDkszkMloRWT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.13528106689452"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.quantile(0.996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "AL7hs7svnNWT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    250.000000\n",
       "mean      10.574578\n",
       "std       12.101466\n",
       "min        0.451542\n",
       "25%        4.143907\n",
       "50%        7.096417\n",
       "75%       13.162082\n",
       "max       89.601229\n",
       "Name: turbulence, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "N78hfHckoqJ9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.29403926590331"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.quantile(0.996)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "U5mmgQF_h1jQ"
   },
   "source": [
    "### Trade\n",
    "\n",
    "DRL model needs to update periodically in order to take full advantage of the data, ideally we need to retrain our model yearly, quarterly, or monthly. We also need to tune the parameters along the way, in this notebook I only use the in-sample data from 2009-01 to 2020-07 to tune the parameters once, so there is some alpha decay here as the length of trade date extends. \n",
    "\n",
    "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "cIqoV0GSI52v"
   },
   "outputs": [],
   "source": [
    "#trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70, risk_indicator_col='vix', **env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "W_XNgGsBMeVw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>adj close</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>macd</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>AUDUSD=X</td>\n",
       "      <td>0.726818</td>\n",
       "      <td>0.726818</td>\n",
       "      <td>0.727908</td>\n",
       "      <td>0.718590</td>\n",
       "      <td>0.726850</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>51.288051</td>\n",
       "      <td>104.966545</td>\n",
       "      <td>3.520604</td>\n",
       "      <td>0.716629</td>\n",
       "      <td>0.728673</td>\n",
       "      <td>16.6</td>\n",
       "      <td>6.664439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>EURUSD=X</td>\n",
       "      <td>1.137346</td>\n",
       "      <td>1.137346</td>\n",
       "      <td>1.137592</td>\n",
       "      <td>1.128541</td>\n",
       "      <td>1.137385</td>\n",
       "      <td>-0.000456</td>\n",
       "      <td>47.814245</td>\n",
       "      <td>122.620797</td>\n",
       "      <td>9.183568</td>\n",
       "      <td>1.129750</td>\n",
       "      <td>1.141925</td>\n",
       "      <td>16.6</td>\n",
       "      <td>6.664439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>GBPUSD=X</td>\n",
       "      <td>1.352228</td>\n",
       "      <td>1.352228</td>\n",
       "      <td>1.353180</td>\n",
       "      <td>1.343274</td>\n",
       "      <td>1.352228</td>\n",
       "      <td>0.003050</td>\n",
       "      <td>53.283006</td>\n",
       "      <td>154.852691</td>\n",
       "      <td>21.800040</td>\n",
       "      <td>1.332292</td>\n",
       "      <td>1.346930</td>\n",
       "      <td>16.6</td>\n",
       "      <td>6.664439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>USDCAD=X</td>\n",
       "      <td>1.265880</td>\n",
       "      <td>1.265880</td>\n",
       "      <td>1.277810</td>\n",
       "      <td>1.264400</td>\n",
       "      <td>1.265710</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>48.905144</td>\n",
       "      <td>-87.188526</td>\n",
       "      <td>9.888084</td>\n",
       "      <td>1.277323</td>\n",
       "      <td>1.260846</td>\n",
       "      <td>16.6</td>\n",
       "      <td>6.664439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>USDCHF=X</td>\n",
       "      <td>0.911975</td>\n",
       "      <td>0.911975</td>\n",
       "      <td>0.919910</td>\n",
       "      <td>0.911500</td>\n",
       "      <td>0.912030</td>\n",
       "      <td>-0.002360</td>\n",
       "      <td>43.914787</td>\n",
       "      <td>-136.171788</td>\n",
       "      <td>14.666355</td>\n",
       "      <td>0.922099</td>\n",
       "      <td>0.921011</td>\n",
       "      <td>16.6</td>\n",
       "      <td>6.664439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       tic  adj close     close      high       low      open  \\\n",
       "0  2022-01-03  AUDUSD=X   0.726818  0.726818  0.727908  0.718590  0.726850   \n",
       "0  2022-01-03  EURUSD=X   1.137346  1.137346  1.137592  1.128541  1.137385   \n",
       "0  2022-01-03  GBPUSD=X   1.352228  1.352228  1.353180  1.343274  1.352228   \n",
       "0  2022-01-03  USDCAD=X   1.265880  1.265880  1.277810  1.264400  1.265710   \n",
       "0  2022-01-03  USDCHF=X   0.911975  0.911975  0.919910  0.911500  0.912030   \n",
       "\n",
       "       macd     rsi_30      cci_30      dx_30  close_30_sma  close_60_sma  \\\n",
       "0  0.001099  51.288051  104.966545   3.520604      0.716629      0.728673   \n",
       "0 -0.000456  47.814245  122.620797   9.183568      1.129750      1.141925   \n",
       "0  0.003050  53.283006  154.852691  21.800040      1.332292      1.346930   \n",
       "0  0.002133  48.905144  -87.188526   9.888084      1.277323      1.260846   \n",
       "0 -0.002360  43.914787 -136.171788  14.666355      0.922099      0.921011   \n",
       "\n",
       "    vix  turbulence  \n",
       "0  16.6    6.664439  \n",
       "0  16.6    6.664439  \n",
       "0  16.6    6.664439  \n",
       "0  16.6    6.664439  \n",
       "0  16.6    6.664439  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load model /mnt/f/financial_projects/Deep Reinforcement Learning Approaches on Stock Prediction/FinRL/MARKETS/ForexMarket/TRAINED_MODEL_DIR/td3_.pth\n"
     ]
    }
   ],
   "source": [
    "model_name = 'td3_.pth'\n",
    "train_model_path = os.path.join(config.TRAINED_MODEL_DIR, model_name)\n",
    "trained_ddpg = DRLAgent.DRL_load_from_file(model_name = 'td3' ,\n",
    "    cwd=train_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "eLOnL5eYh1jR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_ddpg, \n",
    "    environment=e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "nFlK5hNbWVFk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "action_value_df = pd.merge(df_actions, df_account_value,on='date')\n",
    "action_value_df.to_csv(os.path.join(config.RESULTS_DIR,'td3_actions_account_value.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUDUSD=X</th>\n",
       "      <th>EURUSD=X</th>\n",
       "      <th>GBPUSD=X</th>\n",
       "      <th>USDCAD=X</th>\n",
       "      <th>USDCHF=X</th>\n",
       "      <th>USDJPY=X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-06</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-07</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-21</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-22</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-23</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AUDUSD=X  EURUSD=X  GBPUSD=X  USDCAD=X  USDCHF=X  USDJPY=X\n",
       "date                                                                  \n",
       "2022-01-03         0       100       100       100         0         0\n",
       "2022-01-04         0       100       100       100         0         0\n",
       "2022-01-05         0       100       100       100         0         0\n",
       "2022-01-06         0       100       100       100         0         0\n",
       "2022-01-07         0       100       100       100         0         0\n",
       "...              ...       ...       ...       ...       ...       ...\n",
       "2022-12-21         0       100       100       100         0         0\n",
       "2022-12-22         0       100       100       100         0         0\n",
       "2022-12-23         0       100       100       100         0         0\n",
       "2022-12-27         0       100       100       100         0         0\n",
       "2022-12-28         0       100       100       100         0         0\n",
       "\n",
       "[249 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trade by recurrentppo\n",
    "\n",
    "we use recurrent ppo as alternative to finrl's drl agents beacause our env is partially observable and we need memory so we use recurrent ppo (lstm ppo) for using of recurrent prediction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammad/miniconda3/envs/Finrl/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "e_trade_gym = StockTradingEnv(df = trade,  turbulence_threshold = 70,risk_indicator_col='vix', **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_version' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(config\u001b[39m.\u001b[39mTRAINED_MODEL_DIR,  model_version \u001b[39m+\u001b[39m model_version \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.pth\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_version' is not defined"
     ]
    }
   ],
   "source": [
    "os.path.join(config.TRAINED_MODEL_DIR,  model_version + model_version + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TD3Policy.__init__() got an unexpected keyword argument 'use_sde'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_version \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m1000000\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      2\u001b[0m model_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDDPG_\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m model \u001b[39m=\u001b[39m RecurrentPPO\u001b[39m.\u001b[39;49mload(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(TRAINED_MODEL_DIR,  model_name \u001b[39m+\u001b[39;49m model_version \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.pth\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m~/miniconda3/envs/Finrl/lib/python3.10/site-packages/stable_baselines3/common/base_class.py:741\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[0;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m model\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m.\u001b[39mupdate(data)\n\u001b[1;32m    740\u001b[0m model\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[0;32m--> 741\u001b[0m model\u001b[39m.\u001b[39;49m_setup_model()\n\u001b[1;32m    743\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    744\u001b[0m     \u001b[39m# put state_dicts back in place\u001b[39;00m\n\u001b[1;32m    745\u001b[0m     model\u001b[39m.\u001b[39mset_parameters(params, exact_match\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, device\u001b[39m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/Finrl/lib/python3.10/site-packages/sb3_contrib/ppo_recurrent/ppo_recurrent.py:147\u001b[0m, in \u001b[0;36mRecurrentPPO._setup_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_random_seed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseed)\n\u001b[1;32m    145\u001b[0m buffer_cls \u001b[39m=\u001b[39m RecurrentDictRolloutBuffer \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_space, spaces\u001b[39m.\u001b[39mDict) \u001b[39melse\u001b[39;00m RecurrentRolloutBuffer\n\u001b[0;32m--> 147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy_class(\n\u001b[1;32m    148\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobservation_space,\n\u001b[1;32m    149\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_space,\n\u001b[1;32m    150\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlr_schedule,\n\u001b[1;32m    151\u001b[0m     use_sde\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muse_sde,\n\u001b[1;32m    152\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy_kwargs,  \u001b[39m# pytype:disable=not-instantiable\u001b[39;49;00m\n\u001b[1;32m    153\u001b[0m )\n\u001b[1;32m    154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    156\u001b[0m \u001b[39m# We assume that LSTM for the actor and the critic\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39m# have the same architecture\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: TD3Policy.__init__() got an unexpected keyword argument 'use_sde'"
     ]
    }
   ],
   "source": [
    "model_version = '1000000'\n",
    "model_name = 'DDPG_'\n",
    "model = RecurrentPPO.load(os.path.join(TRAINED_MODEL_DIR,  model_name + model_version + \".pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "account_memory = []\n",
    "actions_memory = []\n",
    "lstm_states = None\n",
    "num_envs = 1\n",
    "episode_starts = np.ones((num_envs,), dtype=bool)\n",
    "#         state_memory=[] #add memory pool to store states\n",
    "env_trade.reset()\n",
    "for i in range(len(e_trade_gym.df.index.unique())):\n",
    "    action, lstm_states = model.predict(obs_trade, state=lstm_states, episode_start=episode_starts, deterministic=True)\n",
    "            # account_memory = test_env.env_method(method_name=\"save_asset_memory\")\n",
    "            # actions_memory = test_env.env_method(method_name=\"save_action_memory\")\n",
    "    obs_trade, rewards, dones, info = env_trade.step(action)\n",
    "    episode_starts = dones\n",
    "    env_trade.render()\n",
    "    if i == (len(e_trade_gym.df.index.unique()) - 2):\n",
    "        account_memory = env_trade.env_method(method_name=\"save_asset_memory\")\n",
    "        actions_memory = env_trade.env_method(method_name=\"save_action_memory\")\n",
    "#                 state_memory=test_env.env_method(method_name=\"save_state_memory\") # add current state to state memory\n",
    "    if dones[0]:\n",
    "        print(i)\n",
    "        print(\"hit end!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'account_memory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_account_value \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(account_memory[\u001b[39m0\u001b[39m])\n\u001b[1;32m      2\u001b[0m df_actions_memory \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(actions_memory[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'account_memory' is not defined"
     ]
    }
   ],
   "source": [
    "df_account_value = pd.DataFrame(account_memory[0])\n",
    "df_actions_memory = pd.DataFrame(actions_memory[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-04-26</td>\n",
       "      <td>1.000000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-27</td>\n",
       "      <td>1.017711e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>1.014192e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-29</td>\n",
       "      <td>9.902239e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>1.067545e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2021-09-17</td>\n",
       "      <td>8.741583e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2021-09-20</td>\n",
       "      <td>7.944693e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2021-09-21</td>\n",
       "      <td>7.521426e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2021-09-22</td>\n",
       "      <td>8.052165e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2021-09-23</td>\n",
       "      <td>8.296022e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  account_value\n",
       "0    2021-04-26   1.000000e+06\n",
       "1    2021-04-27   1.017711e+06\n",
       "2    2021-04-28   1.014192e+06\n",
       "3    2021-04-29   9.902239e+05\n",
       "4    2021-04-30   1.067545e+06\n",
       "..          ...            ...\n",
       "101  2021-09-17   8.741583e+05\n",
       "102  2021-09-20   7.944693e+05\n",
       "103  2021-09-21   7.521426e+05\n",
       "104  2021-09-22   8.052165e+05\n",
       "105  2021-09-23   8.296022e+05\n",
       "\n",
       "[106 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.to_csv(os.path.join(config.RESULTS_DIR,'account_value_for$_untill_$'.format(config.TRADE_START_DATE,config.TRADE_END_DATE)))\n",
    "df_actions_memory.to_csv(os.path.join(config.RESULTS_DIR,'actions_memory_for$_untill_$'.format(config.TRADE_START_DATE,config.TRADE_END_DATE)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Uy5_PTmOh1hj",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "include_colab_link": true,
   "name": "FinRL_StockTrading_NeurIPS_2018.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a913f0b5b2020ea25813dce4293e7824585e87f8cd8de80d0bb160f8ff78697"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
